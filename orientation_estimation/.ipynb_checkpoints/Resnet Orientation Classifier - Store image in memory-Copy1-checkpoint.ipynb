{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "sns.set(style=\"ticks\")\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.despine(top=True, right=True, left=False, bottom=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import other python files\n",
    "sys.path.append('../')\n",
    "import modules.Utils as Utils\n",
    "import modules.DataHandler as DataHandler\n",
    "import modules.DataSamplers as DataSamplers\n",
    "import modules.EvaluationUtils as Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = '../../../MainPipeline/data/processed/ORIENTATION_ANNOTATED/'\n",
    "os.path.exists(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeeDataset(Dataset):\n",
    "    '''\n",
    "    Always apply baseline transforms; augmentations optional.\n",
    "    '''\n",
    "    def __init__(self, root_path, baseline_transforms, augment_transforms=None, mode='train'):\n",
    "        # Mode for usage of this class\n",
    "        self.mode = mode\n",
    "\n",
    "        # Paths\n",
    "        self.root_path = root_path\n",
    "\n",
    "        # Transforms\n",
    "        self.baseline_transforms = baseline_transforms\n",
    "        self.augment_transforms = augment_transforms\n",
    "        \n",
    "        # Setups\n",
    "        self.store_imgs()\n",
    "#         self.prep_data()\n",
    "        \n",
    "    def store_imgs(self):\n",
    "        self.img_paths = sorted(glob.glob(f\"{os.path.join(self.root_path, f'cropped_imgs')}\\*.png\"))\n",
    "        \n",
    "        # Create collection of images\n",
    "        self.all_imgs = []\n",
    "        for path in self.img_paths:\n",
    "            img = cv2.imread(path, 0)\n",
    "            self.all_imgs.append(img)\n",
    "        \n",
    "    def prep_data(self):\n",
    "        self.img_dim = self.all_imgs[0].shape[:2]\n",
    "        self.img_c = self.all_imgs[0][..., np.newaxis].shape[-1]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.all_imgs[idx][..., np.newaxis]\n",
    "        label_theta = float(os.path.basename(self.img_paths[idx]).split(\"__\")[1].split(\"_\")[-1].replace('.png', ''))\n",
    "        \n",
    "        # Debug\n",
    "        if label_theta < 0:\n",
    "            label_theta = 0\n",
    "        \n",
    "        head_x = float(os.path.basename(self.img_paths[idx]).split(\"__\")[2].split('_')[-1].split(',')[0])\n",
    "        head_y = float(os.path.basename(self.img_paths[idx]).split(\"__\")[2].split('_')[-1].split(',')[1].replace('.png', ''))\n",
    "        tail_x = float(os.path.basename(self.img_paths[idx]).split(\"__\")[3].split('_')[-1].split(',')[0])\n",
    "        tail_y = float(os.path.basename(self.img_paths[idx]).split(\"__\")[3].split('_')[-1].split(',')[1].replace('.png', ''))\n",
    "\n",
    "        # Apply optinal augmentation transforms\n",
    "        if self.augment_transforms is not None:\n",
    "            img = self.augment_transforms(img)\n",
    "        # For all, apply baseline transforms\n",
    "        if self.baseline_transforms is not None:\n",
    "            img = self.baseline_transforms(img)\n",
    "\n",
    "        return img, label_theta, head_x, head_y, tail_x, tail_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        total_num_imgs = len(self.all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_transforms = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bee_data = BeeDataset(root_path, baseline_transforms, augment_transforms=None, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15435"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_imgs = len(bee_data.all_imgs)\n",
    "num_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'37.195012'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bee_data.img_paths[0].split(\"__\")[1].split(\"_\")[-1].replace('.png', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 10\n",
    "plt.imshow(bee_data.all_imgs[idx])\n",
    "plt.title(bee_data.img_paths[idx].split('/')[-1].split('__')[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split & loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 5 #42   #100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(bee_data, num_imgs, test_split=0.2, val_split=0.1):\n",
    "    dev_split = 1 - test_split\n",
    "    train_split = 1 - val_split\n",
    "\n",
    "    img_idxs = np.arange(0, len(bee_data.all_imgs), 1)\n",
    "    np.random.shuffle(img_idxs)\n",
    "    \n",
    "    # Split to dev and test\n",
    "    num_dev_examples = int(len(img_idxs) * dev_split)\n",
    "    dev_idxs = img_idxs[:num_dev_examples]\n",
    "    test_idxs = img_idxs[num_dev_examples:]\n",
    "    \n",
    "    # Split dev into train and val\n",
    "    num_train_examples = int(len(dev_idxs) * train_split)\n",
    "    train_idxs = dev_idxs[:num_train_examples]\n",
    "    val_idxs = dev_idxs[num_train_examples:]\n",
    "    \n",
    "    # Make sure no duplicates & sum up: 0 and True\n",
    "    check_1 = np.in1d(train_idxs, val_idxs).sum()\n",
    "    check_2 = np.in1d(train_idxs, test_idxs).sum()\n",
    "    check_3 = num_train_examples+len(val_idxs)+len(test_idxs) == num_imgs\n",
    "    print(check_1, check_2, check_3)\n",
    "    return train_idxs, val_idxs, test_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "LOAD_IDXS = True\n",
    "df_path = os.path.join(root_path, f'orient_train_val_test_idxs.pt')\n",
    "\n",
    "if LOAD_IDXS:\n",
    "    save_df_split_dict = torch.load(df_path)\n",
    "    train_idxs = save_df_split_dict['train_idxs']\n",
    "    val_idxs = save_df_split_dict['val_idxs']\n",
    "    test_idxs = save_df_split_dict['test_idxs']\n",
    "else:\n",
    "    train_idxs, val_idxs, test_idxs = train_val_test_split(bee_data, num_imgs, test_split=0.2, val_split=0.1)\n",
    "    save_df_split_dict = {\"train_idxs\": train_idxs, \"val_idxs\": val_idxs, \"test_idxs\": test_idxs}\n",
    "    # Save split indices to use later\n",
    "    df_path = os.path.join(root_path, f'orient_train_val_test_idxs.pt')\n",
    "    torch.save(save_df_split_dict, df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14031,    33, 10648, ...,  6501, 11246, 11801]),\n",
       " array([ 6397, 14569,  3495, ..., 14113, 11700,  8678]),\n",
       " array([3340, 9777, 6245, ..., 4079, 2254, 2915]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs, val_idxs, test_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE = True\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "sampler_train = SubsetRandomSampler(train_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "sampler_val = DataSamplers.SubsetIdentitySampler(indices=val_idxs)\n",
    "sampler_test = DataSamplers.SubsetIdentitySampler(indices=test_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "train_loader = DataLoader(bee_data, batch_size=BATCH_SIZE, sampler=sampler_train, drop_last=True)\n",
    "val_loader = DataLoader(bee_data, batch_size=BATCH_SIZE, sampler=sampler_val, drop_last=True)\n",
    "test_loader = DataLoader(bee_data, batch_size=BATCH_SIZE, sampler=sampler_test, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "for i, (X_, y_, head_x, head_y, tail_x, tail_y) in enumerate(test_loader):\n",
    "    X_, y_ = Utils.shuffle_batch(X_, y_)\n",
    "    break\n",
    "    \n",
    "plt.imshow(make_grid(X_, padding=3).permute(1,2,0))\n",
    "# plt.title(list(y_))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLastLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.activation(x)\n",
    "        out = out * 2.0 * np.pi\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(num_classes):\n",
    "    print(f\"Building resnet-18 with {num_classes} class(es).\")\n",
    "    resnet = torchvision.models.resnet18(pretrained=True)\n",
    "    num_ftrs = resnet.fc.in_features\n",
    "    # resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    resnet.fc = nn.Sequential(\n",
    "#         nn.Dropout(0.5),\n",
    "        nn.Linear(num_ftrs, num_classes),\n",
    "        CustomLastLayer()\n",
    "    )\n",
    "    \n",
    "    return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_resnet = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building resnet-18 with 1 class(es).\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "if use_resnet:\n",
    "    model = build_resnet(NUM_CLASSES)\n",
    "else:\n",
    "    model = Net(n_channels=1, n_classes=1, drop_prob=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.000001 #0.000005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, pred_y, true_y):\n",
    "        term_1 = torch.sin(true_y - pred_y)\n",
    "        term_2 = torch.cos(true_y - pred_y)\n",
    "        # loss = torch.sqrt( (torch.atan2(term_1, term_2))**2 )\n",
    "        loss = (torch.atan2(term_1, term_2))**2\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "criterion = CustomLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check load in trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_metrics():\n",
    "    metrics = {\n",
    "        \"losses\" : {\n",
    "            \"train\" : [],\n",
    "            \"val\"  : []\n",
    "        },\n",
    "        \"accs\" : {\n",
    "            \"train\" : [],\n",
    "            \"val\"  : []\n",
    "        }\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../saved_models/no_dropout_3_ok/ResnetOrientationModel_epoch4500.pt\n"
     ]
    }
   ],
   "source": [
    "LOAD_MODEL = True\n",
    "load_path = '../saved_models/no_dropout_3_ok/ResnetOrientationModel_epoch4500.pt'\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    print(f\"Loading model from {load_path}\")\n",
    "    load_dict = torch.load(load_path)\n",
    "    model.load_state_dict(load_dict['model'])\n",
    "    optimizer.load_state_dict(load_dict['optim'])\n",
    "    metrics = load_dict['metrics']\n",
    "    start_epoch = load_dict['epoch']\n",
    "else:\n",
    "    print(\"Initializing new model.\")\n",
    "    metrics = init_metrics()\n",
    "    start_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, metrics, epoch_i):\n",
    "    save_dict = {\n",
    "        'model'   : model.state_dict(),\n",
    "        'optim'   : optimizer.state_dict(),\n",
    "        'metrics' : metrics,\n",
    "        'epoch'   : epoch_i\n",
    "    }\n",
    "    torch.save(save_dict, f'../saved_models/ResnetOrientationModel_epoch{epoch_i:04d}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y, preds, tol, BATCH_SIZE):\n",
    "    xxx = (y - tol/2) <= preds\n",
    "    yyy = preds <= (y + tol/2)\n",
    "    accuracy = (xxx.view(-1) & yyy.view(-1)).sum() / float(BATCH_SIZE) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_loader, model, criterion, device, tol, BATCH_SIZE):\n",
    "    batch_test_accs = []\n",
    "    batch_test_loss = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch_i, (X, y, head_x, head_y, tail_x, tail_y) in enumerate(test_loader):\n",
    "        # ----------------------\n",
    "            X = Utils.convert_X_for_resnet(X)\n",
    "\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # Convert to float data type\n",
    "            y = y.type(torch.FloatTensor).view(-1,1)\n",
    "            y = np.deg2rad(y)  # Convert to radians\n",
    "            y = y.to(device)\n",
    "    \n",
    "            logits = model(X)\n",
    "                        \n",
    "#             #### Convert negative angles to positive (add 360 to degrees or (2*np.pi) to radians)\n",
    "#             mask = (logits < 0) * (2*np.pi)\n",
    "#             logits = logits + mask\n",
    "#             ####\n",
    "            \n",
    "            accuracy = get_accuracy(y, logits, tol, BATCH_SIZE)\n",
    "            batch_test_accs.append(accuracy.item())\n",
    "            \n",
    "            loss = criterion(logits, y)\n",
    "            batch_test_loss.append(loss.item())\n",
    "\n",
    "            # stdout\n",
    "            eval_stdout = f'\\rBatch {batch_i}/{len(test_loader)} -- Loss: {np.mean(batch_test_loss):0.8f} -- Accuracy: {np.mean(batch_test_accs):0.8f}'\n",
    "            sys.stdout.write(eval_stdout)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    mean_acc = sum(batch_test_accs) / len(batch_test_accs)\n",
    "    mean_loss = sum(batch_test_loss) / len(batch_test_loss)\n",
    "    model.train()\n",
    "    return mean_acc, mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17453292519943295"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_EPOCHS = 5000\n",
    "deg = 10\n",
    "tol = deg * np.pi/180\n",
    "tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch_i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-059b2c877064>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstart_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epoch_i' is not defined"
     ]
    }
   ],
   "source": [
    "start_epoch = epoch_i\n",
    "start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Epoch 1/5000 -- Batch 172/173 -- Loss: 3.45305133 -- Train accuracy: 2.4115\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 3.44239891 -- Accuracy: 3.45394737\n",
      "\n",
      "Training:\n",
      "Epoch 2/5000 -- Batch 172/173 -- Loss: 1.95406008 -- Train accuracy: 3.0527\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 2.85164252 -- Accuracy: 3.20723684\n",
      "\n",
      "Training:\n",
      "Epoch 3/5000 -- Batch 172/173 -- Loss: 2.95156121 -- Train accuracy: 3.7211\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 2.40723006 -- Accuracy: 4.19407895\n",
      "\n",
      "Training:\n",
      "Epoch 4/5000 -- Batch 172/173 -- Loss: 1.38290632 -- Train accuracy: 4.4707\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 2.08278552 -- Accuracy: 4.11184211\n",
      "\n",
      "Training:\n",
      "Epoch 5/5000 -- Batch 172/173 -- Loss: 1.34325528 -- Train accuracy: 5.1662\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 1.81790862 -- Accuracy: 5.26315789\n",
      "\n",
      "Training:\n",
      "Epoch 6/5000 -- Batch 172/173 -- Loss: 1.35427213 -- Train accuracy: 5.7171\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 1.63859624 -- Accuracy: 6.41447368\n",
      "\n",
      "Training:\n",
      "Epoch 7/5000 -- Batch 172/173 -- Loss: 1.04529071 -- Train accuracy: 6.8642\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 1.51845608 -- Accuracy: 6.41447368\n",
      "\n",
      "Training:\n",
      "Epoch 8/5000 -- Batch 172/173 -- Loss: 1.05915403 -- Train accuracy: 7.1171\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 1.40684820 -- Accuracy: 5.92105263\n",
      "\n",
      "Training:\n",
      "Epoch 9/5000 -- Batch 172/173 -- Loss: 1.08373356 -- Train accuracy: 7.2887\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 1.32840926 -- Accuracy: 6.90789474\n",
      "\n",
      "Training:\n",
      "Epoch 10/5000 -- Batch 172/173 -- Loss: 1.02651513 -- Train accuracy: 8.0564\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 1.23030547 -- Accuracy: 6.82565789\n",
      "\n",
      "Training:\n",
      "Epoch 11/5000 -- Batch 172/173 -- Loss: 1.19882631 -- Train accuracy: 8.4809\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 1.18272170 -- Accuracy: 6.99013158\n",
      "\n",
      "Training:\n",
      "Epoch 12/5000 -- Batch 172/173 -- Loss: 0.74954098 -- Train accuracy: 7.9389\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 1.13136355 -- Accuracy: 7.81250000\n",
      "\n",
      "Training:\n",
      "Epoch 13/5000 -- Batch 172/173 -- Loss: 0.62093729 -- Train accuracy: 8.6705\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 1.08317165 -- Accuracy: 7.81250000\n",
      "\n",
      "Training:\n",
      "Epoch 14/5000 -- Batch 172/173 -- Loss: 0.77914310 -- Train accuracy: 9.2666\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 1.04020177 -- Accuracy: 7.56578947\n",
      "\n",
      "Training:\n",
      "Epoch 15/5000 -- Batch 172/173 -- Loss: 0.46301064 -- Train accuracy: 9.1763\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 1.01073060 -- Accuracy: 7.89473684\n",
      "\n",
      "Training:\n",
      "Epoch 16/5000 -- Batch 172/173 -- Loss: 0.92357004 -- Train accuracy: 9.1673\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.98400105 -- Accuracy: 9.04605263\n",
      "\n",
      "Training:\n",
      "Epoch 17/5000 -- Batch 172/173 -- Loss: 0.55489284 -- Train accuracy: 9.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.96710403 -- Accuracy: 10.11513158\n",
      "\n",
      "Training:\n",
      "Epoch 18/5000 -- Batch 172/173 -- Loss: 0.76888788 -- Train accuracy: 10.3053\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.94587766 -- Accuracy: 8.30592105\n",
      "\n",
      "Training:\n",
      "Epoch 19/5000 -- Batch 172/173 -- Loss: 0.52734572 -- Train accuracy: 9.4563\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.92882492 -- Accuracy: 7.97697368\n",
      "\n",
      "Training:\n",
      "Epoch 20/5000 -- Batch 172/173 -- Loss: 0.69888365 -- Train accuracy: 10.8743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.90061571 -- Accuracy: 9.375000007\n",
      "\n",
      "Training:\n",
      "Epoch 21/5000 -- Batch 172/173 -- Loss: 0.55797279 -- Train accuracy: 10.3595\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.89180862 -- Accuracy: 8.38815789\n",
      "\n",
      "Training:\n",
      "Epoch 22/5000 -- Batch 172/173 -- Loss: 0.55696845 -- Train accuracy: 10.6756\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.86747834 -- Accuracy: 9.786184213\n",
      "\n",
      "Training:\n",
      "Epoch 23/5000 -- Batch 172/173 -- Loss: 0.33121327 -- Train accuracy: 10.9104\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.86311678 -- Accuracy: 8.47039474\n",
      "\n",
      "Training:\n",
      "Epoch 24/5000 -- Batch 172/173 -- Loss: 0.40031126 -- Train accuracy: 11.3801\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.84190560 -- Accuracy: 11.18421053\n",
      "\n",
      "Training:\n",
      "Epoch 25/5000 -- Batch 172/173 -- Loss: 0.42756677 -- Train accuracy: 11.7955\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.82496271 -- Accuracy: 10.03289474\n",
      "\n",
      "Training:\n",
      "Epoch 26/5000 -- Batch 172/173 -- Loss: 0.72308648 -- Train accuracy: 12.3645\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.81044151 -- Accuracy: 10.77302632\n",
      "\n",
      "Training:\n",
      "Epoch 27/5000 -- Batch 172/173 -- Loss: 0.47297937 -- Train accuracy: 12.6897\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.79091050 -- Accuracy: 10.27960526\n",
      "\n",
      "Training:\n",
      "Epoch 28/5000 -- Batch 172/173 -- Loss: 0.40085918 -- Train accuracy: 12.2923\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.78406327 -- Accuracy: 10.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 29/5000 -- Batch 172/173 -- Loss: 0.38849065 -- Train accuracy: 12.8793\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.78693257 -- Accuracy: 10.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 30/5000 -- Batch 172/173 -- Loss: 0.23722687 -- Train accuracy: 13.1322\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.77718703 -- Accuracy: 10.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 31/5000 -- Batch 172/173 -- Loss: 0.33143735 -- Train accuracy: 13.0690\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.76333293 -- Accuracy: 10.36184211\n",
      "\n",
      "Training:\n",
      "Epoch 32/5000 -- Batch 172/173 -- Loss: 0.67683500 -- Train accuracy: 13.9180\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.75227248 -- Accuracy: 9.95065789\n",
      "\n",
      "Training:\n",
      "Epoch 33/5000 -- Batch 172/173 -- Loss: 0.28486699 -- Train accuracy: 13.4303\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.74958708 -- Accuracy: 11.10197368\n",
      "\n",
      "Training:\n",
      "Epoch 34/5000 -- Batch 172/173 -- Loss: 0.31033099 -- Train accuracy: 13.8457\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.75142442 -- Accuracy: 11.26644737\n",
      "\n",
      "Training:\n",
      "Epoch 35/5000 -- Batch 172/173 -- Loss: 0.40916649 -- Train accuracy: 14.2070\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.72243402 -- Accuracy: 11.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 36/5000 -- Batch 172/173 -- Loss: 0.30335307 -- Train accuracy: 14.5412\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.72838549 -- Accuracy: 12.33552632\n",
      "\n",
      "Training:\n",
      "Epoch 37/5000 -- Batch 172/173 -- Loss: 0.24706928 -- Train accuracy: 15.3450\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.72315266 -- Accuracy: 11.92434211\n",
      "\n",
      "Training:\n",
      "Epoch 38/5000 -- Batch 172/173 -- Loss: 0.20135793 -- Train accuracy: 15.5979\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.71751728 -- Accuracy: 12.17105263\n",
      "\n",
      "Training:\n",
      "Epoch 39/5000 -- Batch 172/173 -- Loss: 0.28523102 -- Train accuracy: 15.0199\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.71474489 -- Accuracy: 10.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 40/5000 -- Batch 172/173 -- Loss: 0.60998386 -- Train accuracy: 15.8056\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.71184944 -- Accuracy: 12.25328947\n",
      "\n",
      "Training:\n",
      "Epoch 41/5000 -- Batch 172/173 -- Loss: 0.20360954 -- Train accuracy: 15.6792\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.70157813 -- Accuracy: 12.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 42/5000 -- Batch 172/173 -- Loss: 0.26874566 -- Train accuracy: 15.5347\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.68269331 -- Accuracy: 11.67763158\n",
      "\n",
      "Training:\n",
      "Epoch 43/5000 -- Batch 172/173 -- Loss: 0.27673385 -- Train accuracy: 16.3656\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.69199435 -- Accuracy: 11.59539474\n",
      "\n",
      "Training:\n",
      "Epoch 44/5000 -- Batch 172/173 -- Loss: 0.22801420 -- Train accuracy: 16.2301\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.67340377 -- Accuracy: 12.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 45/5000 -- Batch 172/173 -- Loss: 0.15813869 -- Train accuracy: 17.8739\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.68227037 -- Accuracy: 11.92434211\n",
      "\n",
      "Training:\n",
      "Epoch 46/5000 -- Batch 172/173 -- Loss: 0.22867730 -- Train accuracy: 16.6637\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.68706786 -- Accuracy: 12.74671053\n",
      "\n",
      "Training:\n",
      "Epoch 47/5000 -- Batch 172/173 -- Loss: 0.16165480 -- Train accuracy: 16.9527\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.67857900 -- Accuracy: 11.75986842\n",
      "\n",
      "Training:\n",
      "Epoch 48/5000 -- Batch 172/173 -- Loss: 0.32754976 -- Train accuracy: 17.7384\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.66549623 -- Accuracy: 13.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 49/5000 -- Batch 172/173 -- Loss: 0.21516509 -- Train accuracy: 17.7565\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.65628747 -- Accuracy: 13.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 50/5000 -- Batch 172/173 -- Loss: 0.21819419 -- Train accuracy: 18.3436\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.65720577 -- Accuracy: 13.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 51/5000 -- Batch 172/173 -- Loss: 0.37966913 -- Train accuracy: 17.5126\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.65909977 -- Accuracy: 13.48684211\n",
      "\n",
      "Training:\n",
      "Epoch 52/5000 -- Batch 172/173 -- Loss: 0.37331080 -- Train accuracy: 18.1720\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.65279493 -- Accuracy: 13.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 53/5000 -- Batch 172/173 -- Loss: 0.14812607 -- Train accuracy: 18.8223\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.64649507 -- Accuracy: 13.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 54/5000 -- Batch 172/173 -- Loss: 0.10825513 -- Train accuracy: 19.1022\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.63940542 -- Accuracy: 12.91118421\n",
      "\n",
      "Training:\n",
      "Epoch 55/5000 -- Batch 172/173 -- Loss: 0.10462557 -- Train accuracy: 19.5809\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.65118764 -- Accuracy: 13.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 56/5000 -- Batch 172/173 -- Loss: 0.11699075 -- Train accuracy: 19.2106\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.63373871 -- Accuracy: 13.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 57/5000 -- Batch 172/173 -- Loss: 0.09697741 -- Train accuracy: 19.5358\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.64404764 -- Accuracy: 13.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 58/5000 -- Batch 172/173 -- Loss: 0.07668294 -- Train accuracy: 20.4841\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.63620625 -- Accuracy: 14.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 59/5000 -- Batch 172/173 -- Loss: 0.20941600 -- Train accuracy: 19.5358\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.63284640 -- Accuracy: 14.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 60/5000 -- Batch 172/173 -- Loss: 0.14368275 -- Train accuracy: 20.4931\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.62179585 -- Accuracy: 15.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 61/5000 -- Batch 172/173 -- Loss: 0.11380784 -- Train accuracy: 20.9447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.62005633 -- Accuracy: 15.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 62/5000 -- Batch 172/173 -- Loss: 0.21730404 -- Train accuracy: 20.5383\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.62019860 -- Accuracy: 13.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 63/5000 -- Batch 172/173 -- Loss: 0.28142262 -- Train accuracy: 20.2854\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.61855913 -- Accuracy: 15.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 64/5000 -- Batch 172/173 -- Loss: 0.13347550 -- Train accuracy: 20.7551\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.62486639 -- Accuracy: 15.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 65/5000 -- Batch 172/173 -- Loss: 0.28439972 -- Train accuracy: 21.0531\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.60451001 -- Accuracy: 15.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 66/5000 -- Batch 172/173 -- Loss: 0.12322520 -- Train accuracy: 21.0170\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.60988072 -- Accuracy: 14.72039474\n",
      "\n",
      "Training:\n",
      "Epoch 67/5000 -- Batch 172/173 -- Loss: 0.08006354 -- Train accuracy: 22.1098\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.59025579 -- Accuracy: 15.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 68/5000 -- Batch 172/173 -- Loss: 0.10408992 -- Train accuracy: 21.9292\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.60955043 -- Accuracy: 15.70723684\n",
      "\n",
      "Training:\n",
      "Epoch 69/5000 -- Batch 172/173 -- Loss: 0.22318369 -- Train accuracy: 22.0014\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.60491380 -- Accuracy: 16.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 70/5000 -- Batch 172/173 -- Loss: 0.08006021 -- Train accuracy: 22.4530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.59567531 -- Accuracy: 15.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 71/5000 -- Batch 172/173 -- Loss: 0.17993824 -- Train accuracy: 22.5614\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.60098006 -- Accuracy: 15.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 72/5000 -- Batch 172/173 -- Loss: 0.15190977 -- Train accuracy: 21.8660\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.59267726 -- Accuracy: 14.30921053\n",
      "\n",
      "Training:\n",
      "Epoch 73/5000 -- Batch 172/173 -- Loss: 0.09765244 -- Train accuracy: 23.1575\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.60830171 -- Accuracy: 15.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 74/5000 -- Batch 172/173 -- Loss: 0.20326802 -- Train accuracy: 23.2840\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.58512075 -- Accuracy: 15.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 75/5000 -- Batch 172/173 -- Loss: 0.08221827 -- Train accuracy: 24.3136\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.58856279 -- Accuracy: 15.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 76/5000 -- Batch 172/173 -- Loss: 0.12452395 -- Train accuracy: 23.7265\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.57533857 -- Accuracy: 14.30921053\n",
      "\n",
      "Training:\n",
      "Epoch 77/5000 -- Batch 172/173 -- Loss: 0.15165758 -- Train accuracy: 24.1781\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.58148539 -- Accuracy: 16.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 78/5000 -- Batch 172/173 -- Loss: 0.22147076 -- Train accuracy: 24.0155\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.58686114 -- Accuracy: 15.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 79/5000 -- Batch 172/173 -- Loss: 0.07829858 -- Train accuracy: 24.8013\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.57001291 -- Accuracy: 15.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 80/5000 -- Batch 172/173 -- Loss: 0.05679960 -- Train accuracy: 23.8710\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.57389518 -- Accuracy: 15.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 81/5000 -- Batch 172/173 -- Loss: 0.06700081 -- Train accuracy: 23.2117\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.57389518 -- Accuracy: 15.21381579\n",
      "\n",
      "Training:\n",
      "Epoch 82/5000 -- Batch 172/173 -- Loss: 0.14714569 -- Train accuracy: 24.3407\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.57848476 -- Accuracy: 16.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 83/5000 -- Batch 172/173 -- Loss: 0.10747425 -- Train accuracy: 25.6232\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.57083084 -- Accuracy: 16.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 84/5000 -- Batch 172/173 -- Loss: 0.09165609 -- Train accuracy: 25.4516\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.57371291 -- Accuracy: 16.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 85/5000 -- Batch 172/173 -- Loss: 0.11716607 -- Train accuracy: 24.5033\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.56619828 -- Accuracy: 17.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 86/5000 -- Batch 172/173 -- Loss: 0.08303306 -- Train accuracy: 25.6503\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.56014253 -- Accuracy: 16.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 87/5000 -- Batch 172/173 -- Loss: 0.07764820 -- Train accuracy: 24.7200\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.54641058 -- Accuracy: 16.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 88/5000 -- Batch 172/173 -- Loss: 0.09936517 -- Train accuracy: 26.8515\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.55640130 -- Accuracy: 15.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 89/5000 -- Batch 172/173 -- Loss: 0.05019030 -- Train accuracy: 26.1380\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.56836694 -- Accuracy: 15.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 90/5000 -- Batch 172/173 -- Loss: 0.09644034 -- Train accuracy: 26.6980\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.55275381 -- Accuracy: 17.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 91/5000 -- Batch 172/173 -- Loss: 0.08576990 -- Train accuracy: 26.1019\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.55269479 -- Accuracy: 16.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 92/5000 -- Batch 172/173 -- Loss: 0.17381024 -- Train accuracy: 26.4180\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.54486934 -- Accuracy: 17.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 93/5000 -- Batch 172/173 -- Loss: 0.10202694 -- Train accuracy: 26.7702\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.54312591 -- Accuracy: 16.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 94/5000 -- Batch 172/173 -- Loss: 0.13289270 -- Train accuracy: 27.7999\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.53590694 -- Accuracy: 18.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 95/5000 -- Batch 172/173 -- Loss: 0.05223892 -- Train accuracy: 27.0322\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.54787684 -- Accuracy: 17.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 96/5000 -- Batch 172/173 -- Loss: 0.09421038 -- Train accuracy: 28.0437\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.54611588 -- Accuracy: 16.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 97/5000 -- Batch 172/173 -- Loss: 0.07074697 -- Train accuracy: 27.7186\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.54092256 -- Accuracy: 17.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 98/5000 -- Batch 172/173 -- Loss: 0.11967744 -- Train accuracy: 26.9057\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.53474703 -- Accuracy: 16.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 99/5000 -- Batch 172/173 -- Loss: 0.09055800 -- Train accuracy: 26.6980\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.54193266 -- Accuracy: 16.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 100/5000 -- Batch 172/173 -- Loss: 0.05884010 -- Train accuracy: 26.5083\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.53671027 -- Accuracy: 17.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 101/5000 -- Batch 172/173 -- Loss: 0.06574418 -- Train accuracy: 26.9689\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.53345883 -- Accuracy: 18.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 102/5000 -- Batch 172/173 -- Loss: 0.08415352 -- Train accuracy: 27.3573\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.53402581 -- Accuracy: 16.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 103/5000 -- Batch 172/173 -- Loss: 0.03646424 -- Train accuracy: 28.2334\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.54168320 -- Accuracy: 17.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 104/5000 -- Batch 172/173 -- Loss: 0.09188913 -- Train accuracy: 27.7005\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/19 -- Loss: 0.52791460 -- Accuracy: 16.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 105/5000 -- Batch 172/173 -- Loss: 0.05327093 -- Train accuracy: 27.5741\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.53324183 -- Accuracy: 17.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 106/5000 -- Batch 172/173 -- Loss: 0.13280019 -- Train accuracy: 27.1857\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.52828949 -- Accuracy: 18.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 107/5000 -- Batch 172/173 -- Loss: 0.08984321 -- Train accuracy: 28.3869\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.51542293 -- Accuracy: 17.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 108/5000 -- Batch 172/173 -- Loss: 0.07311391 -- Train accuracy: 29.5611\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.51598123 -- Accuracy: 18.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 109/5000 -- Batch 172/173 -- Loss: 0.08271280 -- Train accuracy: 28.7934\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.51306267 -- Accuracy: 17.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 110/5000 -- Batch 172/173 -- Loss: 0.13836715 -- Train accuracy: 29.5340\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.52498887 -- Accuracy: 17.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 111/5000 -- Batch 172/173 -- Loss: 0.06451492 -- Train accuracy: 29.3082\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.51915310 -- Accuracy: 17.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 112/5000 -- Batch 172/173 -- Loss: 0.10731950 -- Train accuracy: 29.1275\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.50791262 -- Accuracy: 17.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 113/5000 -- Batch 172/173 -- Loss: 0.03886668 -- Train accuracy: 29.6333\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.50448264 -- Accuracy: 18.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 114/5000 -- Batch 172/173 -- Loss: 0.05104635 -- Train accuracy: 29.7868\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.49389736 -- Accuracy: 18.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 115/5000 -- Batch 172/173 -- Loss: 0.06507570 -- Train accuracy: 29.5249\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.51438510 -- Accuracy: 18.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 116/5000 -- Batch 172/173 -- Loss: 0.04108439 -- Train accuracy: 29.5249\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.51319352 -- Accuracy: 19.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 117/5000 -- Batch 172/173 -- Loss: 0.07060273 -- Train accuracy: 30.9520\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.50025809 -- Accuracy: 18.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 118/5000 -- Batch 172/173 -- Loss: 0.09853570 -- Train accuracy: 30.9610\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.50276260 -- Accuracy: 18.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 119/5000 -- Batch 172/173 -- Loss: 0.03232012 -- Train accuracy: 31.6022\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.50019657 -- Accuracy: 18.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 120/5000 -- Batch 172/173 -- Loss: 0.12043750 -- Train accuracy: 30.9249\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.50278539 -- Accuracy: 18.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 121/5000 -- Batch 172/173 -- Loss: 0.08394085 -- Train accuracy: 31.4306\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.50575618 -- Accuracy: 16.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 122/5000 -- Batch 172/173 -- Loss: 0.04871892 -- Train accuracy: 30.6178\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.49078826 -- Accuracy: 18.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 123/5000 -- Batch 172/173 -- Loss: 0.05940347 -- Train accuracy: 32.3609\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.48105204 -- Accuracy: 18.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 124/5000 -- Batch 172/173 -- Loss: 0.04376752 -- Train accuracy: 31.6474\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.48598629 -- Accuracy: 18.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 125/5000 -- Batch 172/173 -- Loss: 0.05145725 -- Train accuracy: 31.9996\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.49198341 -- Accuracy: 17.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 126/5000 -- Batch 172/173 -- Loss: 0.05502774 -- Train accuracy: 32.0629\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.48343698 -- Accuracy: 18.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 127/5000 -- Batch 172/173 -- Loss: 0.04312456 -- Train accuracy: 30.6539\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.47404367 -- Accuracy: 19.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 128/5000 -- Batch 172/173 -- Loss: 0.05982506 -- Train accuracy: 32.1622\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.48798814 -- Accuracy: 18.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 129/5000 -- Batch 172/173 -- Loss: 0.05196131 -- Train accuracy: 33.6796\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.49724280 -- Accuracy: 18.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 130/5000 -- Batch 172/173 -- Loss: 0.07465380 -- Train accuracy: 32.0809\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.47531396 -- Accuracy: 18.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 131/5000 -- Batch 172/173 -- Loss: 0.07424378 -- Train accuracy: 32.8035\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.49566173 -- Accuracy: 19.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 132/5000 -- Batch 172/173 -- Loss: 0.03598305 -- Train accuracy: 32.7402\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.48084164 -- Accuracy: 19.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 133/5000 -- Batch 172/173 -- Loss: 0.07609516 -- Train accuracy: 32.1622\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.47750920 -- Accuracy: 18.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 134/5000 -- Batch 172/173 -- Loss: 0.03700238 -- Train accuracy: 33.4718\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.49130793 -- Accuracy: 18.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 135/5000 -- Batch 172/173 -- Loss: 0.15102538 -- Train accuracy: 32.1261\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.48959473 -- Accuracy: 19.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 136/5000 -- Batch 172/173 -- Loss: 0.10226560 -- Train accuracy: 32.3609\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.48261353 -- Accuracy: 19.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 137/5000 -- Batch 172/173 -- Loss: 0.10603303 -- Train accuracy: 32.1803\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.47933915 -- Accuracy: 19.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 138/5000 -- Batch 172/173 -- Loss: 0.05993670 -- Train accuracy: 33.3363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.47375134 -- Accuracy: 19.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 139/5000 -- Batch 172/173 -- Loss: 0.05433018 -- Train accuracy: 34.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.46039110 -- Accuracy: 18.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 140/5000 -- Batch 172/173 -- Loss: 0.04219553 -- Train accuracy: 33.8150\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.46266335 -- Accuracy: 19.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 141/5000 -- Batch 172/173 -- Loss: 0.04422853 -- Train accuracy: 34.0228\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.47698670 -- Accuracy: 20.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 142/5000 -- Batch 172/173 -- Loss: 0.05496380 -- Train accuracy: 34.5105\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.46962173 -- Accuracy: 18.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 143/5000 -- Batch 172/173 -- Loss: 0.05182396 -- Train accuracy: 34.3840\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.46790118 -- Accuracy: 19.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 144/5000 -- Batch 172/173 -- Loss: 0.05868814 -- Train accuracy: 33.6796\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.46788981 -- Accuracy: 19.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 145/5000 -- Batch 172/173 -- Loss: 0.08188905 -- Train accuracy: 34.9801\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.47808234 -- Accuracy: 20.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 146/5000 -- Batch 172/173 -- Loss: 0.04565207 -- Train accuracy: 34.3479\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.46865759 -- Accuracy: 21.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 147/5000 -- Batch 172/173 -- Loss: 0.05135594 -- Train accuracy: 34.4202\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.48333628 -- Accuracy: 21.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 148/5000 -- Batch 172/173 -- Loss: 0.04772236 -- Train accuracy: 33.2912\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.47093018 -- Accuracy: 20.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 149/5000 -- Batch 172/173 -- Loss: 0.04728000 -- Train accuracy: 34.3027\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.47589347 -- Accuracy: 20.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 150/5000 -- Batch 172/173 -- Loss: 0.04412159 -- Train accuracy: 34.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.45134189 -- Accuracy: 20.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 151/5000 -- Batch 172/173 -- Loss: 0.04351004 -- Train accuracy: 35.2150\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.46024950 -- Accuracy: 20.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 152/5000 -- Batch 172/173 -- Loss: 0.05674172 -- Train accuracy: 35.3685\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.46058431 -- Accuracy: 20.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 153/5000 -- Batch 172/173 -- Loss: 0.06040443 -- Train accuracy: 36.8226\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.45719671 -- Accuracy: 19.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 154/5000 -- Batch 172/173 -- Loss: 0.06985832 -- Train accuracy: 34.4202\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44880179 -- Accuracy: 20.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 155/5000 -- Batch 172/173 -- Loss: 0.06753512 -- Train accuracy: 35.4588\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.45550853 -- Accuracy: 20.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 156/5000 -- Batch 172/173 -- Loss: 0.04857485 -- Train accuracy: 35.4859\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.43533513 -- Accuracy: 19.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 157/5000 -- Batch 172/173 -- Loss: 0.05152969 -- Train accuracy: 35.2511\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.45635078 -- Accuracy: 21.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 158/5000 -- Batch 172/173 -- Loss: 0.13205490 -- Train accuracy: 35.1879\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44806686 -- Accuracy: 20.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 159/5000 -- Batch 172/173 -- Loss: 0.07687971 -- Train accuracy: 36.2175\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44966067 -- Accuracy: 20.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 160/5000 -- Batch 172/173 -- Loss: 0.03598289 -- Train accuracy: 36.4794\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44875120 -- Accuracy: 21.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 161/5000 -- Batch 172/173 -- Loss: 0.05802958 -- Train accuracy: 36.1633\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44175544 -- Accuracy: 21.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 162/5000 -- Batch 172/173 -- Loss: 0.05170406 -- Train accuracy: 36.7413\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44386436 -- Accuracy: 21.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 163/5000 -- Batch 172/173 -- Loss: 0.03822710 -- Train accuracy: 35.8291\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.45358558 -- Accuracy: 22.45065789\n",
      "\n",
      "Training:\n",
      "Epoch 164/5000 -- Batch 172/173 -- Loss: 0.05363530 -- Train accuracy: 37.1387\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.43821213 -- Accuracy: 19.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 165/5000 -- Batch 172/173 -- Loss: 0.03854641 -- Train accuracy: 36.5426\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44784522 -- Accuracy: 22.61513158\n",
      "\n",
      "Training:\n",
      "Epoch 166/5000 -- Batch 172/173 -- Loss: 0.04837693 -- Train accuracy: 36.9400\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44257918 -- Accuracy: 20.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 167/5000 -- Batch 172/173 -- Loss: 0.04058076 -- Train accuracy: 37.1026\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.45733941 -- Accuracy: 22.20394737\n",
      "\n",
      "Training:\n",
      "Epoch 168/5000 -- Batch 172/173 -- Loss: 0.06338254 -- Train accuracy: 36.7865\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44559235 -- Accuracy: 21.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 169/5000 -- Batch 172/173 -- Loss: 0.04984046 -- Train accuracy: 37.0303\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44085754 -- Accuracy: 20.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 170/5000 -- Batch 172/173 -- Loss: 0.03470995 -- Train accuracy: 37.9877\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.43713860 -- Accuracy: 22.86184211\n",
      "\n",
      "Training:\n",
      "Epoch 171/5000 -- Batch 172/173 -- Loss: 0.06925826 -- Train accuracy: 36.2807\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.45136602 -- Accuracy: 22.03947368\n",
      "\n",
      "Training:\n",
      "Epoch 172/5000 -- Batch 172/173 -- Loss: 0.03132052 -- Train accuracy: 37.9335\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42998705 -- Accuracy: 22.36842105\n",
      "\n",
      "Training:\n",
      "Epoch 173/5000 -- Batch 172/173 -- Loss: 0.02598478 -- Train accuracy: 38.5206\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.43487715 -- Accuracy: 22.20394737\n",
      "\n",
      "Training:\n",
      "Epoch 174/5000 -- Batch 172/173 -- Loss: 0.02983963 -- Train accuracy: 37.9064\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.43022300 -- Accuracy: 21.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 175/5000 -- Batch 172/173 -- Loss: 0.06511352 -- Train accuracy: 37.6987\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42719782 -- Accuracy: 23.10855263\n",
      "\n",
      "Training:\n",
      "Epoch 176/5000 -- Batch 172/173 -- Loss: 0.05727862 -- Train accuracy: 38.3400\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42667436 -- Accuracy: 21.95723684\n",
      "\n",
      "Training:\n",
      "Epoch 177/5000 -- Batch 172/173 -- Loss: 0.03539214 -- Train accuracy: 38.8186\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44345810 -- Accuracy: 21.95723684\n",
      "\n",
      "Training:\n",
      "Epoch 178/5000 -- Batch 172/173 -- Loss: 0.03386828 -- Train accuracy: 39.4509\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44100598 -- Accuracy: 22.28618421\n",
      "\n",
      "Training:\n",
      "Epoch 179/5000 -- Batch 172/173 -- Loss: 0.04181585 -- Train accuracy: 40.2276\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44039609 -- Accuracy: 22.45065789\n",
      "\n",
      "Training:\n",
      "Epoch 180/5000 -- Batch 172/173 -- Loss: 0.02972613 -- Train accuracy: 40.6250\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.43368588 -- Accuracy: 22.03947368\n",
      "\n",
      "Training:\n",
      "Epoch 181/5000 -- Batch 172/173 -- Loss: 0.03431612 -- Train accuracy: 40.2366\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.43224913 -- Accuracy: 22.86184211\n",
      "\n",
      "Training:\n",
      "Epoch 182/5000 -- Batch 172/173 -- Loss: 0.04274116 -- Train accuracy: 38.8728\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.43037354 -- Accuracy: 22.77960526\n",
      "\n",
      "Training:\n",
      "Epoch 183/5000 -- Batch 172/173 -- Loss: 0.09128532 -- Train accuracy: 38.8367\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.44411042 -- Accuracy: 22.61513158\n",
      "\n",
      "Training:\n",
      "Epoch 184/5000 -- Batch 172/173 -- Loss: 0.14983749 -- Train accuracy: 38.3309\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.41755857 -- Accuracy: 22.69736842\n",
      "\n",
      "Training:\n",
      "Epoch 185/5000 -- Batch 172/173 -- Loss: 0.05247021 -- Train accuracy: 39.0264\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42931979 -- Accuracy: 22.61513158\n",
      "\n",
      "Training:\n",
      "Epoch 186/5000 -- Batch 172/173 -- Loss: 0.04379263 -- Train accuracy: 40.5979\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42030351 -- Accuracy: 22.36842105\n",
      "\n",
      "Training:\n",
      "Epoch 187/5000 -- Batch 172/173 -- Loss: 0.05355239 -- Train accuracy: 40.0831\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.43949352 -- Accuracy: 23.27302632\n",
      "\n",
      "Training:\n",
      "Epoch 188/5000 -- Batch 172/173 -- Loss: 0.07355130 -- Train accuracy: 40.7514\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.41330416 -- Accuracy: 22.61513158\n",
      "\n",
      "Training:\n",
      "Epoch 189/5000 -- Batch 172/173 -- Loss: 0.05026234 -- Train accuracy: 39.6225\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.41541486 -- Accuracy: 22.28618421\n",
      "\n",
      "Training:\n",
      "Epoch 190/5000 -- Batch 172/173 -- Loss: 0.04005782 -- Train accuracy: 40.8327\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42281378 -- Accuracy: 23.68421053\n",
      "\n",
      "Training:\n",
      "Epoch 191/5000 -- Batch 172/173 -- Loss: 0.05759811 -- Train accuracy: 41.3475\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.43356927 -- Accuracy: 23.43750000\n",
      "\n",
      "Training:\n",
      "Epoch 192/5000 -- Batch 172/173 -- Loss: 0.04223429 -- Train accuracy: 40.3450\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40884614 -- Accuracy: 22.36842105\n",
      "\n",
      "Training:\n",
      "Epoch 193/5000 -- Batch 172/173 -- Loss: 0.05799349 -- Train accuracy: 40.6611\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.41629738 -- Accuracy: 23.10855263\n",
      "\n",
      "Training:\n",
      "Epoch 194/5000 -- Batch 172/173 -- Loss: 0.03905162 -- Train accuracy: 41.1127\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42051896 -- Accuracy: 22.20394737\n",
      "\n",
      "Training:\n",
      "Epoch 195/5000 -- Batch 172/173 -- Loss: 0.07342893 -- Train accuracy: 40.7695\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.41384479 -- Accuracy: 24.09539474\n",
      "\n",
      "Training:\n",
      "Epoch 196/5000 -- Batch 172/173 -- Loss: 0.04899963 -- Train accuracy: 41.2121\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40764706 -- Accuracy: 23.76644737\n",
      "\n",
      "Training:\n",
      "Epoch 197/5000 -- Batch 172/173 -- Loss: 0.06649985 -- Train accuracy: 39.9296\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42469331 -- Accuracy: 24.25986842\n",
      "\n",
      "Training:\n",
      "Epoch 198/5000 -- Batch 172/173 -- Loss: 0.06020132 -- Train accuracy: 41.0134\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.41692751 -- Accuracy: 23.84868421\n",
      "\n",
      "Training:\n",
      "Epoch 199/5000 -- Batch 172/173 -- Loss: 0.04976100 -- Train accuracy: 40.9772\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.41470261 -- Accuracy: 22.61513158\n",
      "\n",
      "Training:\n",
      "Epoch 200/5000 -- Batch 172/173 -- Loss: 0.05965409 -- Train accuracy: 40.5527\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.41588384 -- Accuracy: 24.58881579\n",
      "\n",
      "Training:\n",
      "Epoch 201/5000 -- Batch 172/173 -- Loss: 0.03286520 -- Train accuracy: 41.6637\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40646283 -- Accuracy: 23.27302632\n",
      "\n",
      "Training:\n",
      "Epoch 202/5000 -- Batch 172/173 -- Loss: 0.04997031 -- Train accuracy: 42.7113\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42617692 -- Accuracy: 23.60197368\n",
      "\n",
      "Training:\n",
      "Epoch 203/5000 -- Batch 172/173 -- Loss: 0.04418731 -- Train accuracy: 43.3436\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.41827081 -- Accuracy: 22.12171053\n",
      "\n",
      "Training:\n",
      "Epoch 204/5000 -- Batch 172/173 -- Loss: 0.04890697 -- Train accuracy: 42.6572\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40392681 -- Accuracy: 24.25986842\n",
      "\n",
      "Training:\n",
      "Epoch 205/5000 -- Batch 172/173 -- Loss: 0.04623248 -- Train accuracy: 43.0184\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42347346 -- Accuracy: 24.83552632\n",
      "\n",
      "Training:\n",
      "Epoch 206/5000 -- Batch 172/173 -- Loss: 0.04685640 -- Train accuracy: 43.1900\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.41922340 -- Accuracy: 23.84868421\n",
      "\n",
      "Training:\n",
      "Epoch 207/5000 -- Batch 172/173 -- Loss: 0.02934746 -- Train accuracy: 42.9371\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/19 -- Loss: 0.40487195 -- Accuracy: 24.42434211\n",
      "\n",
      "Training:\n",
      "Epoch 208/5000 -- Batch 172/173 -- Loss: 0.12079102 -- Train accuracy: 42.5488\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42130898 -- Accuracy: 23.27302632\n",
      "\n",
      "Training:\n",
      "Epoch 209/5000 -- Batch 172/173 -- Loss: 0.03490364 -- Train accuracy: 41.4830\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.41103795 -- Accuracy: 23.51973684\n",
      "\n",
      "Training:\n",
      "Epoch 210/5000 -- Batch 172/173 -- Loss: 0.02493880 -- Train accuracy: 44.0390\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42147684 -- Accuracy: 24.17763158\n",
      "\n",
      "Training:\n",
      "Epoch 211/5000 -- Batch 172/173 -- Loss: 0.02792696 -- Train accuracy: 43.4429\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42053235 -- Accuracy: 24.50657895\n",
      "\n",
      "Training:\n",
      "Epoch 212/5000 -- Batch 172/173 -- Loss: 0.06039097 -- Train accuracy: 43.0997\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40584463 -- Accuracy: 23.93092105\n",
      "\n",
      "Training:\n",
      "Epoch 213/5000 -- Batch 172/173 -- Loss: 0.02669863 -- Train accuracy: 42.8468\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40950777 -- Accuracy: 23.93092105\n",
      "\n",
      "Training:\n",
      "Epoch 214/5000 -- Batch 172/173 -- Loss: 0.04301981 -- Train accuracy: 44.2829\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40075307 -- Accuracy: 24.09539474\n",
      "\n",
      "Training:\n",
      "Epoch 215/5000 -- Batch 172/173 -- Loss: 0.03338265 -- Train accuracy: 43.1629\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.41354574 -- Accuracy: 24.25986842\n",
      "\n",
      "Training:\n",
      "Epoch 216/5000 -- Batch 172/173 -- Loss: 0.04585905 -- Train accuracy: 44.2287\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.42260026 -- Accuracy: 24.50657895\n",
      "\n",
      "Training:\n",
      "Epoch 217/5000 -- Batch 172/173 -- Loss: 0.03717393 -- Train accuracy: 42.6120\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39833496 -- Accuracy: 25.41118421\n",
      "\n",
      "Training:\n",
      "Epoch 218/5000 -- Batch 172/173 -- Loss: 0.05235736 -- Train accuracy: 44.7254\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40841154 -- Accuracy: 23.68421053\n",
      "\n",
      "Training:\n",
      "Epoch 219/5000 -- Batch 172/173 -- Loss: 0.04319442 -- Train accuracy: 44.4635\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39655278 -- Accuracy: 24.67105263\n",
      "\n",
      "Training:\n",
      "Epoch 220/5000 -- Batch 172/173 -- Loss: 0.07467780 -- Train accuracy: 43.5965\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39255033 -- Accuracy: 25.98684211\n",
      "\n",
      "Training:\n",
      "Epoch 221/5000 -- Batch 172/173 -- Loss: 0.05618974 -- Train accuracy: 44.0390\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39621555 -- Accuracy: 24.42434211\n",
      "\n",
      "Training:\n",
      "Epoch 222/5000 -- Batch 172/173 -- Loss: 0.03743158 -- Train accuracy: 45.7370\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39282421 -- Accuracy: 24.91776316\n",
      "\n",
      "Training:\n",
      "Epoch 223/5000 -- Batch 172/173 -- Loss: 0.03380146 -- Train accuracy: 43.6326\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39414126 -- Accuracy: 24.83552632\n",
      "\n",
      "Training:\n",
      "Epoch 224/5000 -- Batch 172/173 -- Loss: 0.04935161 -- Train accuracy: 45.0777\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39146568 -- Accuracy: 25.08223684\n",
      "\n",
      "Training:\n",
      "Epoch 225/5000 -- Batch 172/173 -- Loss: 0.04177141 -- Train accuracy: 44.1293\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39545975 -- Accuracy: 25.24671053\n",
      "\n",
      "Training:\n",
      "Epoch 226/5000 -- Batch 172/173 -- Loss: 0.04135518 -- Train accuracy: 44.5990\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40606778 -- Accuracy: 25.00000000\n",
      "\n",
      "Training:\n",
      "Epoch 227/5000 -- Batch 172/173 -- Loss: 0.04101725 -- Train accuracy: 45.5835\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40018571 -- Accuracy: 25.49342105\n",
      "\n",
      "Training:\n",
      "Epoch 228/5000 -- Batch 172/173 -- Loss: 0.05838247 -- Train accuracy: 45.9267\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39403209 -- Accuracy: 25.57565789\n",
      "\n",
      "Training:\n",
      "Epoch 229/5000 -- Batch 172/173 -- Loss: 0.05266920 -- Train accuracy: 45.1590\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40095134 -- Accuracy: 26.06907895\n",
      "\n",
      "Training:\n",
      "Epoch 230/5000 -- Batch 172/173 -- Loss: 0.05247937 -- Train accuracy: 45.9718\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39871223 -- Accuracy: 25.57565789\n",
      "\n",
      "Training:\n",
      "Epoch 231/5000 -- Batch 172/173 -- Loss: 0.04134735 -- Train accuracy: 45.5654\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39011593 -- Accuracy: 25.08223684\n",
      "\n",
      "Training:\n",
      "Epoch 232/5000 -- Batch 172/173 -- Loss: 0.05623656 -- Train accuracy: 46.8298\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39553931 -- Accuracy: 24.50657895\n",
      "\n",
      "Training:\n",
      "Epoch 233/5000 -- Batch 172/173 -- Loss: 0.05229802 -- Train accuracy: 44.5177\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38660723 -- Accuracy: 25.49342105\n",
      "\n",
      "Training:\n",
      "Epoch 234/5000 -- Batch 172/173 -- Loss: 0.03018419 -- Train accuracy: 46.9743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39159865 -- Accuracy: 25.57565789\n",
      "\n",
      "Training:\n",
      "Epoch 235/5000 -- Batch 172/173 -- Loss: 0.03205420 -- Train accuracy: 45.1590\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38765063 -- Accuracy: 26.15131579\n",
      "\n",
      "Training:\n",
      "Epoch 236/5000 -- Batch 172/173 -- Loss: 0.04461957 -- Train accuracy: 45.1319\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39360536 -- Accuracy: 27.22039474\n",
      "\n",
      "Training:\n",
      "Epoch 237/5000 -- Batch 172/173 -- Loss: 0.02815430 -- Train accuracy: 45.3848\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38528577 -- Accuracy: 25.65789474\n",
      "\n",
      "Training:\n",
      "Epoch 238/5000 -- Batch 172/173 -- Loss: 0.02409411 -- Train accuracy: 47.0556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40198381 -- Accuracy: 26.31578947\n",
      "\n",
      "Training:\n",
      "Epoch 239/5000 -- Batch 172/173 -- Loss: 0.03566123 -- Train accuracy: 46.3331\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40469540 -- Accuracy: 25.65789474\n",
      "\n",
      "Training:\n",
      "Epoch 240/5000 -- Batch 172/173 -- Loss: 0.07121759 -- Train accuracy: 45.5112\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.37545475 -- Accuracy: 26.72697368\n",
      "\n",
      "Training:\n",
      "Epoch 241/5000 -- Batch 172/173 -- Loss: 0.03822326 -- Train accuracy: 46.5679\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38433777 -- Accuracy: 26.06907895\n",
      "\n",
      "Training:\n",
      "Epoch 242/5000 -- Batch 172/173 -- Loss: 0.02995252 -- Train accuracy: 46.5137\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36163846 -- Accuracy: 27.54934211\n",
      "\n",
      "Training:\n",
      "Epoch 243/5000 -- Batch 172/173 -- Loss: 0.05010439 -- Train accuracy: 46.9021\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40111139 -- Accuracy: 25.24671053\n",
      "\n",
      "Training:\n",
      "Epoch 244/5000 -- Batch 172/173 -- Loss: 0.04801916 -- Train accuracy: 47.7872\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39563636 -- Accuracy: 25.16447368\n",
      "\n",
      "Training:\n",
      "Epoch 245/5000 -- Batch 172/173 -- Loss: 0.04155277 -- Train accuracy: 46.5950\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39550181 -- Accuracy: 25.32894737\n",
      "\n",
      "Training:\n",
      "Epoch 246/5000 -- Batch 172/173 -- Loss: 0.02221138 -- Train accuracy: 47.0285\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40327314 -- Accuracy: 26.15131579\n",
      "\n",
      "Training:\n",
      "Epoch 247/5000 -- Batch 172/173 -- Loss: 0.06351342 -- Train accuracy: 47.9498\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.40353127 -- Accuracy: 26.64473684\n",
      "\n",
      "Training:\n",
      "Epoch 248/5000 -- Batch 172/173 -- Loss: 0.08246119 -- Train accuracy: 46.8569\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38502018 -- Accuracy: 25.98684211\n",
      "\n",
      "Training:\n",
      "Epoch 249/5000 -- Batch 172/173 -- Loss: 0.03895776 -- Train accuracy: 48.3201\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38982694 -- Accuracy: 25.98684211\n",
      "\n",
      "Training:\n",
      "Epoch 250/5000 -- Batch 172/173 -- Loss: 0.04066263 -- Train accuracy: 47.5885\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39499217 -- Accuracy: 25.32894737\n",
      "\n",
      "Training:\n",
      "Epoch 251/5000 -- Batch 172/173 -- Loss: 0.04444467 -- Train accuracy: 48.2388\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38474556 -- Accuracy: 26.56250000\n",
      "\n",
      "Training:\n",
      "Epoch 252/5000 -- Batch 172/173 -- Loss: 0.02796948 -- Train accuracy: 49.3678\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39496683 -- Accuracy: 26.15131579\n",
      "\n",
      "Training:\n",
      "Epoch 253/5000 -- Batch 172/173 -- Loss: 0.04187499 -- Train accuracy: 48.5278\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39465510 -- Accuracy: 26.56250000\n",
      "\n",
      "Training:\n",
      "Epoch 254/5000 -- Batch 172/173 -- Loss: 0.05081388 -- Train accuracy: 47.2724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38567683 -- Accuracy: 26.56250000\n",
      "\n",
      "Training:\n",
      "Epoch 255/5000 -- Batch 172/173 -- Loss: 0.04610615 -- Train accuracy: 48.6994\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38117412 -- Accuracy: 25.24671053\n",
      "\n",
      "Training:\n",
      "Epoch 256/5000 -- Batch 172/173 -- Loss: 0.04160625 -- Train accuracy: 47.4530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38921473 -- Accuracy: 27.13815789\n",
      "\n",
      "Training:\n",
      "Epoch 257/5000 -- Batch 172/173 -- Loss: 0.03444588 -- Train accuracy: 49.5213\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39004670 -- Accuracy: 26.89144737\n",
      "\n",
      "Training:\n",
      "Epoch 258/5000 -- Batch 172/173 -- Loss: 0.04985483 -- Train accuracy: 48.0401\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.37182979 -- Accuracy: 26.97368421\n",
      "\n",
      "Training:\n",
      "Epoch 259/5000 -- Batch 172/173 -- Loss: 0.03690591 -- Train accuracy: 48.2207\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39452719 -- Accuracy: 27.22039474\n",
      "\n",
      "Training:\n",
      "Epoch 260/5000 -- Batch 172/173 -- Loss: 0.04397203 -- Train accuracy: 48.7807\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38447815 -- Accuracy: 27.38486842\n",
      "\n",
      "Training:\n",
      "Epoch 261/5000 -- Batch 172/173 -- Loss: 0.04060140 -- Train accuracy: 48.8710\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.37520595 -- Accuracy: 26.48026316\n",
      "\n",
      "Training:\n",
      "Epoch 262/5000 -- Batch 172/173 -- Loss: 0.10025518 -- Train accuracy: 48.5459\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.37570508 -- Accuracy: 26.23355263\n",
      "\n",
      "Training:\n",
      "Epoch 263/5000 -- Batch 172/173 -- Loss: 0.03304106 -- Train accuracy: 48.4917\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.37815986 -- Accuracy: 27.96052632\n",
      "\n",
      "Training:\n",
      "Epoch 264/5000 -- Batch 172/173 -- Loss: 0.05320287 -- Train accuracy: 48.8349\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.37931219 -- Accuracy: 26.31578947\n",
      "\n",
      "Training:\n",
      "Epoch 265/5000 -- Batch 172/173 -- Loss: 0.01708379 -- Train accuracy: 50.3342\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39309345 -- Accuracy: 27.30263158\n",
      "\n",
      "Training:\n",
      "Epoch 266/5000 -- Batch 172/173 -- Loss: 0.04605108 -- Train accuracy: 48.5007\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38473116 -- Accuracy: 27.13815789\n",
      "\n",
      "Training:\n",
      "Epoch 267/5000 -- Batch 172/173 -- Loss: 0.03682107 -- Train accuracy: 48.3291\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.37564280 -- Accuracy: 27.71381579\n",
      "\n",
      "Training:\n",
      "Epoch 268/5000 -- Batch 172/173 -- Loss: 0.02916840 -- Train accuracy: 50.3974\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.37806356 -- Accuracy: 27.38486842\n",
      "\n",
      "Training:\n",
      "Epoch 269/5000 -- Batch 172/173 -- Loss: 0.04997919 -- Train accuracy: 50.2077\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.37186839 -- Accuracy: 26.64473684\n",
      "\n",
      "Training:\n",
      "Epoch 270/5000 -- Batch 172/173 -- Loss: 0.05064277 -- Train accuracy: 49.6207\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.39244984 -- Accuracy: 27.13815789\n",
      "\n",
      "Training:\n",
      "Epoch 271/5000 -- Batch 172/173 -- Loss: 0.03849350 -- Train accuracy: 50.5780\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38187262 -- Accuracy: 27.63157895\n",
      "\n",
      "Training:\n",
      "Epoch 272/5000 -- Batch 172/173 -- Loss: 0.04292517 -- Train accuracy: 49.6116\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.37667831 -- Accuracy: 26.48026316\n",
      "\n",
      "Training:\n",
      "Epoch 273/5000 -- Batch 172/173 -- Loss: 0.02558514 -- Train accuracy: 50.7045\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36767026 -- Accuracy: 27.79605263\n",
      "\n",
      "Training:\n",
      "Epoch 274/5000 -- Batch 172/173 -- Loss: 0.07449450 -- Train accuracy: 50.8309\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.38296203 -- Accuracy: 27.87828947\n",
      "\n",
      "Training:\n",
      "Epoch 275/5000 -- Batch 172/173 -- Loss: 0.02919767 -- Train accuracy: 50.8580\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.37388651 -- Accuracy: 27.46710526\n",
      "\n",
      "Training:\n",
      "Epoch 276/5000 -- Batch 172/173 -- Loss: 0.03839145 -- Train accuracy: 50.8400\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36708150 -- Accuracy: 27.30263158\n",
      "\n",
      "Training:\n",
      "Epoch 277/5000 -- Batch 172/173 -- Loss: 0.02548162 -- Train accuracy: 49.3497\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36557415 -- Accuracy: 28.45394737\n",
      "\n",
      "Training:\n",
      "Epoch 278/5000 -- Batch 172/173 -- Loss: 0.02819555 -- Train accuracy: 53.3237\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36378436 -- Accuracy: 27.13815789\n",
      "\n",
      "Training:\n",
      "Epoch 279/5000 -- Batch 172/173 -- Loss: 0.04279375 -- Train accuracy: 51.1832\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35321180 -- Accuracy: 27.87828947\n",
      "\n",
      "Training:\n",
      "Epoch 280/5000 -- Batch 172/173 -- Loss: 0.04520733 -- Train accuracy: 50.1897\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36887561 -- Accuracy: 28.45394737\n",
      "\n",
      "Training:\n",
      "Epoch 281/5000 -- Batch 172/173 -- Loss: 0.07072914 -- Train accuracy: 51.2283\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36054674 -- Accuracy: 28.28947368\n",
      "\n",
      "Training:\n",
      "Epoch 282/5000 -- Batch 172/173 -- Loss: 0.01794887 -- Train accuracy: 51.6980\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36428783 -- Accuracy: 28.20723684\n",
      "\n",
      "Training:\n",
      "Epoch 283/5000 -- Batch 172/173 -- Loss: 0.02888759 -- Train accuracy: 52.2489\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35816205 -- Accuracy: 28.86513158\n",
      "\n",
      "Training:\n",
      "Epoch 284/5000 -- Batch 172/173 -- Loss: 0.03246133 -- Train accuracy: 51.9328\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36382894 -- Accuracy: 28.28947368\n",
      "\n",
      "Training:\n",
      "Epoch 285/5000 -- Batch 172/173 -- Loss: 0.03101518 -- Train accuracy: 49.7561\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35311278 -- Accuracy: 27.87828947\n",
      "\n",
      "Training:\n",
      "Epoch 286/5000 -- Batch 172/173 -- Loss: 0.05513470 -- Train accuracy: 51.1561\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33690505 -- Accuracy: 29.44078947\n",
      "\n",
      "Training:\n",
      "Epoch 287/5000 -- Batch 172/173 -- Loss: 0.03691851 -- Train accuracy: 51.6618\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35979712 -- Accuracy: 27.38486842\n",
      "\n",
      "Training:\n",
      "Epoch 288/5000 -- Batch 172/173 -- Loss: 0.05360441 -- Train accuracy: 52.5108\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.37448385 -- Accuracy: 27.79605263\n",
      "\n",
      "Training:\n",
      "Epoch 289/5000 -- Batch 172/173 -- Loss: 0.02445856 -- Train accuracy: 51.9960\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36896076 -- Accuracy: 29.44078947\n",
      "\n",
      "Training:\n",
      "Epoch 290/5000 -- Batch 172/173 -- Loss: 0.02273859 -- Train accuracy: 51.2825\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35250534 -- Accuracy: 29.11184211\n",
      "\n",
      "Training:\n",
      "Epoch 291/5000 -- Batch 172/173 -- Loss: 0.03845014 -- Train accuracy: 53.2243\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36733015 -- Accuracy: 28.61842105\n",
      "\n",
      "Training:\n",
      "Epoch 292/5000 -- Batch 172/173 -- Loss: 0.05055906 -- Train accuracy: 51.8967\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35074472 -- Accuracy: 29.11184211\n",
      "\n",
      "Training:\n",
      "Epoch 293/5000 -- Batch 172/173 -- Loss: 0.02026368 -- Train accuracy: 53.2153\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36417660 -- Accuracy: 29.02960526\n",
      "\n",
      "Training:\n",
      "Epoch 294/5000 -- Batch 172/173 -- Loss: 0.03086331 -- Train accuracy: 52.9263\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35510581 -- Accuracy: 29.44078947\n",
      "\n",
      "Training:\n",
      "Epoch 295/5000 -- Batch 172/173 -- Loss: 0.02352925 -- Train accuracy: 52.8631\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36255891 -- Accuracy: 28.61842105\n",
      "\n",
      "Training:\n",
      "Epoch 296/5000 -- Batch 172/173 -- Loss: 0.04665575 -- Train accuracy: 52.0773\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35400293 -- Accuracy: 29.27631579\n",
      "\n",
      "Training:\n",
      "Epoch 297/5000 -- Batch 172/173 -- Loss: 0.04838326 -- Train accuracy: 52.4115\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36539286 -- Accuracy: 28.86513158\n",
      "\n",
      "Training:\n",
      "Epoch 298/5000 -- Batch 172/173 -- Loss: 0.05105103 -- Train accuracy: 52.3573\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35052234 -- Accuracy: 29.68750000\n",
      "\n",
      "Training:\n",
      "Epoch 299/5000 -- Batch 172/173 -- Loss: 0.03016390 -- Train accuracy: 53.5676\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35717073 -- Accuracy: 30.26315789\n",
      "\n",
      "Training:\n",
      "Epoch 300/5000 -- Batch 172/173 -- Loss: 0.05839837 -- Train accuracy: 53.7392\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.34542718 -- Accuracy: 29.44078947\n",
      "\n",
      "Training:\n",
      "Epoch 301/5000 -- Batch 172/173 -- Loss: 0.03724036 -- Train accuracy: 52.4566\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.34341395 -- Accuracy: 29.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 302/5000 -- Batch 172/173 -- Loss: 0.04127511 -- Train accuracy: 52.9624\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.34649190 -- Accuracy: 30.34539474\n",
      "\n",
      "Training:\n",
      "Epoch 303/5000 -- Batch 172/173 -- Loss: 0.04182465 -- Train accuracy: 54.5069\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33940807 -- Accuracy: 29.68750000\n",
      "\n",
      "Training:\n",
      "Epoch 304/5000 -- Batch 172/173 -- Loss: 0.02318553 -- Train accuracy: 53.7753\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35266952 -- Accuracy: 30.01644737\n",
      "\n",
      "Training:\n",
      "Epoch 305/5000 -- Batch 172/173 -- Loss: 0.03019550 -- Train accuracy: 53.2243\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36022875 -- Accuracy: 29.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 306/5000 -- Batch 172/173 -- Loss: 0.03961250 -- Train accuracy: 54.3443\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36303601 -- Accuracy: 29.44078947\n",
      "\n",
      "Training:\n",
      "Epoch 307/5000 -- Batch 172/173 -- Loss: 0.03520139 -- Train accuracy: 52.8540\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35812446 -- Accuracy: 28.86513158\n",
      "\n",
      "Training:\n",
      "Epoch 308/5000 -- Batch 172/173 -- Loss: 0.03667372 -- Train accuracy: 54.3714\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35721857 -- Accuracy: 29.44078947\n",
      "\n",
      "Training:\n",
      "Epoch 309/5000 -- Batch 172/173 -- Loss: 0.03352122 -- Train accuracy: 53.8475\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35264096 -- Accuracy: 30.26315789\n",
      "\n",
      "Training:\n",
      "Epoch 310/5000 -- Batch 172/173 -- Loss: 0.02323020 -- Train accuracy: 54.5611\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/19 -- Loss: 0.35214091 -- Accuracy: 29.68750000\n",
      "\n",
      "Training:\n",
      "Epoch 311/5000 -- Batch 172/173 -- Loss: 0.04521938 -- Train accuracy: 54.2720\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33310087 -- Accuracy: 29.27631579\n",
      "\n",
      "Training:\n",
      "Epoch 312/5000 -- Batch 172/173 -- Loss: 0.04682290 -- Train accuracy: 54.5972\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33533677 -- Accuracy: 29.93421053\n",
      "\n",
      "Training:\n",
      "Epoch 313/5000 -- Batch 172/173 -- Loss: 0.03085919 -- Train accuracy: 53.2153\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35242857 -- Accuracy: 29.52302632\n",
      "\n",
      "Training:\n",
      "Epoch 314/5000 -- Batch 172/173 -- Loss: 0.03794762 -- Train accuracy: 55.3017\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.34352613 -- Accuracy: 30.34539474\n",
      "\n",
      "Training:\n",
      "Epoch 315/5000 -- Batch 172/173 -- Loss: 0.03587275 -- Train accuracy: 54.9314\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33512272 -- Accuracy: 29.85197368\n",
      "\n",
      "Training:\n",
      "Epoch 316/5000 -- Batch 172/173 -- Loss: 0.02321482 -- Train accuracy: 55.1030\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.34753688 -- Accuracy: 29.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 317/5000 -- Batch 172/173 -- Loss: 0.04946394 -- Train accuracy: 54.8952\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36094706 -- Accuracy: 30.26315789\n",
      "\n",
      "Training:\n",
      "Epoch 318/5000 -- Batch 172/173 -- Loss: 0.04374053 -- Train accuracy: 54.6062\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33715584 -- Accuracy: 30.42763158\n",
      "\n",
      "Training:\n",
      "Epoch 319/5000 -- Batch 172/173 -- Loss: 0.02758630 -- Train accuracy: 55.4371\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33192722 -- Accuracy: 30.83881579\n",
      "\n",
      "Training:\n",
      "Epoch 320/5000 -- Batch 172/173 -- Loss: 0.02846662 -- Train accuracy: 56.1416\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.35027852 -- Accuracy: 29.76973684\n",
      "\n",
      "Training:\n",
      "Epoch 321/5000 -- Batch 172/173 -- Loss: 0.03156379 -- Train accuracy: 55.5184\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.34438659 -- Accuracy: 31.00328947\n",
      "\n",
      "Training:\n",
      "Epoch 322/5000 -- Batch 172/173 -- Loss: 0.02933500 -- Train accuracy: 55.8165\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.36579228 -- Accuracy: 30.59210526\n",
      "\n",
      "Training:\n",
      "Epoch 323/5000 -- Batch 172/173 -- Loss: 0.03134700 -- Train accuracy: 56.0965\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.34099102 -- Accuracy: 30.26315789\n",
      "\n",
      "Training:\n",
      "Epoch 324/5000 -- Batch 172/173 -- Loss: 0.05015450 -- Train accuracy: 55.3920\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.34690124 -- Accuracy: 30.01644737\n",
      "\n",
      "Training:\n",
      "Epoch 325/5000 -- Batch 172/173 -- Loss: 0.02300248 -- Train accuracy: 54.4798\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32867671 -- Accuracy: 30.92105263\n",
      "\n",
      "Training:\n",
      "Epoch 326/5000 -- Batch 172/173 -- Loss: 0.01522409 -- Train accuracy: 55.1210\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31933929 -- Accuracy: 30.75657895\n",
      "\n",
      "Training:\n",
      "Epoch 327/5000 -- Batch 172/173 -- Loss: 0.02827134 -- Train accuracy: 57.1893\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.34366799 -- Accuracy: 30.42763158\n",
      "\n",
      "Training:\n",
      "Epoch 328/5000 -- Batch 172/173 -- Loss: 0.02797743 -- Train accuracy: 56.5119\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.34192039 -- Accuracy: 30.18092105\n",
      "\n",
      "Training:\n",
      "Epoch 329/5000 -- Batch 172/173 -- Loss: 0.03213378 -- Train accuracy: 56.8732\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33091759 -- Accuracy: 30.92105263\n",
      "\n",
      "Training:\n",
      "Epoch 330/5000 -- Batch 172/173 -- Loss: 0.03767728 -- Train accuracy: 55.2926\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32821699 -- Accuracy: 30.42763158\n",
      "\n",
      "Training:\n",
      "Epoch 331/5000 -- Batch 172/173 -- Loss: 0.04803419 -- Train accuracy: 56.2952\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32524009 -- Accuracy: 31.90789474\n",
      "\n",
      "Training:\n",
      "Epoch 332/5000 -- Batch 172/173 -- Loss: 0.03166154 -- Train accuracy: 57.5777\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32923866 -- Accuracy: 30.75657895\n",
      "\n",
      "Training:\n",
      "Epoch 333/5000 -- Batch 172/173 -- Loss: 0.05563653 -- Train accuracy: 56.9545\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33929861 -- Accuracy: 30.50986842\n",
      "\n",
      "Training:\n",
      "Epoch 334/5000 -- Batch 172/173 -- Loss: 0.01841496 -- Train accuracy: 56.8100\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.34583398 -- Accuracy: 29.93421053\n",
      "\n",
      "Training:\n",
      "Epoch 335/5000 -- Batch 172/173 -- Loss: 0.03798409 -- Train accuracy: 57.8125\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33245399 -- Accuracy: 30.50986842\n",
      "\n",
      "Training:\n",
      "Epoch 336/5000 -- Batch 172/173 -- Loss: 0.03716935 -- Train accuracy: 57.0448\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33848253 -- Accuracy: 31.41447368\n",
      "\n",
      "Training:\n",
      "Epoch 337/5000 -- Batch 172/173 -- Loss: 0.02136857 -- Train accuracy: 56.9274\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31991450 -- Accuracy: 31.90789474\n",
      "\n",
      "Training:\n",
      "Epoch 338/5000 -- Batch 172/173 -- Loss: 0.03364351 -- Train accuracy: 57.1261\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33873407 -- Accuracy: 31.00328947\n",
      "\n",
      "Training:\n",
      "Epoch 339/5000 -- Batch 172/173 -- Loss: 0.06336457 -- Train accuracy: 56.3855\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32436479 -- Accuracy: 29.85197368\n",
      "\n",
      "Training:\n",
      "Epoch 340/5000 -- Batch 172/173 -- Loss: 0.03426056 -- Train accuracy: 56.0603\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31824948 -- Accuracy: 30.26315789\n",
      "\n",
      "Training:\n",
      "Epoch 341/5000 -- Batch 172/173 -- Loss: 0.02863196 -- Train accuracy: 57.0448\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30087819 -- Accuracy: 30.42763158\n",
      "\n",
      "Training:\n",
      "Epoch 342/5000 -- Batch 172/173 -- Loss: 0.04441884 -- Train accuracy: 57.3067\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31802249 -- Accuracy: 31.16776316\n",
      "\n",
      "Training:\n",
      "Epoch 343/5000 -- Batch 172/173 -- Loss: 0.07025821 -- Train accuracy: 56.6655\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32096196 -- Accuracy: 29.02960526\n",
      "\n",
      "Training:\n",
      "Epoch 344/5000 -- Batch 172/173 -- Loss: 0.02930393 -- Train accuracy: 57.9751\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32604433 -- Accuracy: 30.18092105\n",
      "\n",
      "Training:\n",
      "Epoch 345/5000 -- Batch 172/173 -- Loss: 0.01795882 -- Train accuracy: 56.9906\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33101932 -- Accuracy: 31.33223684\n",
      "\n",
      "Training:\n",
      "Epoch 346/5000 -- Batch 172/173 -- Loss: 0.02659186 -- Train accuracy: 57.9660\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31808897 -- Accuracy: 32.23684211\n",
      "\n",
      "Training:\n",
      "Epoch 347/5000 -- Batch 172/173 -- Loss: 0.02382240 -- Train accuracy: 57.6138\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32802735 -- Accuracy: 31.41447368\n",
      "\n",
      "Training:\n",
      "Epoch 348/5000 -- Batch 172/173 -- Loss: 0.04601112 -- Train accuracy: 58.1557\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33798364 -- Accuracy: 30.18092105\n",
      "\n",
      "Training:\n",
      "Epoch 349/5000 -- Batch 172/173 -- Loss: 0.02978754 -- Train accuracy: 57.3248\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32220663 -- Accuracy: 30.18092105\n",
      "\n",
      "Training:\n",
      "Epoch 350/5000 -- Batch 172/173 -- Loss: 0.03060228 -- Train accuracy: 58.3363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31065704 -- Accuracy: 31.33223684\n",
      "\n",
      "Training:\n",
      "Epoch 351/5000 -- Batch 172/173 -- Loss: 0.02184611 -- Train accuracy: 58.4809\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31394631 -- Accuracy: 31.16776316\n",
      "\n",
      "Training:\n",
      "Epoch 352/5000 -- Batch 172/173 -- Loss: 0.03442124 -- Train accuracy: 58.0202\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31444414 -- Accuracy: 31.82565789\n",
      "\n",
      "Training:\n",
      "Epoch 353/5000 -- Batch 172/173 -- Loss: 0.03614906 -- Train accuracy: 57.8035\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33794072 -- Accuracy: 31.08552632\n",
      "\n",
      "Training:\n",
      "Epoch 354/5000 -- Batch 172/173 -- Loss: 0.02056904 -- Train accuracy: 58.8873\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32624325 -- Accuracy: 30.42763158\n",
      "\n",
      "Training:\n",
      "Epoch 355/5000 -- Batch 172/173 -- Loss: 0.02872036 -- Train accuracy: 58.4357\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32419385 -- Accuracy: 31.66118421\n",
      "\n",
      "Training:\n",
      "Epoch 356/5000 -- Batch 172/173 -- Loss: 0.02808642 -- Train accuracy: 58.4718\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33006819 -- Accuracy: 31.99013158\n",
      "\n",
      "Training:\n",
      "Epoch 357/5000 -- Batch 172/173 -- Loss: 0.05677003 -- Train accuracy: 59.0047\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33624765 -- Accuracy: 30.83881579\n",
      "\n",
      "Training:\n",
      "Epoch 358/5000 -- Batch 172/173 -- Loss: 0.03033555 -- Train accuracy: 60.6124\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32365603 -- Accuracy: 31.49671053\n",
      "\n",
      "Training:\n",
      "Epoch 359/5000 -- Batch 172/173 -- Loss: 0.04206422 -- Train accuracy: 57.7583\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32385585 -- Accuracy: 31.00328947\n",
      "\n",
      "Training:\n",
      "Epoch 360/5000 -- Batch 172/173 -- Loss: 0.02660893 -- Train accuracy: 59.3750\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33838035 -- Accuracy: 32.15460526\n",
      "\n",
      "Training:\n",
      "Epoch 361/5000 -- Batch 172/173 -- Loss: 0.04058741 -- Train accuracy: 59.7092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32821823 -- Accuracy: 31.99013158\n",
      "\n",
      "Training:\n",
      "Epoch 362/5000 -- Batch 172/173 -- Loss: 0.04994797 -- Train accuracy: 59.5376\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33280290 -- Accuracy: 31.00328947\n",
      "\n",
      "Training:\n",
      "Epoch 363/5000 -- Batch 172/173 -- Loss: 0.02098707 -- Train accuracy: 58.9595\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32304189 -- Accuracy: 31.33223684\n",
      "\n",
      "Training:\n",
      "Epoch 364/5000 -- Batch 172/173 -- Loss: 0.05429130 -- Train accuracy: 58.9957\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33440249 -- Accuracy: 31.74342105\n",
      "\n",
      "Training:\n",
      "Epoch 365/5000 -- Batch 172/173 -- Loss: 0.02207978 -- Train accuracy: 60.5491\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31490493 -- Accuracy: 31.66118421\n",
      "\n",
      "Training:\n",
      "Epoch 366/5000 -- Batch 172/173 -- Loss: 0.03941633 -- Train accuracy: 59.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29484311 -- Accuracy: 31.33223684\n",
      "\n",
      "Training:\n",
      "Epoch 367/5000 -- Batch 172/173 -- Loss: 0.03423220 -- Train accuracy: 59.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32172598 -- Accuracy: 31.33223684\n",
      "\n",
      "Training:\n",
      "Epoch 368/5000 -- Batch 172/173 -- Loss: 0.02059258 -- Train accuracy: 59.4924\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32786364 -- Accuracy: 31.41447368\n",
      "\n",
      "Training:\n",
      "Epoch 369/5000 -- Batch 172/173 -- Loss: 0.08512191 -- Train accuracy: 59.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31685746 -- Accuracy: 31.82565789\n",
      "\n",
      "Training:\n",
      "Epoch 370/5000 -- Batch 172/173 -- Loss: 0.02475769 -- Train accuracy: 61.0007\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33291409 -- Accuracy: 32.23684211\n",
      "\n",
      "Training:\n",
      "Epoch 371/5000 -- Batch 172/173 -- Loss: 0.02119687 -- Train accuracy: 59.4202\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33063414 -- Accuracy: 31.57894737\n",
      "\n",
      "Training:\n",
      "Epoch 372/5000 -- Batch 172/173 -- Loss: 0.03342042 -- Train accuracy: 61.6871\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.34053935 -- Accuracy: 31.90789474\n",
      "\n",
      "Training:\n",
      "Epoch 373/5000 -- Batch 172/173 -- Loss: 0.03661074 -- Train accuracy: 59.1673\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29363737 -- Accuracy: 31.82565789\n",
      "\n",
      "Training:\n",
      "Epoch 374/5000 -- Batch 172/173 -- Loss: 0.06111826 -- Train accuracy: 59.5918\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31299191 -- Accuracy: 32.31907895\n",
      "\n",
      "Training:\n",
      "Epoch 375/5000 -- Batch 172/173 -- Loss: 0.02674291 -- Train accuracy: 60.8743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31212829 -- Accuracy: 31.33223684\n",
      "\n",
      "Training:\n",
      "Epoch 376/5000 -- Batch 172/173 -- Loss: 0.03484256 -- Train accuracy: 61.0368\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33225867 -- Accuracy: 31.08552632\n",
      "\n",
      "Training:\n",
      "Epoch 377/5000 -- Batch 172/173 -- Loss: 0.02847851 -- Train accuracy: 60.2421\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31968400 -- Accuracy: 31.99013158\n",
      "\n",
      "Training:\n",
      "Epoch 378/5000 -- Batch 172/173 -- Loss: 0.04893975 -- Train accuracy: 60.9827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31386824 -- Accuracy: 32.23684211\n",
      "\n",
      "Training:\n",
      "Epoch 379/5000 -- Batch 172/173 -- Loss: 0.02309759 -- Train accuracy: 60.5401\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32380037 -- Accuracy: 30.67434211\n",
      "\n",
      "Training:\n",
      "Epoch 380/5000 -- Batch 172/173 -- Loss: 0.04239629 -- Train accuracy: 60.9014\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32422306 -- Accuracy: 31.57894737\n",
      "\n",
      "Training:\n",
      "Epoch 381/5000 -- Batch 172/173 -- Loss: 0.03625603 -- Train accuracy: 61.3620\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32553284 -- Accuracy: 31.99013158\n",
      "\n",
      "Training:\n",
      "Epoch 382/5000 -- Batch 172/173 -- Loss: 0.02279086 -- Train accuracy: 60.1969\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32497811 -- Accuracy: 31.41447368\n",
      "\n",
      "Training:\n",
      "Epoch 383/5000 -- Batch 172/173 -- Loss: 0.01756298 -- Train accuracy: 60.8833\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32860979 -- Accuracy: 30.50986842\n",
      "\n",
      "Training:\n",
      "Epoch 384/5000 -- Batch 172/173 -- Loss: 0.02917191 -- Train accuracy: 61.9039\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33645856 -- Accuracy: 31.74342105\n",
      "\n",
      "Training:\n",
      "Epoch 385/5000 -- Batch 172/173 -- Loss: 0.02608932 -- Train accuracy: 61.4072\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.33334319 -- Accuracy: 31.99013158\n",
      "\n",
      "Training:\n",
      "Epoch 386/5000 -- Batch 172/173 -- Loss: 0.03672908 -- Train accuracy: 62.0394\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32130022 -- Accuracy: 32.15460526\n",
      "\n",
      "Training:\n",
      "Epoch 387/5000 -- Batch 172/173 -- Loss: 0.04329169 -- Train accuracy: 61.9400\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32981996 -- Accuracy: 32.56578947\n",
      "\n",
      "Training:\n",
      "Epoch 388/5000 -- Batch 172/173 -- Loss: 0.01953598 -- Train accuracy: 62.3013\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31816366 -- Accuracy: 32.23684211\n",
      "\n",
      "Training:\n",
      "Epoch 389/5000 -- Batch 172/173 -- Loss: 0.04314962 -- Train accuracy: 62.5181\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32046763 -- Accuracy: 33.30592105\n",
      "\n",
      "Training:\n",
      "Epoch 390/5000 -- Batch 172/173 -- Loss: 0.03967878 -- Train accuracy: 63.1774\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32499228 -- Accuracy: 31.74342105\n",
      "\n",
      "Training:\n",
      "Epoch 391/5000 -- Batch 172/173 -- Loss: 0.04200613 -- Train accuracy: 62.7258\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32560400 -- Accuracy: 32.64802632\n",
      "\n",
      "Training:\n",
      "Epoch 392/5000 -- Batch 172/173 -- Loss: 0.01889995 -- Train accuracy: 61.5246\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31402466 -- Accuracy: 32.81250000\n",
      "\n",
      "Training:\n",
      "Epoch 393/5000 -- Batch 172/173 -- Loss: 0.04585125 -- Train accuracy: 62.1749\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30222254 -- Accuracy: 32.56578947\n",
      "\n",
      "Training:\n",
      "Epoch 394/5000 -- Batch 172/173 -- Loss: 0.02866350 -- Train accuracy: 62.1297\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32525368 -- Accuracy: 32.81250000\n",
      "\n",
      "Training:\n",
      "Epoch 395/5000 -- Batch 172/173 -- Loss: 0.02887013 -- Train accuracy: 61.1904\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30956855 -- Accuracy: 34.21052632\n",
      "\n",
      "Training:\n",
      "Epoch 396/5000 -- Batch 172/173 -- Loss: 0.03496010 -- Train accuracy: 62.1478\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30926324 -- Accuracy: 33.63486842\n",
      "\n",
      "Training:\n",
      "Epoch 397/5000 -- Batch 172/173 -- Loss: 0.07030271 -- Train accuracy: 62.1839\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31975380 -- Accuracy: 32.97697368\n",
      "\n",
      "Training:\n",
      "Epoch 398/5000 -- Batch 172/173 -- Loss: 0.02201187 -- Train accuracy: 62.8793\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31466520 -- Accuracy: 32.56578947\n",
      "\n",
      "Training:\n",
      "Epoch 399/5000 -- Batch 172/173 -- Loss: 0.02628485 -- Train accuracy: 61.3620\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31362902 -- Accuracy: 33.79934211\n",
      "\n",
      "Training:\n",
      "Epoch 400/5000 -- Batch 172/173 -- Loss: 0.02347495 -- Train accuracy: 62.4729\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31107491 -- Accuracy: 32.56578947\n",
      "\n",
      "Training:\n",
      "Epoch 401/5000 -- Batch 172/173 -- Loss: 0.02966559 -- Train accuracy: 62.5090\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30665196 -- Accuracy: 34.45723684\n",
      "\n",
      "Training:\n",
      "Epoch 402/5000 -- Batch 172/173 -- Loss: 0.04725683 -- Train accuracy: 62.7348\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32032898 -- Accuracy: 33.88157895\n",
      "\n",
      "Training:\n",
      "Epoch 403/5000 -- Batch 172/173 -- Loss: 0.02652381 -- Train accuracy: 62.7258\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30425190 -- Accuracy: 33.30592105\n",
      "\n",
      "Training:\n",
      "Epoch 404/5000 -- Batch 172/173 -- Loss: 0.03427779 -- Train accuracy: 62.6897\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32486289 -- Accuracy: 34.04605263\n",
      "\n",
      "Training:\n",
      "Epoch 405/5000 -- Batch 172/173 -- Loss: 0.03079467 -- Train accuracy: 63.0871\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31284564 -- Accuracy: 33.30592105\n",
      "\n",
      "Training:\n",
      "Epoch 406/5000 -- Batch 172/173 -- Loss: 0.03509950 -- Train accuracy: 63.5658\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31928176 -- Accuracy: 32.07236842\n",
      "\n",
      "Training:\n",
      "Epoch 407/5000 -- Batch 172/173 -- Loss: 0.04474565 -- Train accuracy: 62.2742\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29433381 -- Accuracy: 34.04605263\n",
      "\n",
      "Training:\n",
      "Epoch 408/5000 -- Batch 172/173 -- Loss: 0.11229046 -- Train accuracy: 63.1142\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.32604334 -- Accuracy: 32.81250000\n",
      "\n",
      "Training:\n",
      "Epoch 409/5000 -- Batch 172/173 -- Loss: 0.01769895 -- Train accuracy: 63.8999\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29322196 -- Accuracy: 34.70394737\n",
      "\n",
      "Training:\n",
      "Epoch 410/5000 -- Batch 172/173 -- Loss: 0.04952396 -- Train accuracy: 63.6922\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30951078 -- Accuracy: 33.88157895\n",
      "\n",
      "Training:\n",
      "Epoch 411/5000 -- Batch 172/173 -- Loss: 0.03670616 -- Train accuracy: 63.1864\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30375913 -- Accuracy: 33.79934211\n",
      "\n",
      "Training:\n",
      "Epoch 412/5000 -- Batch 172/173 -- Loss: 0.02636389 -- Train accuracy: 63.6199\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30363336 -- Accuracy: 33.71710526\n",
      "\n",
      "Training:\n",
      "Epoch 413/5000 -- Batch 172/173 -- Loss: 0.03215691 -- Train accuracy: 62.5632\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/19 -- Loss: 0.29801269 -- Accuracy: 33.96381579\n",
      "\n",
      "Training:\n",
      "Epoch 414/5000 -- Batch 172/173 -- Loss: 0.09072390 -- Train accuracy: 64.2522\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29150504 -- Accuracy: 33.71710526\n",
      "\n",
      "Training:\n",
      "Epoch 415/5000 -- Batch 172/173 -- Loss: 0.03545543 -- Train accuracy: 63.6651\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30371132 -- Accuracy: 32.64802632\n",
      "\n",
      "Training:\n",
      "Epoch 416/5000 -- Batch 172/173 -- Loss: 0.04021666 -- Train accuracy: 64.0986\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30128263 -- Accuracy: 34.21052632\n",
      "\n",
      "Training:\n",
      "Epoch 417/5000 -- Batch 172/173 -- Loss: 0.06545982 -- Train accuracy: 63.7735\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29975199 -- Accuracy: 34.21052632\n",
      "\n",
      "Training:\n",
      "Epoch 418/5000 -- Batch 172/173 -- Loss: 0.04000146 -- Train accuracy: 64.6676\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30578780 -- Accuracy: 33.71710526\n",
      "\n",
      "Training:\n",
      "Epoch 419/5000 -- Batch 172/173 -- Loss: 0.03113287 -- Train accuracy: 63.6290\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29865451 -- Accuracy: 32.97697368\n",
      "\n",
      "Training:\n",
      "Epoch 420/5000 -- Batch 172/173 -- Loss: 0.04339344 -- Train accuracy: 63.6109\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28645854 -- Accuracy: 34.29276316\n",
      "\n",
      "Training:\n",
      "Epoch 421/5000 -- Batch 172/173 -- Loss: 0.02765562 -- Train accuracy: 63.7645\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30136535 -- Accuracy: 33.63486842\n",
      "\n",
      "Training:\n",
      "Epoch 422/5000 -- Batch 172/173 -- Loss: 0.02148237 -- Train accuracy: 64.9296\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.31576112 -- Accuracy: 33.71710526\n",
      "\n",
      "Training:\n",
      "Epoch 423/5000 -- Batch 172/173 -- Loss: 0.02001663 -- Train accuracy: 64.9657\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29612486 -- Accuracy: 35.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 424/5000 -- Batch 172/173 -- Loss: 0.01941605 -- Train accuracy: 64.9657\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28697092 -- Accuracy: 33.63486842\n",
      "\n",
      "Training:\n",
      "Epoch 425/5000 -- Batch 172/173 -- Loss: 0.03769161 -- Train accuracy: 64.8483\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28062266 -- Accuracy: 34.53947368\n",
      "\n",
      "Training:\n",
      "Epoch 426/5000 -- Batch 172/173 -- Loss: 0.04534093 -- Train accuracy: 64.5322\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29144684 -- Accuracy: 35.69078947\n",
      "\n",
      "Training:\n",
      "Epoch 427/5000 -- Batch 172/173 -- Loss: 0.03248074 -- Train accuracy: 64.8031\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30455501 -- Accuracy: 34.62171053\n",
      "\n",
      "Training:\n",
      "Epoch 428/5000 -- Batch 172/173 -- Loss: 0.03412421 -- Train accuracy: 63.9451\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29051982 -- Accuracy: 34.53947368\n",
      "\n",
      "Training:\n",
      "Epoch 429/5000 -- Batch 172/173 -- Loss: 0.03377634 -- Train accuracy: 64.9747\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28713844 -- Accuracy: 34.37500000\n",
      "\n",
      "Training:\n",
      "Epoch 430/5000 -- Batch 172/173 -- Loss: 0.03755298 -- Train accuracy: 63.8186\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30708816 -- Accuracy: 33.14144737\n",
      "\n",
      "Training:\n",
      "Epoch 431/5000 -- Batch 172/173 -- Loss: 0.02209627 -- Train accuracy: 66.3927\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30521749 -- Accuracy: 34.78618421\n",
      "\n",
      "Training:\n",
      "Epoch 432/5000 -- Batch 172/173 -- Loss: 0.04060928 -- Train accuracy: 64.8663\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28483472 -- Accuracy: 34.62171053\n",
      "\n",
      "Training:\n",
      "Epoch 433/5000 -- Batch 172/173 -- Loss: 0.01925739 -- Train accuracy: 65.8598\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27702298 -- Accuracy: 33.71710526\n",
      "\n",
      "Training:\n",
      "Epoch 434/5000 -- Batch 172/173 -- Loss: 0.04577384 -- Train accuracy: 65.9682\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29670014 -- Accuracy: 34.62171053\n",
      "\n",
      "Training:\n",
      "Epoch 435/5000 -- Batch 172/173 -- Loss: 0.02589816 -- Train accuracy: 64.7309\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30586850 -- Accuracy: 33.96381579\n",
      "\n",
      "Training:\n",
      "Epoch 436/5000 -- Batch 172/173 -- Loss: 0.04279692 -- Train accuracy: 65.8869\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30230487 -- Accuracy: 33.88157895\n",
      "\n",
      "Training:\n",
      "Epoch 437/5000 -- Batch 172/173 -- Loss: 0.02753002 -- Train accuracy: 65.6250\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28404505 -- Accuracy: 35.69078947\n",
      "\n",
      "Training:\n",
      "Epoch 438/5000 -- Batch 172/173 -- Loss: 0.02465420 -- Train accuracy: 65.7605\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30022728 -- Accuracy: 35.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 439/5000 -- Batch 172/173 -- Loss: 0.05654524 -- Train accuracy: 65.2095\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30493280 -- Accuracy: 35.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 440/5000 -- Batch 172/173 -- Loss: 0.02396486 -- Train accuracy: 65.8327\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30724337 -- Accuracy: 34.62171053\n",
      "\n",
      "Training:\n",
      "Epoch 441/5000 -- Batch 172/173 -- Loss: 0.02779850 -- Train accuracy: 65.6792\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28521048 -- Accuracy: 35.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 442/5000 -- Batch 172/173 -- Loss: 0.02719414 -- Train accuracy: 66.9617\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30632055 -- Accuracy: 34.04605263\n",
      "\n",
      "Training:\n",
      "Epoch 443/5000 -- Batch 172/173 -- Loss: 0.02759402 -- Train accuracy: 65.9953\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28193627 -- Accuracy: 35.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 444/5000 -- Batch 172/173 -- Loss: 0.01943738 -- Train accuracy: 67.1243\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29912144 -- Accuracy: 34.21052632\n",
      "\n",
      "Training:\n",
      "Epoch 445/5000 -- Batch 172/173 -- Loss: 0.05464537 -- Train accuracy: 65.6250\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29422042 -- Accuracy: 35.36184211\n",
      "\n",
      "Training:\n",
      "Epoch 446/5000 -- Batch 172/173 -- Loss: 0.03173670 -- Train accuracy: 65.3992\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27722287 -- Accuracy: 35.11513158\n",
      "\n",
      "Training:\n",
      "Epoch 447/5000 -- Batch 172/173 -- Loss: 0.04098860 -- Train accuracy: 66.0585\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29283976 -- Accuracy: 35.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 448/5000 -- Batch 172/173 -- Loss: 0.04363464 -- Train accuracy: 65.6792\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28527568 -- Accuracy: 35.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 449/5000 -- Batch 172/173 -- Loss: 0.06168340 -- Train accuracy: 66.6275\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28830671 -- Accuracy: 35.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 450/5000 -- Batch 172/173 -- Loss: 0.04020014 -- Train accuracy: 66.8714\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29316920 -- Accuracy: 34.62171053\n",
      "\n",
      "Training:\n",
      "Epoch 451/5000 -- Batch 172/173 -- Loss: 0.02876658 -- Train accuracy: 67.1965\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28454009 -- Accuracy: 34.78618421\n",
      "\n",
      "Training:\n",
      "Epoch 452/5000 -- Batch 172/173 -- Loss: 0.01868512 -- Train accuracy: 65.9863\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29132768 -- Accuracy: 35.60855263\n",
      "\n",
      "Training:\n",
      "Epoch 453/5000 -- Batch 172/173 -- Loss: 0.04839689 -- Train accuracy: 66.7720\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28543545 -- Accuracy: 35.44407895\n",
      "\n",
      "Training:\n",
      "Epoch 454/5000 -- Batch 172/173 -- Loss: 0.02805870 -- Train accuracy: 66.2482\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27368622 -- Accuracy: 35.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 455/5000 -- Batch 172/173 -- Loss: 0.03501710 -- Train accuracy: 67.2417\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28714092 -- Accuracy: 35.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 456/5000 -- Batch 172/173 -- Loss: 0.02650165 -- Train accuracy: 66.9978\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29065389 -- Accuracy: 35.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 457/5000 -- Batch 172/173 -- Loss: 0.02292155 -- Train accuracy: 67.3681\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29930030 -- Accuracy: 35.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 458/5000 -- Batch 172/173 -- Loss: 0.03703070 -- Train accuracy: 67.9281\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27914776 -- Accuracy: 35.44407895\n",
      "\n",
      "Training:\n",
      "Epoch 459/5000 -- Batch 172/173 -- Loss: 0.05617272 -- Train accuracy: 67.8197\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29753925 -- Accuracy: 36.01973684\n",
      "\n",
      "Training:\n",
      "Epoch 460/5000 -- Batch 172/173 -- Loss: 0.03509910 -- Train accuracy: 68.0275\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.30534174 -- Accuracy: 36.26644737\n",
      "\n",
      "Training:\n",
      "Epoch 461/5000 -- Batch 172/173 -- Loss: 0.02413400 -- Train accuracy: 67.9823\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28311130 -- Accuracy: 35.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 462/5000 -- Batch 172/173 -- Loss: 0.04595773 -- Train accuracy: 67.3320\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28897577 -- Accuracy: 36.10197368\n",
      "\n",
      "Training:\n",
      "Epoch 463/5000 -- Batch 172/173 -- Loss: 0.04347470 -- Train accuracy: 67.9462\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27062525 -- Accuracy: 35.77302632\n",
      "\n",
      "Training:\n",
      "Epoch 464/5000 -- Batch 172/173 -- Loss: 0.04722387 -- Train accuracy: 67.4043\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27451104 -- Accuracy: 35.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 465/5000 -- Batch 172/173 -- Loss: 0.03402694 -- Train accuracy: 68.3165\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27481079 -- Accuracy: 35.03289474\n",
      "\n",
      "Training:\n",
      "Epoch 466/5000 -- Batch 172/173 -- Loss: 0.02086966 -- Train accuracy: 67.7475\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27848633 -- Accuracy: 35.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 467/5000 -- Batch 172/173 -- Loss: 0.03192450 -- Train accuracy: 67.7475\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27582407 -- Accuracy: 36.18421053\n",
      "\n",
      "Training:\n",
      "Epoch 468/5000 -- Batch 172/173 -- Loss: 0.03582056 -- Train accuracy: 68.3797\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28014239 -- Accuracy: 36.84210526\n",
      "\n",
      "Training:\n",
      "Epoch 469/5000 -- Batch 172/173 -- Loss: 0.01796470 -- Train accuracy: 67.6933\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27022533 -- Accuracy: 36.75986842\n",
      "\n",
      "Training:\n",
      "Epoch 470/5000 -- Batch 172/173 -- Loss: 0.03151333 -- Train accuracy: 67.7475\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26379805 -- Accuracy: 36.92434211\n",
      "\n",
      "Training:\n",
      "Epoch 471/5000 -- Batch 172/173 -- Loss: 0.04257321 -- Train accuracy: 68.1900\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29631779 -- Accuracy: 36.67763158\n",
      "\n",
      "Training:\n",
      "Epoch 472/5000 -- Batch 172/173 -- Loss: 0.02999367 -- Train accuracy: 67.5036\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26740974 -- Accuracy: 36.43092105\n",
      "\n",
      "Training:\n",
      "Epoch 473/5000 -- Batch 172/173 -- Loss: 0.02391503 -- Train accuracy: 68.1810\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29457767 -- Accuracy: 36.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 474/5000 -- Batch 172/173 -- Loss: 0.02876418 -- Train accuracy: 68.0726\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27634530 -- Accuracy: 35.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 475/5000 -- Batch 172/173 -- Loss: 0.07496975 -- Train accuracy: 67.6933\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28150427 -- Accuracy: 36.34868421\n",
      "\n",
      "Training:\n",
      "Epoch 476/5000 -- Batch 172/173 -- Loss: 0.03546278 -- Train accuracy: 68.7139\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28546236 -- Accuracy: 36.43092105\n",
      "\n",
      "Training:\n",
      "Epoch 477/5000 -- Batch 172/173 -- Loss: 0.02987008 -- Train accuracy: 68.0094\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27838613 -- Accuracy: 37.82894737\n",
      "\n",
      "Training:\n",
      "Epoch 478/5000 -- Batch 172/173 -- Loss: 0.02782022 -- Train accuracy: 68.1810\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27028715 -- Accuracy: 36.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 479/5000 -- Batch 172/173 -- Loss: 0.04818942 -- Train accuracy: 68.9306\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28487529 -- Accuracy: 38.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 480/5000 -- Batch 172/173 -- Loss: 0.01378948 -- Train accuracy: 67.9642\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29201189 -- Accuracy: 36.01973684\n",
      "\n",
      "Training:\n",
      "Epoch 481/5000 -- Batch 172/173 -- Loss: 0.03427528 -- Train accuracy: 67.4765\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27783640 -- Accuracy: 36.84210526\n",
      "\n",
      "Training:\n",
      "Epoch 482/5000 -- Batch 172/173 -- Loss: 0.08979940 -- Train accuracy: 69.3009\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29852150 -- Accuracy: 36.26644737\n",
      "\n",
      "Training:\n",
      "Epoch 483/5000 -- Batch 172/173 -- Loss: 0.05103929 -- Train accuracy: 68.9035\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28268430 -- Accuracy: 36.10197368\n",
      "\n",
      "Training:\n",
      "Epoch 484/5000 -- Batch 172/173 -- Loss: 0.01899857 -- Train accuracy: 69.4725\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28398576 -- Accuracy: 37.82894737\n",
      "\n",
      "Training:\n",
      "Epoch 485/5000 -- Batch 172/173 -- Loss: 0.03756787 -- Train accuracy: 68.5694\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29416920 -- Accuracy: 37.74671053\n",
      "\n",
      "Training:\n",
      "Epoch 486/5000 -- Batch 172/173 -- Loss: 0.09371576 -- Train accuracy: 68.0365\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29629659 -- Accuracy: 37.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 487/5000 -- Batch 172/173 -- Loss: 0.04000957 -- Train accuracy: 69.9061\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27256487 -- Accuracy: 37.08881579\n",
      "\n",
      "Training:\n",
      "Epoch 488/5000 -- Batch 172/173 -- Loss: 0.03241345 -- Train accuracy: 69.2738\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27985964 -- Accuracy: 37.91118421\n",
      "\n",
      "Training:\n",
      "Epoch 489/5000 -- Batch 172/173 -- Loss: 0.06694710 -- Train accuracy: 68.9397\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28283339 -- Accuracy: 39.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 490/5000 -- Batch 172/173 -- Loss: 0.02841750 -- Train accuracy: 69.4635\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28565274 -- Accuracy: 37.82894737\n",
      "\n",
      "Training:\n",
      "Epoch 491/5000 -- Batch 172/173 -- Loss: 0.03677036 -- Train accuracy: 69.4003\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.29078815 -- Accuracy: 37.66447368\n",
      "\n",
      "Training:\n",
      "Epoch 492/5000 -- Batch 172/173 -- Loss: 0.04924012 -- Train accuracy: 69.7616\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28609682 -- Accuracy: 37.58223684\n",
      "\n",
      "Training:\n",
      "Epoch 493/5000 -- Batch 172/173 -- Loss: 0.03196955 -- Train accuracy: 69.5809\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28446703 -- Accuracy: 37.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 494/5000 -- Batch 172/173 -- Loss: 0.02649137 -- Train accuracy: 70.2673\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28437412 -- Accuracy: 38.48684211\n",
      "\n",
      "Training:\n",
      "Epoch 495/5000 -- Batch 172/173 -- Loss: 0.02464662 -- Train accuracy: 69.5719\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25934695 -- Accuracy: 38.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 496/5000 -- Batch 172/173 -- Loss: 0.02639913 -- Train accuracy: 67.7475\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26964013 -- Accuracy: 37.17105263\n",
      "\n",
      "Training:\n",
      "Epoch 497/5000 -- Batch 172/173 -- Loss: 0.02108547 -- Train accuracy: 70.2402\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27794706 -- Accuracy: 38.48684211\n",
      "\n",
      "Training:\n",
      "Epoch 498/5000 -- Batch 172/173 -- Loss: 0.02620792 -- Train accuracy: 69.8609\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26139573 -- Accuracy: 36.92434211\n",
      "\n",
      "Training:\n",
      "Epoch 499/5000 -- Batch 172/173 -- Loss: 0.02532965 -- Train accuracy: 68.9397\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26235068 -- Accuracy: 38.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 500/5000 -- Batch 172/173 -- Loss: 0.04860335 -- Train accuracy: 69.4003\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25986603 -- Accuracy: 38.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 501/5000 -- Batch 172/173 -- Loss: 0.04096659 -- Train accuracy: 69.3100\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25686529 -- Accuracy: 38.40460526\n",
      "\n",
      "Training:\n",
      "Epoch 502/5000 -- Batch 172/173 -- Loss: 0.03029017 -- Train accuracy: 69.9061\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27656484 -- Accuracy: 37.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 503/5000 -- Batch 172/173 -- Loss: 0.04581049 -- Train accuracy: 69.8338\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28527489 -- Accuracy: 37.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 504/5000 -- Batch 172/173 -- Loss: 0.02186575 -- Train accuracy: 70.3938\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27672146 -- Accuracy: 37.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 505/5000 -- Batch 172/173 -- Loss: 0.02627980 -- Train accuracy: 68.8403\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28348400 -- Accuracy: 37.25328947\n",
      "\n",
      "Training:\n",
      "Epoch 506/5000 -- Batch 172/173 -- Loss: 0.02341443 -- Train accuracy: 70.9718\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27381052 -- Accuracy: 38.65131579\n",
      "\n",
      "Training:\n",
      "Epoch 507/5000 -- Batch 172/173 -- Loss: 0.02555969 -- Train accuracy: 69.4635\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27299053 -- Accuracy: 38.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 508/5000 -- Batch 172/173 -- Loss: 0.02675040 -- Train accuracy: 70.6738\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26994682 -- Accuracy: 38.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 509/5000 -- Batch 172/173 -- Loss: 0.02847937 -- Train accuracy: 70.7189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24943289 -- Accuracy: 38.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 510/5000 -- Batch 172/173 -- Loss: 0.03063903 -- Train accuracy: 69.8248\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26272286 -- Accuracy: 38.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 511/5000 -- Batch 172/173 -- Loss: 0.01811064 -- Train accuracy: 70.4028\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27414096 -- Accuracy: 38.89802632\n",
      "\n",
      "Training:\n",
      "Epoch 512/5000 -- Batch 172/173 -- Loss: 0.02510657 -- Train accuracy: 70.0957\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27453608 -- Accuracy: 38.15789474\n",
      "\n",
      "Training:\n",
      "Epoch 513/5000 -- Batch 172/173 -- Loss: 0.02863770 -- Train accuracy: 70.4028\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26611611 -- Accuracy: 37.91118421\n",
      "\n",
      "Training:\n",
      "Epoch 514/5000 -- Batch 172/173 -- Loss: 0.01450662 -- Train accuracy: 69.6532\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28100112 -- Accuracy: 38.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 515/5000 -- Batch 172/173 -- Loss: 0.02355029 -- Train accuracy: 70.8183\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27595590 -- Accuracy: 38.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 516/5000 -- Batch 172/173 -- Loss: 0.01923594 -- Train accuracy: 70.8544\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/19 -- Loss: 0.27573293 -- Accuracy: 38.15789474\n",
      "\n",
      "Training:\n",
      "Epoch 517/5000 -- Batch 172/173 -- Loss: 0.03362174 -- Train accuracy: 71.1163\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27055946 -- Accuracy: 38.65131579\n",
      "\n",
      "Training:\n",
      "Epoch 518/5000 -- Batch 172/173 -- Loss: 0.02166409 -- Train accuracy: 70.9357\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28547142 -- Accuracy: 38.40460526\n",
      "\n",
      "Training:\n",
      "Epoch 519/5000 -- Batch 172/173 -- Loss: 0.04611391 -- Train accuracy: 69.9783\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26630052 -- Accuracy: 39.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 520/5000 -- Batch 172/173 -- Loss: 0.04507759 -- Train accuracy: 70.5112\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26740048 -- Accuracy: 38.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 521/5000 -- Batch 172/173 -- Loss: 0.03822187 -- Train accuracy: 71.7937\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28055256 -- Accuracy: 39.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 522/5000 -- Batch 172/173 -- Loss: 0.02952443 -- Train accuracy: 70.0415\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28871703 -- Accuracy: 39.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 523/5000 -- Batch 172/173 -- Loss: 0.03326451 -- Train accuracy: 69.7345\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26268564 -- Accuracy: 38.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 524/5000 -- Batch 172/173 -- Loss: 0.04791550 -- Train accuracy: 70.8815\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25672866 -- Accuracy: 38.40460526\n",
      "\n",
      "Training:\n",
      "Epoch 525/5000 -- Batch 172/173 -- Loss: 0.03613025 -- Train accuracy: 70.5293\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25332529 -- Accuracy: 38.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 526/5000 -- Batch 172/173 -- Loss: 0.04707361 -- Train accuracy: 71.0079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26997779 -- Accuracy: 38.40460526\n",
      "\n",
      "Training:\n",
      "Epoch 527/5000 -- Batch 172/173 -- Loss: 0.03997965 -- Train accuracy: 72.2001\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28088780 -- Accuracy: 39.30921053\n",
      "\n",
      "Training:\n",
      "Epoch 528/5000 -- Batch 172/173 -- Loss: 0.02516110 -- Train accuracy: 71.3150\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27714950 -- Accuracy: 39.22697368\n",
      "\n",
      "Training:\n",
      "Epoch 529/5000 -- Batch 172/173 -- Loss: 0.02384130 -- Train accuracy: 71.0802\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28113206 -- Accuracy: 39.39144737\n",
      "\n",
      "Training:\n",
      "Epoch 530/5000 -- Batch 172/173 -- Loss: 0.02027960 -- Train accuracy: 71.4234\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28329948 -- Accuracy: 38.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 531/5000 -- Batch 172/173 -- Loss: 0.01817087 -- Train accuracy: 71.9382\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28621014 -- Accuracy: 38.65131579\n",
      "\n",
      "Training:\n",
      "Epoch 532/5000 -- Batch 172/173 -- Loss: 0.04857292 -- Train accuracy: 70.8905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28845912 -- Accuracy: 38.65131579\n",
      "\n",
      "Training:\n",
      "Epoch 533/5000 -- Batch 172/173 -- Loss: 0.01774823 -- Train accuracy: 71.9743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27696231 -- Accuracy: 39.63815789\n",
      "\n",
      "Training:\n",
      "Epoch 534/5000 -- Batch 172/173 -- Loss: 0.01663154 -- Train accuracy: 71.1976\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28098533 -- Accuracy: 38.40460526\n",
      "\n",
      "Training:\n",
      "Epoch 535/5000 -- Batch 172/173 -- Loss: 0.05603931 -- Train accuracy: 72.3537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27117781 -- Accuracy: 39.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 536/5000 -- Batch 172/173 -- Loss: 0.01777488 -- Train accuracy: 72.4169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28205247 -- Accuracy: 40.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 537/5000 -- Batch 172/173 -- Loss: 0.03554736 -- Train accuracy: 71.5589\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25838022 -- Accuracy: 38.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 538/5000 -- Batch 172/173 -- Loss: 0.02201664 -- Train accuracy: 71.6221\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28399277 -- Accuracy: 38.89802632\n",
      "\n",
      "Training:\n",
      "Epoch 539/5000 -- Batch 172/173 -- Loss: 0.03953085 -- Train accuracy: 71.4866\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27842812 -- Accuracy: 38.65131579\n",
      "\n",
      "Training:\n",
      "Epoch 540/5000 -- Batch 172/173 -- Loss: 0.03434660 -- Train accuracy: 72.4711\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.28198769 -- Accuracy: 38.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 541/5000 -- Batch 172/173 -- Loss: 0.02656309 -- Train accuracy: 71.7757\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27510686 -- Accuracy: 39.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 542/5000 -- Batch 172/173 -- Loss: 0.03947207 -- Train accuracy: 72.5704\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27912732 -- Accuracy: 38.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 543/5000 -- Batch 172/173 -- Loss: 0.01980146 -- Train accuracy: 72.2092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27560767 -- Accuracy: 38.89802632\n",
      "\n",
      "Training:\n",
      "Epoch 544/5000 -- Batch 172/173 -- Loss: 0.04889737 -- Train accuracy: 72.5795\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25844914 -- Accuracy: 39.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 545/5000 -- Batch 172/173 -- Loss: 0.02212674 -- Train accuracy: 72.3717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27654317 -- Accuracy: 38.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 546/5000 -- Batch 172/173 -- Loss: 0.01591562 -- Train accuracy: 72.3085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24739343 -- Accuracy: 39.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 547/5000 -- Batch 172/173 -- Loss: 0.03539685 -- Train accuracy: 72.4440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26918850 -- Accuracy: 39.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 548/5000 -- Batch 172/173 -- Loss: 0.04078658 -- Train accuracy: 72.0918\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24788605 -- Accuracy: 39.47368421\n",
      "\n",
      "Training:\n",
      "Epoch 549/5000 -- Batch 172/173 -- Loss: 0.02703456 -- Train accuracy: 72.4259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.27835166 -- Accuracy: 39.47368421\n",
      "\n",
      "Training:\n",
      "Epoch 550/5000 -- Batch 172/173 -- Loss: 0.07250130 -- Train accuracy: 72.7962\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25987608 -- Accuracy: 40.21381579\n",
      "\n",
      "Training:\n",
      "Epoch 551/5000 -- Batch 172/173 -- Loss: 0.04436098 -- Train accuracy: 72.2543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25489873 -- Accuracy: 39.22697368\n",
      "\n",
      "Training:\n",
      "Epoch 552/5000 -- Batch 172/173 -- Loss: 0.04324770 -- Train accuracy: 72.3627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25243522 -- Accuracy: 39.39144737\n",
      "\n",
      "Training:\n",
      "Epoch 553/5000 -- Batch 172/173 -- Loss: 0.01664806 -- Train accuracy: 72.3898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25841225 -- Accuracy: 40.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 554/5000 -- Batch 172/173 -- Loss: 0.03861405 -- Train accuracy: 73.1033\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25426621 -- Accuracy: 40.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 555/5000 -- Batch 172/173 -- Loss: 0.05809507 -- Train accuracy: 72.6969\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25781025 -- Accuracy: 39.72039474\n",
      "\n",
      "Training:\n",
      "Epoch 556/5000 -- Batch 172/173 -- Loss: 0.04305525 -- Train accuracy: 73.3111\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26576517 -- Accuracy: 39.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 557/5000 -- Batch 172/173 -- Loss: 0.02202358 -- Train accuracy: 73.1124\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25047311 -- Accuracy: 40.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 558/5000 -- Batch 172/173 -- Loss: 0.02379982 -- Train accuracy: 72.9046\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26175199 -- Accuracy: 39.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 559/5000 -- Batch 172/173 -- Loss: 0.05462418 -- Train accuracy: 72.6156\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26775551 -- Accuracy: 39.63815789\n",
      "\n",
      "Training:\n",
      "Epoch 560/5000 -- Batch 172/173 -- Loss: 0.02916901 -- Train accuracy: 72.9588\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25100549 -- Accuracy: 39.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 561/5000 -- Batch 172/173 -- Loss: 0.03784869 -- Train accuracy: 72.9408\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25447785 -- Accuracy: 39.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 562/5000 -- Batch 172/173 -- Loss: 0.02639615 -- Train accuracy: 73.6543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25193316 -- Accuracy: 41.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 563/5000 -- Batch 172/173 -- Loss: 0.02990404 -- Train accuracy: 73.3562\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24311755 -- Accuracy: 41.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 564/5000 -- Batch 172/173 -- Loss: 0.04854855 -- Train accuracy: 73.3743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24345064 -- Accuracy: 41.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 565/5000 -- Batch 172/173 -- Loss: 0.02728823 -- Train accuracy: 72.2092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23835837 -- Accuracy: 39.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 566/5000 -- Batch 172/173 -- Loss: 0.03912783 -- Train accuracy: 72.8414\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25630115 -- Accuracy: 41.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 567/5000 -- Batch 172/173 -- Loss: 0.08140732 -- Train accuracy: 73.3833\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26906453 -- Accuracy: 40.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 568/5000 -- Batch 172/173 -- Loss: 0.04510096 -- Train accuracy: 73.7265\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26152269 -- Accuracy: 40.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 569/5000 -- Batch 172/173 -- Loss: 0.01690213 -- Train accuracy: 73.8078\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26783272 -- Accuracy: 39.63815789\n",
      "\n",
      "Training:\n",
      "Epoch 570/5000 -- Batch 172/173 -- Loss: 0.05125492 -- Train accuracy: 73.0130\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25245324 -- Accuracy: 40.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 571/5000 -- Batch 172/173 -- Loss: 0.02025654 -- Train accuracy: 73.1936\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24632961 -- Accuracy: 41.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 572/5000 -- Batch 172/173 -- Loss: 0.02714840 -- Train accuracy: 73.1214\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24891866 -- Accuracy: 40.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 573/5000 -- Batch 172/173 -- Loss: 0.06552338 -- Train accuracy: 74.1329\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25004314 -- Accuracy: 40.70723684\n",
      "\n",
      "Training:\n",
      "Epoch 574/5000 -- Batch 172/173 -- Loss: 0.02821446 -- Train accuracy: 73.7085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25260769 -- Accuracy: 40.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 575/5000 -- Batch 172/173 -- Loss: 0.05064386 -- Train accuracy: 74.1329\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24479982 -- Accuracy: 41.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 576/5000 -- Batch 172/173 -- Loss: 0.01870107 -- Train accuracy: 72.7691\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25060060 -- Accuracy: 41.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 577/5000 -- Batch 172/173 -- Loss: 0.02050350 -- Train accuracy: 74.1420\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26463460 -- Accuracy: 40.54276316\n",
      "\n",
      "Training:\n",
      "Epoch 578/5000 -- Batch 172/173 -- Loss: 0.01330520 -- Train accuracy: 74.7110\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25796958 -- Accuracy: 41.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 579/5000 -- Batch 172/173 -- Loss: 0.06276020 -- Train accuracy: 73.1485\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24204878 -- Accuracy: 41.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 580/5000 -- Batch 172/173 -- Loss: 0.03142841 -- Train accuracy: 73.9342\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25976148 -- Accuracy: 40.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 581/5000 -- Batch 172/173 -- Loss: 0.04421892 -- Train accuracy: 74.6297\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24881746 -- Accuracy: 41.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 582/5000 -- Batch 172/173 -- Loss: 0.01759574 -- Train accuracy: 73.1485\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23649356 -- Accuracy: 39.47368421\n",
      "\n",
      "Training:\n",
      "Epoch 583/5000 -- Batch 172/173 -- Loss: 0.01739513 -- Train accuracy: 74.1600\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25036406 -- Accuracy: 40.54276316\n",
      "\n",
      "Training:\n",
      "Epoch 584/5000 -- Batch 172/173 -- Loss: 0.02547623 -- Train accuracy: 74.6116\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24771054 -- Accuracy: 41.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 585/5000 -- Batch 172/173 -- Loss: 0.01591639 -- Train accuracy: 74.6116\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26541020 -- Accuracy: 40.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 586/5000 -- Batch 172/173 -- Loss: 0.02581803 -- Train accuracy: 73.8530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25149411 -- Accuracy: 41.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 587/5000 -- Batch 172/173 -- Loss: 0.02245042 -- Train accuracy: 73.1214\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24000089 -- Accuracy: 40.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 588/5000 -- Batch 172/173 -- Loss: 0.04993670 -- Train accuracy: 75.2168\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24913602 -- Accuracy: 41.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 589/5000 -- Batch 172/173 -- Loss: 0.05048215 -- Train accuracy: 73.8891\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23800344 -- Accuracy: 41.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 590/5000 -- Batch 172/173 -- Loss: 0.02835321 -- Train accuracy: 73.9072\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24070303 -- Accuracy: 40.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 591/5000 -- Batch 172/173 -- Loss: 0.01016237 -- Train accuracy: 74.8465\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26069070 -- Accuracy: 41.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 592/5000 -- Batch 172/173 -- Loss: 0.03145039 -- Train accuracy: 74.4762\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24393245 -- Accuracy: 40.54276316\n",
      "\n",
      "Training:\n",
      "Epoch 593/5000 -- Batch 172/173 -- Loss: 0.01486081 -- Train accuracy: 75.2890\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24997132 -- Accuracy: 41.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 594/5000 -- Batch 172/173 -- Loss: 0.03341155 -- Train accuracy: 74.6297\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26494899 -- Accuracy: 41.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 595/5000 -- Batch 172/173 -- Loss: 0.02557960 -- Train accuracy: 74.9097\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24930388 -- Accuracy: 41.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 596/5000 -- Batch 172/173 -- Loss: 0.01896771 -- Train accuracy: 75.0542\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24579804 -- Accuracy: 40.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 597/5000 -- Batch 172/173 -- Loss: 0.02485321 -- Train accuracy: 74.9548\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24017005 -- Accuracy: 40.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 598/5000 -- Batch 172/173 -- Loss: 0.01720947 -- Train accuracy: 75.0271\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26196581 -- Accuracy: 41.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 599/5000 -- Batch 172/173 -- Loss: 0.02225830 -- Train accuracy: 74.6568\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26739672 -- Accuracy: 40.54276316\n",
      "\n",
      "Training:\n",
      "Epoch 600/5000 -- Batch 172/173 -- Loss: 0.01975708 -- Train accuracy: 75.0632\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26122606 -- Accuracy: 40.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 601/5000 -- Batch 172/173 -- Loss: 0.00810939 -- Train accuracy: 74.0878\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26862540 -- Accuracy: 40.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 602/5000 -- Batch 172/173 -- Loss: 0.03465112 -- Train accuracy: 75.0452\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25300630 -- Accuracy: 41.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 603/5000 -- Batch 172/173 -- Loss: 0.01499236 -- Train accuracy: 75.5871\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25806355 -- Accuracy: 41.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 604/5000 -- Batch 172/173 -- Loss: 0.03795948 -- Train accuracy: 74.6207\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25304792 -- Accuracy: 41.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 605/5000 -- Batch 172/173 -- Loss: 0.02479807 -- Train accuracy: 75.4245\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25248169 -- Accuracy: 42.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 606/5000 -- Batch 172/173 -- Loss: 0.02759532 -- Train accuracy: 75.1626\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25065560 -- Accuracy: 42.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 607/5000 -- Batch 172/173 -- Loss: 0.01540020 -- Train accuracy: 75.7948\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25526652 -- Accuracy: 42.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 608/5000 -- Batch 172/173 -- Loss: 0.05020982 -- Train accuracy: 74.1239\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23606425 -- Accuracy: 42.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 609/5000 -- Batch 172/173 -- Loss: 0.01893655 -- Train accuracy: 74.9097\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24400594 -- Accuracy: 41.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 610/5000 -- Batch 172/173 -- Loss: 0.04408345 -- Train accuracy: 75.4155\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24372361 -- Accuracy: 42.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 611/5000 -- Batch 172/173 -- Loss: 0.02528370 -- Train accuracy: 74.9548\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25681675 -- Accuracy: 41.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 612/5000 -- Batch 172/173 -- Loss: 0.02891961 -- Train accuracy: 75.5148\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25743694 -- Accuracy: 42.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 613/5000 -- Batch 172/173 -- Loss: 0.02147630 -- Train accuracy: 75.7677\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25232580 -- Accuracy: 41.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 614/5000 -- Batch 172/173 -- Loss: 0.02630762 -- Train accuracy: 75.2348\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25444725 -- Accuracy: 41.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 615/5000 -- Batch 172/173 -- Loss: 0.02265886 -- Train accuracy: 75.5871\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24640949 -- Accuracy: 41.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 616/5000 -- Batch 172/173 -- Loss: 0.04154431 -- Train accuracy: 74.9458\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23452290 -- Accuracy: 42.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 617/5000 -- Batch 172/173 -- Loss: 0.03632634 -- Train accuracy: 75.4155\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25396458 -- Accuracy: 42.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 618/5000 -- Batch 172/173 -- Loss: 0.05223464 -- Train accuracy: 75.3342\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24316718 -- Accuracy: 42.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 619/5000 -- Batch 172/173 -- Loss: 0.01637392 -- Train accuracy: 76.0567\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/19 -- Loss: 0.25662767 -- Accuracy: 42.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 620/5000 -- Batch 172/173 -- Loss: 0.02429210 -- Train accuracy: 75.8761\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24244539 -- Accuracy: 42.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 621/5000 -- Batch 172/173 -- Loss: 0.01732573 -- Train accuracy: 76.3638\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25971640 -- Accuracy: 43.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 622/5000 -- Batch 172/173 -- Loss: 0.02532968 -- Train accuracy: 75.9845\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25273781 -- Accuracy: 43.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 623/5000 -- Batch 172/173 -- Loss: 0.01955775 -- Train accuracy: 75.4697\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24227342 -- Accuracy: 42.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 624/5000 -- Batch 172/173 -- Loss: 0.03786464 -- Train accuracy: 76.2825\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25531753 -- Accuracy: 42.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 625/5000 -- Batch 172/173 -- Loss: 0.03873438 -- Train accuracy: 75.7948\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25896370 -- Accuracy: 42.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 626/5000 -- Batch 172/173 -- Loss: 0.03520625 -- Train accuracy: 75.5329\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23416805 -- Accuracy: 42.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 627/5000 -- Batch 172/173 -- Loss: 0.01902897 -- Train accuracy: 76.0025\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25124846 -- Accuracy: 42.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 628/5000 -- Batch 172/173 -- Loss: 0.00830142 -- Train accuracy: 76.1922\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24664252 -- Accuracy: 42.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 629/5000 -- Batch 172/173 -- Loss: 0.02744938 -- Train accuracy: 76.3999\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25187163 -- Accuracy: 42.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 630/5000 -- Batch 172/173 -- Loss: 0.04429804 -- Train accuracy: 76.5625\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25806485 -- Accuracy: 42.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 631/5000 -- Batch 172/173 -- Loss: 0.02572052 -- Train accuracy: 76.4812\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25143652 -- Accuracy: 43.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 632/5000 -- Batch 172/173 -- Loss: 0.02993544 -- Train accuracy: 76.3006\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23857724 -- Accuracy: 43.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 633/5000 -- Batch 172/173 -- Loss: 0.01740317 -- Train accuracy: 76.3006\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25641070 -- Accuracy: 42.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 634/5000 -- Batch 172/173 -- Loss: 0.03251051 -- Train accuracy: 76.7522\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25085414 -- Accuracy: 42.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 635/5000 -- Batch 172/173 -- Loss: 0.01690239 -- Train accuracy: 76.6438\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24337981 -- Accuracy: 42.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 636/5000 -- Batch 172/173 -- Loss: 0.04011364 -- Train accuracy: 76.2103\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23637455 -- Accuracy: 43.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 637/5000 -- Batch 172/173 -- Loss: 0.01741954 -- Train accuracy: 75.9393\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24797980 -- Accuracy: 42.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 638/5000 -- Batch 172/173 -- Loss: 0.01905752 -- Train accuracy: 76.9328\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23832510 -- Accuracy: 42.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 639/5000 -- Batch 172/173 -- Loss: 0.02413047 -- Train accuracy: 76.6257\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23695458 -- Accuracy: 43.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 640/5000 -- Batch 172/173 -- Loss: 0.03757902 -- Train accuracy: 75.9122\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23110392 -- Accuracy: 43.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 641/5000 -- Batch 172/173 -- Loss: 0.03067740 -- Train accuracy: 76.4180\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24428073 -- Accuracy: 42.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 642/5000 -- Batch 172/173 -- Loss: 0.04626655 -- Train accuracy: 77.0231\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25211178 -- Accuracy: 42.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 643/5000 -- Batch 172/173 -- Loss: 0.03683563 -- Train accuracy: 76.9780\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23853996 -- Accuracy: 42.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 644/5000 -- Batch 172/173 -- Loss: 0.02880880 -- Train accuracy: 76.7251\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24538244 -- Accuracy: 42.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 645/5000 -- Batch 172/173 -- Loss: 0.04033041 -- Train accuracy: 77.6283\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24532518 -- Accuracy: 42.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 646/5000 -- Batch 172/173 -- Loss: 0.03087602 -- Train accuracy: 77.1134\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.26120944 -- Accuracy: 42.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 647/5000 -- Batch 172/173 -- Loss: 0.01672577 -- Train accuracy: 77.3844\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24488730 -- Accuracy: 42.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 648/5000 -- Batch 172/173 -- Loss: 0.01442675 -- Train accuracy: 77.2489\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24294963 -- Accuracy: 43.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 649/5000 -- Batch 172/173 -- Loss: 0.02357134 -- Train accuracy: 77.3031\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24874340 -- Accuracy: 43.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 650/5000 -- Batch 172/173 -- Loss: 0.02319219 -- Train accuracy: 77.3212\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24584175 -- Accuracy: 43.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 651/5000 -- Batch 172/173 -- Loss: 0.01294943 -- Train accuracy: 77.1767\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24645487 -- Accuracy: 43.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 652/5000 -- Batch 172/173 -- Loss: 0.02618779 -- Train accuracy: 76.7341\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24876071 -- Accuracy: 43.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 653/5000 -- Batch 172/173 -- Loss: 0.00810637 -- Train accuracy: 76.6167\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23850496 -- Accuracy: 43.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 654/5000 -- Batch 172/173 -- Loss: 0.01068134 -- Train accuracy: 76.4722\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24532417 -- Accuracy: 42.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 655/5000 -- Batch 172/173 -- Loss: 0.02773799 -- Train accuracy: 76.4270\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24516268 -- Accuracy: 43.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 656/5000 -- Batch 172/173 -- Loss: 0.03192878 -- Train accuracy: 76.7341\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24540848 -- Accuracy: 42.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 657/5000 -- Batch 172/173 -- Loss: 0.04540076 -- Train accuracy: 76.7070\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25335479 -- Accuracy: 42.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 658/5000 -- Batch 172/173 -- Loss: 0.02243522 -- Train accuracy: 77.1857\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23989302 -- Accuracy: 43.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 659/5000 -- Batch 172/173 -- Loss: 0.12096764 -- Train accuracy: 77.3663\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23591809 -- Accuracy: 43.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 660/5000 -- Batch 172/173 -- Loss: 0.01641195 -- Train accuracy: 77.6644\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25070333 -- Accuracy: 43.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 661/5000 -- Batch 172/173 -- Loss: 0.01244838 -- Train accuracy: 77.5741\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23992686 -- Accuracy: 43.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 662/5000 -- Batch 172/173 -- Loss: 0.02589257 -- Train accuracy: 77.6644\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24798795 -- Accuracy: 43.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 663/5000 -- Batch 172/173 -- Loss: 0.02891313 -- Train accuracy: 76.4090\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23149756 -- Accuracy: 43.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 664/5000 -- Batch 172/173 -- Loss: 0.03055059 -- Train accuracy: 77.0863\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24506159 -- Accuracy: 43.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 665/5000 -- Batch 172/173 -- Loss: 0.01261613 -- Train accuracy: 77.7818\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24968594 -- Accuracy: 43.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 666/5000 -- Batch 172/173 -- Loss: 0.04284721 -- Train accuracy: 78.1431\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23150830 -- Accuracy: 42.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 667/5000 -- Batch 172/173 -- Loss: 0.02542078 -- Train accuracy: 78.0347\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23210268 -- Accuracy: 43.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 668/5000 -- Batch 172/173 -- Loss: 0.03691954 -- Train accuracy: 76.9599\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23103195 -- Accuracy: 44.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 669/5000 -- Batch 172/173 -- Loss: 0.01436764 -- Train accuracy: 76.6438\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23884856 -- Accuracy: 44.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 670/5000 -- Batch 172/173 -- Loss: 0.03048117 -- Train accuracy: 76.9418\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24544620 -- Accuracy: 44.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 671/5000 -- Batch 172/173 -- Loss: 0.01807706 -- Train accuracy: 77.1857\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23696475 -- Accuracy: 43.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 672/5000 -- Batch 172/173 -- Loss: 0.02831360 -- Train accuracy: 77.7186\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23857070 -- Accuracy: 44.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 673/5000 -- Batch 172/173 -- Loss: 0.01652009 -- Train accuracy: 77.7366\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24653116 -- Accuracy: 44.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 674/5000 -- Batch 172/173 -- Loss: 0.02240285 -- Train accuracy: 77.6463\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24173887 -- Accuracy: 43.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 675/5000 -- Batch 172/173 -- Loss: 0.01829063 -- Train accuracy: 76.9870\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23150214 -- Accuracy: 43.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 676/5000 -- Batch 172/173 -- Loss: 0.02810694 -- Train accuracy: 77.8089\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22354294 -- Accuracy: 44.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 677/5000 -- Batch 172/173 -- Loss: 0.02855993 -- Train accuracy: 77.7637\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23890926 -- Accuracy: 44.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 678/5000 -- Batch 172/173 -- Loss: 0.05092200 -- Train accuracy: 78.0889\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23333726 -- Accuracy: 44.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 679/5000 -- Batch 172/173 -- Loss: 0.02281513 -- Train accuracy: 78.4050\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23898731 -- Accuracy: 44.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 680/5000 -- Batch 172/173 -- Loss: 0.03671853 -- Train accuracy: 77.2670\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22787395 -- Accuracy: 44.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 681/5000 -- Batch 172/173 -- Loss: 0.04660906 -- Train accuracy: 77.5650\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23539177 -- Accuracy: 43.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 682/5000 -- Batch 172/173 -- Loss: 0.02237454 -- Train accuracy: 78.0166\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24060750 -- Accuracy: 44.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 683/5000 -- Batch 172/173 -- Loss: 0.02183923 -- Train accuracy: 77.7366\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24108806 -- Accuracy: 44.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 684/5000 -- Batch 172/173 -- Loss: 0.02514981 -- Train accuracy: 78.0437\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23227058 -- Accuracy: 43.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 685/5000 -- Batch 172/173 -- Loss: 0.02470865 -- Train accuracy: 78.2966\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24078141 -- Accuracy: 43.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 686/5000 -- Batch 172/173 -- Loss: 0.02100737 -- Train accuracy: 79.0101\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23246216 -- Accuracy: 44.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 687/5000 -- Batch 172/173 -- Loss: 0.01987314 -- Train accuracy: 77.8992\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23999473 -- Accuracy: 44.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 688/5000 -- Batch 172/173 -- Loss: 0.02652007 -- Train accuracy: 78.0979\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23733115 -- Accuracy: 44.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 689/5000 -- Batch 172/173 -- Loss: 0.01355667 -- Train accuracy: 78.5224\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23023288 -- Accuracy: 43.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 690/5000 -- Batch 172/173 -- Loss: 0.00824583 -- Train accuracy: 78.4140\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23332096 -- Accuracy: 44.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 691/5000 -- Batch 172/173 -- Loss: 0.03043015 -- Train accuracy: 78.7301\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23671876 -- Accuracy: 44.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 692/5000 -- Batch 172/173 -- Loss: 0.04360776 -- Train accuracy: 78.5676\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23480053 -- Accuracy: 44.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 693/5000 -- Batch 172/173 -- Loss: 0.04138228 -- Train accuracy: 78.2876\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23922138 -- Accuracy: 44.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 694/5000 -- Batch 172/173 -- Loss: 0.03948940 -- Train accuracy: 78.1792\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23058251 -- Accuracy: 44.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 695/5000 -- Batch 172/173 -- Loss: 0.03267111 -- Train accuracy: 78.1340\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22373409 -- Accuracy: 44.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 696/5000 -- Batch 172/173 -- Loss: 0.03045383 -- Train accuracy: 78.6037\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23009970 -- Accuracy: 44.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 697/5000 -- Batch 172/173 -- Loss: 0.03281260 -- Train accuracy: 78.4772\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23694085 -- Accuracy: 45.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 698/5000 -- Batch 172/173 -- Loss: 0.01466997 -- Train accuracy: 78.7572\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23562211 -- Accuracy: 44.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 699/5000 -- Batch 172/173 -- Loss: 0.00925668 -- Train accuracy: 78.1521\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23230267 -- Accuracy: 43.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 700/5000 -- Batch 172/173 -- Loss: 0.13034880 -- Train accuracy: 78.6217\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23893049 -- Accuracy: 44.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 701/5000 -- Batch 172/173 -- Loss: 0.02531190 -- Train accuracy: 77.6553\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24300668 -- Accuracy: 44.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 702/5000 -- Batch 172/173 -- Loss: 0.03652053 -- Train accuracy: 78.4230\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.25100218 -- Accuracy: 44.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 703/5000 -- Batch 172/173 -- Loss: 0.04614327 -- Train accuracy: 77.8721\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23402273 -- Accuracy: 44.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 704/5000 -- Batch 172/173 -- Loss: 0.01055283 -- Train accuracy: 79.1817\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24381994 -- Accuracy: 44.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 705/5000 -- Batch 172/173 -- Loss: 0.01806446 -- Train accuracy: 78.4863\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22290186 -- Accuracy: 45.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 706/5000 -- Batch 172/173 -- Loss: 0.03001125 -- Train accuracy: 77.9534\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23287762 -- Accuracy: 44.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 707/5000 -- Batch 172/173 -- Loss: 0.02538967 -- Train accuracy: 78.6579\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22996012 -- Accuracy: 45.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 708/5000 -- Batch 172/173 -- Loss: 0.01796522 -- Train accuracy: 78.7392\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22834561 -- Accuracy: 44.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 709/5000 -- Batch 172/173 -- Loss: 0.11925794 -- Train accuracy: 78.7482\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23215094 -- Accuracy: 44.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 710/5000 -- Batch 172/173 -- Loss: 0.02263720 -- Train accuracy: 78.5947\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21220955 -- Accuracy: 44.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 711/5000 -- Batch 172/173 -- Loss: 0.01754951 -- Train accuracy: 79.1275\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22450905 -- Accuracy: 44.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 712/5000 -- Batch 172/173 -- Loss: 0.00904083 -- Train accuracy: 78.1973\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23238989 -- Accuracy: 44.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 713/5000 -- Batch 172/173 -- Loss: 0.02233360 -- Train accuracy: 79.1456\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23127504 -- Accuracy: 44.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 714/5000 -- Batch 172/173 -- Loss: 0.01271676 -- Train accuracy: 78.5856\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22464066 -- Accuracy: 44.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 715/5000 -- Batch 172/173 -- Loss: 0.02231320 -- Train accuracy: 78.6308\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22874212 -- Accuracy: 44.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 716/5000 -- Batch 172/173 -- Loss: 0.02678048 -- Train accuracy: 78.9198\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22256184 -- Accuracy: 45.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 717/5000 -- Batch 172/173 -- Loss: 0.03323985 -- Train accuracy: 79.3262\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22066718 -- Accuracy: 44.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 718/5000 -- Batch 172/173 -- Loss: 0.05082593 -- Train accuracy: 78.5314\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20509321 -- Accuracy: 44.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 719/5000 -- Batch 172/173 -- Loss: 0.03242402 -- Train accuracy: 78.9017\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21176351 -- Accuracy: 44.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 720/5000 -- Batch 172/173 -- Loss: 0.03335308 -- Train accuracy: 79.5882\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23908448 -- Accuracy: 45.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 721/5000 -- Batch 172/173 -- Loss: 0.03675352 -- Train accuracy: 79.1908\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23440333 -- Accuracy: 45.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 722/5000 -- Batch 172/173 -- Loss: 0.01489885 -- Train accuracy: 79.3172\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/19 -- Loss: 0.22955289 -- Accuracy: 44.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 723/5000 -- Batch 172/173 -- Loss: 0.03590948 -- Train accuracy: 78.9469\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22592831 -- Accuracy: 44.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 724/5000 -- Batch 172/173 -- Loss: 0.02605992 -- Train accuracy: 79.5249\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22290304 -- Accuracy: 45.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 725/5000 -- Batch 172/173 -- Loss: 0.02621976 -- Train accuracy: 79.4617\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22933403 -- Accuracy: 44.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 726/5000 -- Batch 172/173 -- Loss: 0.02840387 -- Train accuracy: 79.0011\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21413119 -- Accuracy: 45.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 727/5000 -- Batch 172/173 -- Loss: 0.02637303 -- Train accuracy: 79.5611\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22687341 -- Accuracy: 46.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 728/5000 -- Batch 172/173 -- Loss: 0.00783997 -- Train accuracy: 79.2269\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23527864 -- Accuracy: 45.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 729/5000 -- Batch 172/173 -- Loss: 0.02461096 -- Train accuracy: 79.0733\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23178901 -- Accuracy: 45.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 730/5000 -- Batch 172/173 -- Loss: 0.03206605 -- Train accuracy: 79.1275\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22265539 -- Accuracy: 45.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 731/5000 -- Batch 172/173 -- Loss: 0.02719435 -- Train accuracy: 79.6965\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.24053847 -- Accuracy: 44.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 732/5000 -- Batch 172/173 -- Loss: 0.02553980 -- Train accuracy: 79.6333\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23186635 -- Accuracy: 45.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 733/5000 -- Batch 172/173 -- Loss: 0.02748088 -- Train accuracy: 79.3714\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23363972 -- Accuracy: 45.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 734/5000 -- Batch 172/173 -- Loss: 0.01474578 -- Train accuracy: 79.3624\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.23232782 -- Accuracy: 45.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 735/5000 -- Batch 172/173 -- Loss: 0.02912010 -- Train accuracy: 79.7056\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22933845 -- Accuracy: 46.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 736/5000 -- Batch 172/173 -- Loss: 0.01850543 -- Train accuracy: 79.6333\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22564184 -- Accuracy: 45.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 737/5000 -- Batch 172/173 -- Loss: 0.03373340 -- Train accuracy: 79.4527\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22499500 -- Accuracy: 46.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 738/5000 -- Batch 172/173 -- Loss: 0.02677479 -- Train accuracy: 79.4075\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20574912 -- Accuracy: 45.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 739/5000 -- Batch 172/173 -- Loss: 0.02862766 -- Train accuracy: 79.5882\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21714277 -- Accuracy: 45.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 740/5000 -- Batch 172/173 -- Loss: 0.02197969 -- Train accuracy: 79.5430\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22986817 -- Accuracy: 45.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 741/5000 -- Batch 172/173 -- Loss: 0.01220957 -- Train accuracy: 79.2540\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20608223 -- Accuracy: 46.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 742/5000 -- Batch 172/173 -- Loss: 0.01558782 -- Train accuracy: 78.6308\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21655376 -- Accuracy: 46.87500000\n",
      "\n",
      "Training:\n",
      "Epoch 743/5000 -- Batch 172/173 -- Loss: 0.02046996 -- Train accuracy: 79.0643\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21297458 -- Accuracy: 46.87500000\n",
      "\n",
      "Training:\n",
      "Epoch 744/5000 -- Batch 172/173 -- Loss: 0.01897382 -- Train accuracy: 79.6333\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21766417 -- Accuracy: 45.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 745/5000 -- Batch 172/173 -- Loss: 0.04085665 -- Train accuracy: 79.3804\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21356466 -- Accuracy: 46.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 746/5000 -- Batch 172/173 -- Loss: 0.03193886 -- Train accuracy: 79.5972\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21391338 -- Accuracy: 45.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 747/5000 -- Batch 172/173 -- Loss: 0.01369462 -- Train accuracy: 79.6694\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22323817 -- Accuracy: 45.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 748/5000 -- Batch 172/173 -- Loss: 0.01227083 -- Train accuracy: 79.5520\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22266017 -- Accuracy: 45.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 749/5000 -- Batch 172/173 -- Loss: 0.02674709 -- Train accuracy: 80.1120\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22122794 -- Accuracy: 45.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 750/5000 -- Batch 172/173 -- Loss: 0.03147920 -- Train accuracy: 80.2294\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22457011 -- Accuracy: 45.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 751/5000 -- Batch 172/173 -- Loss: 0.01433495 -- Train accuracy: 79.2811\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21152738 -- Accuracy: 46.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 752/5000 -- Batch 172/173 -- Loss: 0.03271724 -- Train accuracy: 79.4256\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21642688 -- Accuracy: 45.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 753/5000 -- Batch 172/173 -- Loss: 0.01311185 -- Train accuracy: 80.0849\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21489204 -- Accuracy: 46.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 754/5000 -- Batch 172/173 -- Loss: 0.01492225 -- Train accuracy: 79.5611\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22173421 -- Accuracy: 45.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 755/5000 -- Batch 172/173 -- Loss: 0.03010640 -- Train accuracy: 80.1391\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21617220 -- Accuracy: 46.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 756/5000 -- Batch 172/173 -- Loss: 0.04596242 -- Train accuracy: 79.7327\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21450515 -- Accuracy: 46.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 757/5000 -- Batch 172/173 -- Loss: 0.01650336 -- Train accuracy: 78.6940\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21930913 -- Accuracy: 46.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 758/5000 -- Batch 172/173 -- Loss: 0.04227588 -- Train accuracy: 80.3107\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22312939 -- Accuracy: 46.87500000\n",
      "\n",
      "Training:\n",
      "Epoch 759/5000 -- Batch 172/173 -- Loss: 0.02491964 -- Train accuracy: 79.9223\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22678255 -- Accuracy: 45.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 760/5000 -- Batch 172/173 -- Loss: 0.02250268 -- Train accuracy: 79.9223\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22237965 -- Accuracy: 46.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 761/5000 -- Batch 172/173 -- Loss: 0.04447817 -- Train accuracy: 80.1933\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22509488 -- Accuracy: 46.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 762/5000 -- Batch 172/173 -- Loss: 0.03042010 -- Train accuracy: 79.8139\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22140637 -- Accuracy: 46.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 763/5000 -- Batch 172/173 -- Loss: 0.03461027 -- Train accuracy: 79.5791\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22547287 -- Accuracy: 46.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 764/5000 -- Batch 172/173 -- Loss: 0.02409850 -- Train accuracy: 79.9585\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22003313 -- Accuracy: 46.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 765/5000 -- Batch 172/173 -- Loss: 0.02856250 -- Train accuracy: 80.2023\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21596777 -- Accuracy: 47.20394737\n",
      "\n",
      "Training:\n",
      "Epoch 766/5000 -- Batch 172/173 -- Loss: 0.02509044 -- Train accuracy: 80.1120\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21929297 -- Accuracy: 45.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 767/5000 -- Batch 172/173 -- Loss: 0.05194040 -- Train accuracy: 79.4798\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22292404 -- Accuracy: 46.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 768/5000 -- Batch 172/173 -- Loss: 0.03325327 -- Train accuracy: 80.2384\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21842848 -- Accuracy: 46.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 769/5000 -- Batch 172/173 -- Loss: 0.02959919 -- Train accuracy: 80.0849\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22289192 -- Accuracy: 46.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 770/5000 -- Batch 172/173 -- Loss: 0.04395736 -- Train accuracy: 80.0126\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22417257 -- Accuracy: 46.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 771/5000 -- Batch 172/173 -- Loss: 0.02498646 -- Train accuracy: 79.8952\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22146112 -- Accuracy: 46.87500000\n",
      "\n",
      "Training:\n",
      "Epoch 772/5000 -- Batch 172/173 -- Loss: 0.02028680 -- Train accuracy: 80.1391\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22745454 -- Accuracy: 46.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 773/5000 -- Batch 172/173 -- Loss: 0.03222699 -- Train accuracy: 80.1391\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22420070 -- Accuracy: 46.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 774/5000 -- Batch 172/173 -- Loss: 0.02798128 -- Train accuracy: 80.2926\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21527902 -- Accuracy: 46.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 775/5000 -- Batch 172/173 -- Loss: 0.02702884 -- Train accuracy: 80.2023\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22014527 -- Accuracy: 46.79276316\n",
      "\n",
      "Training:\n",
      "Epoch 776/5000 -- Batch 172/173 -- Loss: 0.03662007 -- Train accuracy: 80.3288\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22143370 -- Accuracy: 46.87500000\n",
      "\n",
      "Training:\n",
      "Epoch 777/5000 -- Batch 172/173 -- Loss: 0.02694499 -- Train accuracy: 80.6178\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22579953 -- Accuracy: 46.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 778/5000 -- Batch 172/173 -- Loss: 0.03053807 -- Train accuracy: 80.4823\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22289113 -- Accuracy: 46.87500000\n",
      "\n",
      "Training:\n",
      "Epoch 779/5000 -- Batch 172/173 -- Loss: 0.01471861 -- Train accuracy: 80.4462\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22963196 -- Accuracy: 47.53289474\n",
      "\n",
      "Training:\n",
      "Epoch 780/5000 -- Batch 172/173 -- Loss: 0.01828554 -- Train accuracy: 80.0939\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22358504 -- Accuracy: 46.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 781/5000 -- Batch 172/173 -- Loss: 0.03897198 -- Train accuracy: 80.1842\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22533317 -- Accuracy: 47.28618421\n",
      "\n",
      "Training:\n",
      "Epoch 782/5000 -- Batch 172/173 -- Loss: 0.03128159 -- Train accuracy: 80.1572\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22028415 -- Accuracy: 47.12171053\n",
      "\n",
      "Training:\n",
      "Epoch 783/5000 -- Batch 172/173 -- Loss: 0.01564722 -- Train accuracy: 80.4100\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21744757 -- Accuracy: 47.94407895\n",
      "\n",
      "Training:\n",
      "Epoch 784/5000 -- Batch 172/173 -- Loss: 0.02394566 -- Train accuracy: 80.4913\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21139021 -- Accuracy: 47.61513158\n",
      "\n",
      "Training:\n",
      "Epoch 785/5000 -- Batch 172/173 -- Loss: 0.03487563 -- Train accuracy: 80.3920\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21934525 -- Accuracy: 46.95723684\n",
      "\n",
      "Training:\n",
      "Epoch 786/5000 -- Batch 172/173 -- Loss: 0.01967946 -- Train accuracy: 80.8797\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22651273 -- Accuracy: 47.53289474\n",
      "\n",
      "Training:\n",
      "Epoch 787/5000 -- Batch 172/173 -- Loss: 0.01697314 -- Train accuracy: 79.9043\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21762019 -- Accuracy: 47.53289474\n",
      "\n",
      "Training:\n",
      "Epoch 788/5000 -- Batch 172/173 -- Loss: 0.02343700 -- Train accuracy: 80.6810\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21919991 -- Accuracy: 47.61513158\n",
      "\n",
      "Training:\n",
      "Epoch 789/5000 -- Batch 172/173 -- Loss: 0.01817852 -- Train accuracy: 80.9520\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22116320 -- Accuracy: 47.28618421\n",
      "\n",
      "Training:\n",
      "Epoch 790/5000 -- Batch 172/173 -- Loss: 0.02297428 -- Train accuracy: 80.7713\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21681948 -- Accuracy: 47.12171053\n",
      "\n",
      "Training:\n",
      "Epoch 791/5000 -- Batch 172/173 -- Loss: 0.02790625 -- Train accuracy: 80.4371\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20842864 -- Accuracy: 47.53289474\n",
      "\n",
      "Training:\n",
      "Epoch 792/5000 -- Batch 172/173 -- Loss: 0.01483736 -- Train accuracy: 80.2655\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21504139 -- Accuracy: 46.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 793/5000 -- Batch 172/173 -- Loss: 0.03203034 -- Train accuracy: 80.1662\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21226753 -- Accuracy: 47.69736842\n",
      "\n",
      "Training:\n",
      "Epoch 794/5000 -- Batch 172/173 -- Loss: 0.03584003 -- Train accuracy: 80.7533\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22365119 -- Accuracy: 46.95723684\n",
      "\n",
      "Training:\n",
      "Epoch 795/5000 -- Batch 172/173 -- Loss: 0.04170045 -- Train accuracy: 80.9158\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21576599 -- Accuracy: 47.28618421\n",
      "\n",
      "Training:\n",
      "Epoch 796/5000 -- Batch 172/173 -- Loss: 0.03275709 -- Train accuracy: 80.8616\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21346077 -- Accuracy: 47.53289474\n",
      "\n",
      "Training:\n",
      "Epoch 797/5000 -- Batch 172/173 -- Loss: 0.01224869 -- Train accuracy: 80.9249\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21674205 -- Accuracy: 48.27302632\n",
      "\n",
      "Training:\n",
      "Epoch 798/5000 -- Batch 172/173 -- Loss: 0.03212175 -- Train accuracy: 80.7352\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21448343 -- Accuracy: 47.69736842\n",
      "\n",
      "Training:\n",
      "Epoch 799/5000 -- Batch 172/173 -- Loss: 0.05803369 -- Train accuracy: 80.0759\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20875210 -- Accuracy: 47.77960526\n",
      "\n",
      "Training:\n",
      "Epoch 800/5000 -- Batch 172/173 -- Loss: 0.01454378 -- Train accuracy: 81.1597\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21444524 -- Accuracy: 47.77960526\n",
      "\n",
      "Training:\n",
      "Epoch 801/5000 -- Batch 172/173 -- Loss: 0.03256281 -- Train accuracy: 80.6720\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21828617 -- Accuracy: 48.43750000\n",
      "\n",
      "Training:\n",
      "Epoch 802/5000 -- Batch 172/173 -- Loss: 0.02844739 -- Train accuracy: 80.7533\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21803577 -- Accuracy: 48.02631579\n",
      "\n",
      "Training:\n",
      "Epoch 803/5000 -- Batch 172/173 -- Loss: 0.02757343 -- Train accuracy: 80.9249\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22228582 -- Accuracy: 47.94407895\n",
      "\n",
      "Training:\n",
      "Epoch 804/5000 -- Batch 172/173 -- Loss: 0.02069271 -- Train accuracy: 80.7081\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21100297 -- Accuracy: 47.69736842\n",
      "\n",
      "Training:\n",
      "Epoch 805/5000 -- Batch 172/173 -- Loss: 0.02920566 -- Train accuracy: 80.7171\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21785412 -- Accuracy: 47.20394737\n",
      "\n",
      "Training:\n",
      "Epoch 806/5000 -- Batch 172/173 -- Loss: 0.04231382 -- Train accuracy: 80.1391\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21867379 -- Accuracy: 47.86184211\n",
      "\n",
      "Training:\n",
      "Epoch 807/5000 -- Batch 172/173 -- Loss: 0.00569369 -- Train accuracy: 81.1236\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21706085 -- Accuracy: 46.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 808/5000 -- Batch 172/173 -- Loss: 0.03382631 -- Train accuracy: 81.2861\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21574363 -- Accuracy: 47.45065789\n",
      "\n",
      "Training:\n",
      "Epoch 809/5000 -- Batch 172/173 -- Loss: 0.00842676 -- Train accuracy: 80.6720\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21156931 -- Accuracy: 47.69736842\n",
      "\n",
      "Training:\n",
      "Epoch 810/5000 -- Batch 172/173 -- Loss: 0.02711516 -- Train accuracy: 80.4642\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21106656 -- Accuracy: 47.53289474\n",
      "\n",
      "Training:\n",
      "Epoch 811/5000 -- Batch 172/173 -- Loss: 0.04012767 -- Train accuracy: 80.9971\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20861833 -- Accuracy: 48.10855263\n",
      "\n",
      "Training:\n",
      "Epoch 812/5000 -- Batch 172/173 -- Loss: 0.01037839 -- Train accuracy: 80.6268\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22048464 -- Accuracy: 47.61513158\n",
      "\n",
      "Training:\n",
      "Epoch 813/5000 -- Batch 172/173 -- Loss: 0.02968573 -- Train accuracy: 80.4823\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22369636 -- Accuracy: 48.35526316\n",
      "\n",
      "Training:\n",
      "Epoch 814/5000 -- Batch 172/173 -- Loss: 0.02486464 -- Train accuracy: 81.0874\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20991258 -- Accuracy: 48.60197368\n",
      "\n",
      "Training:\n",
      "Epoch 815/5000 -- Batch 172/173 -- Loss: 0.03299208 -- Train accuracy: 80.9158\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21584908 -- Accuracy: 48.43750000\n",
      "\n",
      "Training:\n",
      "Epoch 816/5000 -- Batch 172/173 -- Loss: 0.02008764 -- Train accuracy: 80.9068\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21659017 -- Accuracy: 47.94407895\n",
      "\n",
      "Training:\n",
      "Epoch 817/5000 -- Batch 172/173 -- Loss: 0.04007014 -- Train accuracy: 81.4758\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21464345 -- Accuracy: 47.53289474\n",
      "\n",
      "Training:\n",
      "Epoch 818/5000 -- Batch 172/173 -- Loss: 0.02312553 -- Train accuracy: 81.0694\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.22195047 -- Accuracy: 47.77960526\n",
      "\n",
      "Training:\n",
      "Epoch 819/5000 -- Batch 172/173 -- Loss: 0.01649076 -- Train accuracy: 81.1687\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20745403 -- Accuracy: 47.94407895\n",
      "\n",
      "Training:\n",
      "Epoch 820/5000 -- Batch 172/173 -- Loss: 0.02175854 -- Train accuracy: 81.5751\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21300167 -- Accuracy: 48.27302632\n",
      "\n",
      "Training:\n",
      "Epoch 821/5000 -- Batch 172/173 -- Loss: 0.01465296 -- Train accuracy: 81.0061\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21385831 -- Accuracy: 47.86184211\n",
      "\n",
      "Training:\n",
      "Epoch 822/5000 -- Batch 172/173 -- Loss: 0.02642768 -- Train accuracy: 81.6293\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21151820 -- Accuracy: 49.25986842\n",
      "\n",
      "Training:\n",
      "Epoch 823/5000 -- Batch 172/173 -- Loss: 0.02011947 -- Train accuracy: 80.5816\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21703108 -- Accuracy: 48.51973684\n",
      "\n",
      "Training:\n",
      "Epoch 824/5000 -- Batch 172/173 -- Loss: 0.00874968 -- Train accuracy: 80.9068\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21316184 -- Accuracy: 48.02631579\n",
      "\n",
      "Training:\n",
      "Epoch 825/5000 -- Batch 172/173 -- Loss: 0.01168045 -- Train accuracy: 81.4397\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/19 -- Loss: 0.18813968 -- Accuracy: 48.35526316\n",
      "\n",
      "Training:\n",
      "Epoch 826/5000 -- Batch 172/173 -- Loss: 0.01952649 -- Train accuracy: 81.2410\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19850867 -- Accuracy: 48.35526316\n",
      "\n",
      "Training:\n",
      "Epoch 827/5000 -- Batch 172/173 -- Loss: 0.04816826 -- Train accuracy: 81.5661\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20538267 -- Accuracy: 49.42434211\n",
      "\n",
      "Training:\n",
      "Epoch 828/5000 -- Batch 172/173 -- Loss: 0.03110408 -- Train accuracy: 81.5661\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20668126 -- Accuracy: 49.09539474\n",
      "\n",
      "Training:\n",
      "Epoch 829/5000 -- Batch 172/173 -- Loss: 0.02386419 -- Train accuracy: 81.4758\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19765657 -- Accuracy: 48.84868421\n",
      "\n",
      "Training:\n",
      "Epoch 830/5000 -- Batch 172/173 -- Loss: 0.02746480 -- Train accuracy: 81.8461\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20750595 -- Accuracy: 48.27302632\n",
      "\n",
      "Training:\n",
      "Epoch 831/5000 -- Batch 172/173 -- Loss: 0.02895474 -- Train accuracy: 81.5751\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21092910 -- Accuracy: 48.68421053\n",
      "\n",
      "Training:\n",
      "Epoch 832/5000 -- Batch 172/173 -- Loss: 0.01045947 -- Train accuracy: 81.4126\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20235214 -- Accuracy: 49.09539474\n",
      "\n",
      "Training:\n",
      "Epoch 833/5000 -- Batch 172/173 -- Loss: 0.03203693 -- Train accuracy: 81.8913\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20635981 -- Accuracy: 48.76644737\n",
      "\n",
      "Training:\n",
      "Epoch 834/5000 -- Batch 172/173 -- Loss: 0.01803501 -- Train accuracy: 81.8732\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21597094 -- Accuracy: 48.93092105\n",
      "\n",
      "Training:\n",
      "Epoch 835/5000 -- Batch 172/173 -- Loss: 0.01600841 -- Train accuracy: 81.2319\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20838462 -- Accuracy: 48.51973684\n",
      "\n",
      "Training:\n",
      "Epoch 836/5000 -- Batch 172/173 -- Loss: 0.01555847 -- Train accuracy: 81.7558\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21691278 -- Accuracy: 48.19078947\n",
      "\n",
      "Training:\n",
      "Epoch 837/5000 -- Batch 172/173 -- Loss: 0.02016933 -- Train accuracy: 81.5661\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20962591 -- Accuracy: 48.51973684\n",
      "\n",
      "Training:\n",
      "Epoch 838/5000 -- Batch 172/173 -- Loss: 0.02939706 -- Train accuracy: 81.5119\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20768445 -- Accuracy: 48.51973684\n",
      "\n",
      "Training:\n",
      "Epoch 839/5000 -- Batch 172/173 -- Loss: 0.07162008 -- Train accuracy: 81.1597\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20576002 -- Accuracy: 48.84868421\n",
      "\n",
      "Training:\n",
      "Epoch 840/5000 -- Batch 172/173 -- Loss: 0.04676656 -- Train accuracy: 81.7829\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20265278 -- Accuracy: 48.76644737\n",
      "\n",
      "Training:\n",
      "Epoch 841/5000 -- Batch 172/173 -- Loss: 0.02864278 -- Train accuracy: 80.9700\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19643881 -- Accuracy: 49.09539474\n",
      "\n",
      "Training:\n",
      "Epoch 842/5000 -- Batch 172/173 -- Loss: 0.03924212 -- Train accuracy: 81.4758\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20275033 -- Accuracy: 48.10855263\n",
      "\n",
      "Training:\n",
      "Epoch 843/5000 -- Batch 172/173 -- Loss: 0.01827423 -- Train accuracy: 81.3584\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19595906 -- Accuracy: 49.17763158\n",
      "\n",
      "Training:\n",
      "Epoch 844/5000 -- Batch 172/173 -- Loss: 0.01839313 -- Train accuracy: 81.6564\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19997876 -- Accuracy: 49.58881579\n",
      "\n",
      "Training:\n",
      "Epoch 845/5000 -- Batch 172/173 -- Loss: 0.04527074 -- Train accuracy: 81.9003\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20321512 -- Accuracy: 48.51973684\n",
      "\n",
      "Training:\n",
      "Epoch 846/5000 -- Batch 172/173 -- Loss: 0.02102828 -- Train accuracy: 81.2952\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20566769 -- Accuracy: 48.60197368\n",
      "\n",
      "Training:\n",
      "Epoch 847/5000 -- Batch 172/173 -- Loss: 0.04036336 -- Train accuracy: 81.6655\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20928175 -- Accuracy: 49.09539474\n",
      "\n",
      "Training:\n",
      "Epoch 848/5000 -- Batch 172/173 -- Loss: 0.05952660 -- Train accuracy: 81.4758\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20733006 -- Accuracy: 49.75328947\n",
      "\n",
      "Training:\n",
      "Epoch 849/5000 -- Batch 172/173 -- Loss: 0.02554506 -- Train accuracy: 82.0448\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21195626 -- Accuracy: 48.60197368\n",
      "\n",
      "Training:\n",
      "Epoch 850/5000 -- Batch 172/173 -- Loss: 0.03219770 -- Train accuracy: 81.9274\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20368144 -- Accuracy: 49.25986842\n",
      "\n",
      "Training:\n",
      "Epoch 851/5000 -- Batch 172/173 -- Loss: 0.03081883 -- Train accuracy: 81.8822\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20273986 -- Accuracy: 48.84868421\n",
      "\n",
      "Training:\n",
      "Epoch 852/5000 -- Batch 172/173 -- Loss: 0.03196089 -- Train accuracy: 81.9816\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20302159 -- Accuracy: 48.43750000\n",
      "\n",
      "Training:\n",
      "Epoch 853/5000 -- Batch 172/173 -- Loss: 0.03971642 -- Train accuracy: 81.6293\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19328342 -- Accuracy: 49.50657895\n",
      "\n",
      "Training:\n",
      "Epoch 854/5000 -- Batch 172/173 -- Loss: 0.01180499 -- Train accuracy: 81.5029\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18954482 -- Accuracy: 49.17763158\n",
      "\n",
      "Training:\n",
      "Epoch 855/5000 -- Batch 172/173 -- Loss: 0.02086584 -- Train accuracy: 80.6178\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18213651 -- Accuracy: 49.01315789\n",
      "\n",
      "Training:\n",
      "Epoch 856/5000 -- Batch 172/173 -- Loss: 0.03157174 -- Train accuracy: 81.4848\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19211294 -- Accuracy: 49.17763158\n",
      "\n",
      "Training:\n",
      "Epoch 857/5000 -- Batch 172/173 -- Loss: 0.03747822 -- Train accuracy: 81.7558\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20846513 -- Accuracy: 49.09539474\n",
      "\n",
      "Training:\n",
      "Epoch 858/5000 -- Batch 172/173 -- Loss: 0.01432866 -- Train accuracy: 82.0719\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20984326 -- Accuracy: 49.17763158\n",
      "\n",
      "Training:\n",
      "Epoch 859/5000 -- Batch 172/173 -- Loss: 0.01892784 -- Train accuracy: 81.8009\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20152416 -- Accuracy: 48.93092105\n",
      "\n",
      "Training:\n",
      "Epoch 860/5000 -- Batch 172/173 -- Loss: 0.01879858 -- Train accuracy: 81.9996\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20512850 -- Accuracy: 48.93092105\n",
      "\n",
      "Training:\n",
      "Epoch 861/5000 -- Batch 172/173 -- Loss: 0.04615454 -- Train accuracy: 81.9816\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20635940 -- Accuracy: 50.08223684\n",
      "\n",
      "Training:\n",
      "Epoch 862/5000 -- Batch 172/173 -- Loss: 0.01511321 -- Train accuracy: 81.9725\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20299397 -- Accuracy: 49.91776316\n",
      "\n",
      "Training:\n",
      "Epoch 863/5000 -- Batch 172/173 -- Loss: 0.01835044 -- Train accuracy: 81.7919\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20458562 -- Accuracy: 48.60197368\n",
      "\n",
      "Training:\n",
      "Epoch 864/5000 -- Batch 172/173 -- Loss: 0.02022098 -- Train accuracy: 81.9274\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20324638 -- Accuracy: 47.94407895\n",
      "\n",
      "Training:\n",
      "Epoch 865/5000 -- Batch 172/173 -- Loss: 0.03552356 -- Train accuracy: 81.8190\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19971675 -- Accuracy: 49.67105263\n",
      "\n",
      "Training:\n",
      "Epoch 866/5000 -- Batch 172/173 -- Loss: 0.01944468 -- Train accuracy: 81.7377\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20108365 -- Accuracy: 49.50657895\n",
      "\n",
      "Training:\n",
      "Epoch 867/5000 -- Batch 172/173 -- Loss: 0.01569108 -- Train accuracy: 81.8280\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19968337 -- Accuracy: 49.58881579\n",
      "\n",
      "Training:\n",
      "Epoch 868/5000 -- Batch 172/173 -- Loss: 0.01494382 -- Train accuracy: 82.1171\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20048341 -- Accuracy: 49.75328947\n",
      "\n",
      "Training:\n",
      "Epoch 869/5000 -- Batch 172/173 -- Loss: 0.02293368 -- Train accuracy: 81.9545\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20364142 -- Accuracy: 50.00000000\n",
      "\n",
      "Training:\n",
      "Epoch 870/5000 -- Batch 172/173 -- Loss: 0.01092959 -- Train accuracy: 82.0448\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21152107 -- Accuracy: 48.93092105\n",
      "\n",
      "Training:\n",
      "Epoch 871/5000 -- Batch 172/173 -- Loss: 0.03257676 -- Train accuracy: 82.1171\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20838579 -- Accuracy: 49.67105263\n",
      "\n",
      "Training:\n",
      "Epoch 872/5000 -- Batch 172/173 -- Loss: 0.01010777 -- Train accuracy: 82.0990\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20690308 -- Accuracy: 49.50657895\n",
      "\n",
      "Training:\n",
      "Epoch 873/5000 -- Batch 172/173 -- Loss: 0.03666208 -- Train accuracy: 82.2074\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19906406 -- Accuracy: 49.50657895\n",
      "\n",
      "Training:\n",
      "Epoch 874/5000 -- Batch 172/173 -- Loss: 0.01496608 -- Train accuracy: 81.7829\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20274409 -- Accuracy: 49.75328947\n",
      "\n",
      "Training:\n",
      "Epoch 875/5000 -- Batch 172/173 -- Loss: 0.00706509 -- Train accuracy: 81.7016\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20471929 -- Accuracy: 50.24671053\n",
      "\n",
      "Training:\n",
      "Epoch 876/5000 -- Batch 172/173 -- Loss: 0.02821066 -- Train accuracy: 82.5325\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19885862 -- Accuracy: 50.24671053\n",
      "\n",
      "Training:\n",
      "Epoch 877/5000 -- Batch 172/173 -- Loss: 0.02050742 -- Train accuracy: 82.4332\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19934680 -- Accuracy: 50.00000000\n",
      "\n",
      "Training:\n",
      "Epoch 878/5000 -- Batch 172/173 -- Loss: 0.03898249 -- Train accuracy: 82.2164\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19605727 -- Accuracy: 49.25986842\n",
      "\n",
      "Training:\n",
      "Epoch 879/5000 -- Batch 172/173 -- Loss: 0.02203330 -- Train accuracy: 81.8913\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20414877 -- Accuracy: 49.09539474\n",
      "\n",
      "Training:\n",
      "Epoch 880/5000 -- Batch 172/173 -- Loss: 0.02494030 -- Train accuracy: 81.9364\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19617591 -- Accuracy: 49.83552632\n",
      "\n",
      "Training:\n",
      "Epoch 881/5000 -- Batch 172/173 -- Loss: 0.02174192 -- Train accuracy: 82.1351\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20474189 -- Accuracy: 49.91776316\n",
      "\n",
      "Training:\n",
      "Epoch 882/5000 -- Batch 172/173 -- Loss: 0.03972713 -- Train accuracy: 82.0087\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21454619 -- Accuracy: 49.25986842\n",
      "\n",
      "Training:\n",
      "Epoch 883/5000 -- Batch 172/173 -- Loss: 0.00724567 -- Train accuracy: 81.9725\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21210271 -- Accuracy: 49.09539474\n",
      "\n",
      "Training:\n",
      "Epoch 884/5000 -- Batch 172/173 -- Loss: 0.03323853 -- Train accuracy: 81.6474\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19357722 -- Accuracy: 49.58881579\n",
      "\n",
      "Training:\n",
      "Epoch 885/5000 -- Batch 172/173 -- Loss: 0.05531600 -- Train accuracy: 82.2616\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19997807 -- Accuracy: 50.57565789\n",
      "\n",
      "Training:\n",
      "Epoch 886/5000 -- Batch 172/173 -- Loss: 0.01334692 -- Train accuracy: 82.4332\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20140847 -- Accuracy: 49.09539474\n",
      "\n",
      "Training:\n",
      "Epoch 887/5000 -- Batch 172/173 -- Loss: 0.03221384 -- Train accuracy: 82.0719\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21008253 -- Accuracy: 49.83552632\n",
      "\n",
      "Training:\n",
      "Epoch 888/5000 -- Batch 172/173 -- Loss: 0.02004585 -- Train accuracy: 82.4151\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20991536 -- Accuracy: 50.24671053\n",
      "\n",
      "Training:\n",
      "Epoch 889/5000 -- Batch 172/173 -- Loss: 0.04180459 -- Train accuracy: 82.2796\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20913177 -- Accuracy: 49.50657895\n",
      "\n",
      "Training:\n",
      "Epoch 890/5000 -- Batch 172/173 -- Loss: 0.04532174 -- Train accuracy: 82.2616\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20899624 -- Accuracy: 49.34210526\n",
      "\n",
      "Training:\n",
      "Epoch 891/5000 -- Batch 172/173 -- Loss: 0.02287550 -- Train accuracy: 82.3248\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20896697 -- Accuracy: 49.91776316\n",
      "\n",
      "Training:\n",
      "Epoch 892/5000 -- Batch 172/173 -- Loss: 0.02332297 -- Train accuracy: 81.8371\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19584341 -- Accuracy: 50.24671053\n",
      "\n",
      "Training:\n",
      "Epoch 893/5000 -- Batch 172/173 -- Loss: 0.03666949 -- Train accuracy: 82.2525\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20245517 -- Accuracy: 50.00000000\n",
      "\n",
      "Training:\n",
      "Epoch 894/5000 -- Batch 172/173 -- Loss: 0.03671468 -- Train accuracy: 82.1983\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21231174 -- Accuracy: 49.34210526\n",
      "\n",
      "Training:\n",
      "Epoch 895/5000 -- Batch 172/173 -- Loss: 0.06529316 -- Train accuracy: 81.9635\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20193401 -- Accuracy: 50.16447368\n",
      "\n",
      "Training:\n",
      "Epoch 896/5000 -- Batch 172/173 -- Loss: 0.06272688 -- Train accuracy: 81.8461\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20005676 -- Accuracy: 50.32894737\n",
      "\n",
      "Training:\n",
      "Epoch 897/5000 -- Batch 172/173 -- Loss: 0.03084800 -- Train accuracy: 82.4422\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20323822 -- Accuracy: 50.08223684\n",
      "\n",
      "Training:\n",
      "Epoch 898/5000 -- Batch 172/173 -- Loss: 0.03754282 -- Train accuracy: 82.5506\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20498607 -- Accuracy: 50.49342105\n",
      "\n",
      "Training:\n",
      "Epoch 899/5000 -- Batch 172/173 -- Loss: 0.02512769 -- Train accuracy: 82.1171\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17887495 -- Accuracy: 50.32894737\n",
      "\n",
      "Training:\n",
      "Epoch 900/5000 -- Batch 172/173 -- Loss: 0.01803942 -- Train accuracy: 81.6113\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18444629 -- Accuracy: 49.67105263\n",
      "\n",
      "Training:\n",
      "Epoch 901/5000 -- Batch 172/173 -- Loss: 0.02592257 -- Train accuracy: 81.9364\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19670577 -- Accuracy: 50.00000000\n",
      "\n",
      "Training:\n",
      "Epoch 902/5000 -- Batch 172/173 -- Loss: 0.02178675 -- Train accuracy: 82.3067\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19073916 -- Accuracy: 50.16447368\n",
      "\n",
      "Training:\n",
      "Epoch 903/5000 -- Batch 172/173 -- Loss: 0.02097787 -- Train accuracy: 82.4061\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19917648 -- Accuracy: 50.24671053\n",
      "\n",
      "Training:\n",
      "Epoch 904/5000 -- Batch 172/173 -- Loss: 0.03714358 -- Train accuracy: 82.8306\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19702170 -- Accuracy: 49.42434211\n",
      "\n",
      "Training:\n",
      "Epoch 905/5000 -- Batch 172/173 -- Loss: 0.01471676 -- Train accuracy: 82.7493\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20236635 -- Accuracy: 50.74013158\n",
      "\n",
      "Training:\n",
      "Epoch 906/5000 -- Batch 172/173 -- Loss: 0.02222431 -- Train accuracy: 82.2796\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20858148 -- Accuracy: 49.42434211\n",
      "\n",
      "Training:\n",
      "Epoch 907/5000 -- Batch 172/173 -- Loss: 0.04366603 -- Train accuracy: 82.5145\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19876152 -- Accuracy: 50.82236842\n",
      "\n",
      "Training:\n",
      "Epoch 908/5000 -- Batch 172/173 -- Loss: 0.07146199 -- Train accuracy: 82.2164\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20857186 -- Accuracy: 50.00000000\n",
      "\n",
      "Training:\n",
      "Epoch 909/5000 -- Batch 172/173 -- Loss: 0.03812630 -- Train accuracy: 81.9454\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21339500 -- Accuracy: 50.65789474\n",
      "\n",
      "Training:\n",
      "Epoch 910/5000 -- Batch 172/173 -- Loss: 0.04076672 -- Train accuracy: 82.3428\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20836687 -- Accuracy: 50.00000000\n",
      "\n",
      "Training:\n",
      "Epoch 911/5000 -- Batch 172/173 -- Loss: 0.01184828 -- Train accuracy: 82.4693\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20763640 -- Accuracy: 50.57565789\n",
      "\n",
      "Training:\n",
      "Epoch 912/5000 -- Batch 172/173 -- Loss: 0.03714868 -- Train accuracy: 82.2435\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21243292 -- Accuracy: 49.83552632\n",
      "\n",
      "Training:\n",
      "Epoch 913/5000 -- Batch 172/173 -- Loss: 0.05549715 -- Train accuracy: 82.3970\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20878882 -- Accuracy: 49.25986842\n",
      "\n",
      "Training:\n",
      "Epoch 914/5000 -- Batch 172/173 -- Loss: 0.06206104 -- Train accuracy: 82.5596\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20219629 -- Accuracy: 50.32894737\n",
      "\n",
      "Training:\n",
      "Epoch 915/5000 -- Batch 172/173 -- Loss: 0.02118450 -- Train accuracy: 82.7583\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19886377 -- Accuracy: 50.74013158\n",
      "\n",
      "Training:\n",
      "Epoch 916/5000 -- Batch 172/173 -- Loss: 0.06291229 -- Train accuracy: 82.3428\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20345347 -- Accuracy: 50.49342105\n",
      "\n",
      "Training:\n",
      "Epoch 917/5000 -- Batch 172/173 -- Loss: 0.03346457 -- Train accuracy: 82.7493\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20742230 -- Accuracy: 50.74013158\n",
      "\n",
      "Training:\n",
      "Epoch 918/5000 -- Batch 172/173 -- Loss: 0.01831931 -- Train accuracy: 82.6499\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20653303 -- Accuracy: 51.15131579\n",
      "\n",
      "Training:\n",
      "Epoch 919/5000 -- Batch 172/173 -- Loss: 0.01475981 -- Train accuracy: 82.6770\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20649067 -- Accuracy: 50.49342105\n",
      "\n",
      "Training:\n",
      "Epoch 920/5000 -- Batch 172/173 -- Loss: 0.06457385 -- Train accuracy: 81.7829\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19462257 -- Accuracy: 50.16447368\n",
      "\n",
      "Training:\n",
      "Epoch 921/5000 -- Batch 172/173 -- Loss: 0.03036123 -- Train accuracy: 82.6770\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19946671 -- Accuracy: 50.08223684\n",
      "\n",
      "Training:\n",
      "Epoch 922/5000 -- Batch 172/173 -- Loss: 0.04866499 -- Train accuracy: 81.9725\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20464655 -- Accuracy: 50.90460526\n",
      "\n",
      "Training:\n",
      "Epoch 923/5000 -- Batch 172/173 -- Loss: 0.03020733 -- Train accuracy: 82.6228\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.21019532 -- Accuracy: 50.49342105\n",
      "\n",
      "Training:\n",
      "Epoch 924/5000 -- Batch 172/173 -- Loss: 0.01813518 -- Train accuracy: 82.4964\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20440303 -- Accuracy: 51.56250000\n",
      "\n",
      "Training:\n",
      "Epoch 925/5000 -- Batch 172/173 -- Loss: 0.01172375 -- Train accuracy: 82.5054\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20025056 -- Accuracy: 51.23355263\n",
      "\n",
      "Training:\n",
      "Epoch 926/5000 -- Batch 172/173 -- Loss: 0.02404655 -- Train accuracy: 82.8667\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20062614 -- Accuracy: 51.06907895\n",
      "\n",
      "Training:\n",
      "Epoch 927/5000 -- Batch 172/173 -- Loss: 0.03394593 -- Train accuracy: 82.7583\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20377954 -- Accuracy: 50.65789474\n",
      "\n",
      "Training:\n",
      "Epoch 928/5000 -- Batch 172/173 -- Loss: 0.00822554 -- Train accuracy: 82.7944\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/19 -- Loss: 0.20174940 -- Accuracy: 50.41118421\n",
      "\n",
      "Training:\n",
      "Epoch 929/5000 -- Batch 172/173 -- Loss: 0.03660507 -- Train accuracy: 82.7312\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19742707 -- Accuracy: 50.82236842\n",
      "\n",
      "Training:\n",
      "Epoch 930/5000 -- Batch 172/173 -- Loss: 0.02763751 -- Train accuracy: 82.5325\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20265066 -- Accuracy: 50.49342105\n",
      "\n",
      "Training:\n",
      "Epoch 931/5000 -- Batch 172/173 -- Loss: 0.00857134 -- Train accuracy: 82.4603\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20481508 -- Accuracy: 50.41118421\n",
      "\n",
      "Training:\n",
      "Epoch 932/5000 -- Batch 172/173 -- Loss: 0.02392710 -- Train accuracy: 82.1441\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18905941 -- Accuracy: 50.65789474\n",
      "\n",
      "Training:\n",
      "Epoch 933/5000 -- Batch 172/173 -- Loss: 0.02947643 -- Train accuracy: 82.6228\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20060808 -- Accuracy: 51.39802632\n",
      "\n",
      "Training:\n",
      "Epoch 934/5000 -- Batch 172/173 -- Loss: 0.03204234 -- Train accuracy: 82.5686\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19707217 -- Accuracy: 50.32894737\n",
      "\n",
      "Training:\n",
      "Epoch 935/5000 -- Batch 172/173 -- Loss: 0.03444272 -- Train accuracy: 82.9118\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20598672 -- Accuracy: 50.49342105\n",
      "\n",
      "Training:\n",
      "Epoch 936/5000 -- Batch 172/173 -- Loss: 0.03468890 -- Train accuracy: 82.7222\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19479596 -- Accuracy: 50.57565789\n",
      "\n",
      "Training:\n",
      "Epoch 937/5000 -- Batch 172/173 -- Loss: 0.03936673 -- Train accuracy: 82.6680\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19863751 -- Accuracy: 51.15131579\n",
      "\n",
      "Training:\n",
      "Epoch 938/5000 -- Batch 172/173 -- Loss: 0.02683534 -- Train accuracy: 82.7222\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19716407 -- Accuracy: 50.41118421\n",
      "\n",
      "Training:\n",
      "Epoch 939/5000 -- Batch 172/173 -- Loss: 0.02789154 -- Train accuracy: 82.9660\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20668216 -- Accuracy: 50.65789474\n",
      "\n",
      "Training:\n",
      "Epoch 940/5000 -- Batch 172/173 -- Loss: 0.02888608 -- Train accuracy: 82.8667\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19892238 -- Accuracy: 51.06907895\n",
      "\n",
      "Training:\n",
      "Epoch 941/5000 -- Batch 172/173 -- Loss: 0.03437182 -- Train accuracy: 82.9570\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19671245 -- Accuracy: 50.41118421\n",
      "\n",
      "Training:\n",
      "Epoch 942/5000 -- Batch 172/173 -- Loss: 0.04188990 -- Train accuracy: 82.8577\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20030415 -- Accuracy: 51.15131579\n",
      "\n",
      "Training:\n",
      "Epoch 943/5000 -- Batch 172/173 -- Loss: 0.01440437 -- Train accuracy: 82.7402\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20288996 -- Accuracy: 50.90460526\n",
      "\n",
      "Training:\n",
      "Epoch 944/5000 -- Batch 172/173 -- Loss: 0.02780171 -- Train accuracy: 82.6499\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19827011 -- Accuracy: 51.06907895\n",
      "\n",
      "Training:\n",
      "Epoch 945/5000 -- Batch 172/173 -- Loss: 0.04381248 -- Train accuracy: 82.8486\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20212988 -- Accuracy: 51.56250000\n",
      "\n",
      "Training:\n",
      "Epoch 946/5000 -- Batch 172/173 -- Loss: 0.02974601 -- Train accuracy: 83.1196\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20749893 -- Accuracy: 50.49342105\n",
      "\n",
      "Training:\n",
      "Epoch 947/5000 -- Batch 172/173 -- Loss: 0.03645245 -- Train accuracy: 82.7944\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20219193 -- Accuracy: 51.56250000\n",
      "\n",
      "Training:\n",
      "Epoch 948/5000 -- Batch 172/173 -- Loss: 0.02456865 -- Train accuracy: 82.8396\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20120231 -- Accuracy: 51.06907895\n",
      "\n",
      "Training:\n",
      "Epoch 949/5000 -- Batch 172/173 -- Loss: 0.02329275 -- Train accuracy: 83.1105\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20341564 -- Accuracy: 50.82236842\n",
      "\n",
      "Training:\n",
      "Epoch 950/5000 -- Batch 172/173 -- Loss: 0.03741353 -- Train accuracy: 82.9570\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20442739 -- Accuracy: 51.48026316\n",
      "\n",
      "Training:\n",
      "Epoch 951/5000 -- Batch 172/173 -- Loss: 0.06219368 -- Train accuracy: 82.3067\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20338834 -- Accuracy: 52.22039474\n",
      "\n",
      "Training:\n",
      "Epoch 952/5000 -- Batch 172/173 -- Loss: 0.02900265 -- Train accuracy: 82.7222\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19546634 -- Accuracy: 50.90460526\n",
      "\n",
      "Training:\n",
      "Epoch 953/5000 -- Batch 172/173 -- Loss: 0.01167210 -- Train accuracy: 82.9028\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18406544 -- Accuracy: 51.48026316\n",
      "\n",
      "Training:\n",
      "Epoch 954/5000 -- Batch 172/173 -- Loss: 0.03062330 -- Train accuracy: 82.7041\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19994859 -- Accuracy: 52.05592105\n",
      "\n",
      "Training:\n",
      "Epoch 955/5000 -- Batch 172/173 -- Loss: 0.03603550 -- Train accuracy: 82.9389\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20493097 -- Accuracy: 51.80921053\n",
      "\n",
      "Training:\n",
      "Epoch 956/5000 -- Batch 172/173 -- Loss: 0.02393345 -- Train accuracy: 82.8848\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19969400 -- Accuracy: 51.48026316\n",
      "\n",
      "Training:\n",
      "Epoch 957/5000 -- Batch 172/173 -- Loss: 0.01156824 -- Train accuracy: 82.8396\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19516131 -- Accuracy: 52.38486842\n",
      "\n",
      "Training:\n",
      "Epoch 958/5000 -- Batch 172/173 -- Loss: 0.04564625 -- Train accuracy: 82.8848\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19565794 -- Accuracy: 51.64473684\n",
      "\n",
      "Training:\n",
      "Epoch 959/5000 -- Batch 172/173 -- Loss: 0.02223179 -- Train accuracy: 82.9751\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19372124 -- Accuracy: 52.63157895\n",
      "\n",
      "Training:\n",
      "Epoch 960/5000 -- Batch 172/173 -- Loss: 0.00766231 -- Train accuracy: 83.1738\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19571496 -- Accuracy: 52.30263158\n",
      "\n",
      "Training:\n",
      "Epoch 961/5000 -- Batch 172/173 -- Loss: 0.03256029 -- Train accuracy: 83.0473\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19612759 -- Accuracy: 52.38486842\n",
      "\n",
      "Training:\n",
      "Epoch 962/5000 -- Batch 172/173 -- Loss: 0.00891845 -- Train accuracy: 83.3363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19761299 -- Accuracy: 52.22039474\n",
      "\n",
      "Training:\n",
      "Epoch 963/5000 -- Batch 172/173 -- Loss: 0.04585097 -- Train accuracy: 83.0202\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19650750 -- Accuracy: 51.06907895\n",
      "\n",
      "Training:\n",
      "Epoch 964/5000 -- Batch 172/173 -- Loss: 0.02246462 -- Train accuracy: 82.4964\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18994270 -- Accuracy: 51.23355263\n",
      "\n",
      "Training:\n",
      "Epoch 965/5000 -- Batch 172/173 -- Loss: 0.01870027 -- Train accuracy: 83.0744\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18822441 -- Accuracy: 52.46710526\n",
      "\n",
      "Training:\n",
      "Epoch 966/5000 -- Batch 172/173 -- Loss: 0.02514862 -- Train accuracy: 82.6680\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18589520 -- Accuracy: 52.30263158\n",
      "\n",
      "Training:\n",
      "Epoch 967/5000 -- Batch 172/173 -- Loss: 0.02714774 -- Train accuracy: 83.0564\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18943315 -- Accuracy: 51.56250000\n",
      "\n",
      "Training:\n",
      "Epoch 968/5000 -- Batch 172/173 -- Loss: 0.02365262 -- Train accuracy: 83.0744\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19249558 -- Accuracy: 52.30263158\n",
      "\n",
      "Training:\n",
      "Epoch 969/5000 -- Batch 172/173 -- Loss: 0.03597045 -- Train accuracy: 82.9751\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20277668 -- Accuracy: 52.22039474\n",
      "\n",
      "Training:\n",
      "Epoch 970/5000 -- Batch 172/173 -- Loss: 0.04242307 -- Train accuracy: 82.6409\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19925195 -- Accuracy: 51.97368421\n",
      "\n",
      "Training:\n",
      "Epoch 971/5000 -- Batch 172/173 -- Loss: 0.01321821 -- Train accuracy: 83.1196\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19252634 -- Accuracy: 51.64473684\n",
      "\n",
      "Training:\n",
      "Epoch 972/5000 -- Batch 172/173 -- Loss: 0.01772448 -- Train accuracy: 83.1467\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19485117 -- Accuracy: 51.56250000\n",
      "\n",
      "Training:\n",
      "Epoch 973/5000 -- Batch 172/173 -- Loss: 0.02020554 -- Train accuracy: 83.0473\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19164193 -- Accuracy: 51.31578947\n",
      "\n",
      "Training:\n",
      "Epoch 974/5000 -- Batch 172/173 -- Loss: 0.01266978 -- Train accuracy: 83.3544\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19548470 -- Accuracy: 51.23355263\n",
      "\n",
      "Training:\n",
      "Epoch 975/5000 -- Batch 172/173 -- Loss: 0.03123121 -- Train accuracy: 82.9841\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19531252 -- Accuracy: 51.64473684\n",
      "\n",
      "Training:\n",
      "Epoch 976/5000 -- Batch 172/173 -- Loss: 0.01949314 -- Train accuracy: 83.1828\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19848351 -- Accuracy: 51.89144737\n",
      "\n",
      "Training:\n",
      "Epoch 977/5000 -- Batch 172/173 -- Loss: 0.01180089 -- Train accuracy: 83.4989\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19730042 -- Accuracy: 51.64473684\n",
      "\n",
      "Training:\n",
      "Epoch 978/5000 -- Batch 172/173 -- Loss: 0.03055184 -- Train accuracy: 83.5983\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19934443 -- Accuracy: 51.80921053\n",
      "\n",
      "Training:\n",
      "Epoch 979/5000 -- Batch 172/173 -- Loss: 0.02069378 -- Train accuracy: 82.6409\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18712262 -- Accuracy: 51.39802632\n",
      "\n",
      "Training:\n",
      "Epoch 980/5000 -- Batch 172/173 -- Loss: 0.04482327 -- Train accuracy: 82.7854\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19316732 -- Accuracy: 51.80921053\n",
      "\n",
      "Training:\n",
      "Epoch 981/5000 -- Batch 172/173 -- Loss: 0.03081439 -- Train accuracy: 83.3905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19153643 -- Accuracy: 51.48026316\n",
      "\n",
      "Training:\n",
      "Epoch 982/5000 -- Batch 172/173 -- Loss: 0.02969252 -- Train accuracy: 82.8848\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19368967 -- Accuracy: 50.57565789\n",
      "\n",
      "Training:\n",
      "Epoch 983/5000 -- Batch 172/173 -- Loss: 0.02333364 -- Train accuracy: 83.0744\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18886537 -- Accuracy: 51.48026316\n",
      "\n",
      "Training:\n",
      "Epoch 984/5000 -- Batch 172/173 -- Loss: 0.04268350 -- Train accuracy: 83.3725\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19257285 -- Accuracy: 51.31578947\n",
      "\n",
      "Training:\n",
      "Epoch 985/5000 -- Batch 172/173 -- Loss: 0.01312785 -- Train accuracy: 83.3183\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19131992 -- Accuracy: 51.80921053\n",
      "\n",
      "Training:\n",
      "Epoch 986/5000 -- Batch 172/173 -- Loss: 0.03297620 -- Train accuracy: 83.2641\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18884847 -- Accuracy: 52.96052632\n",
      "\n",
      "Training:\n",
      "Epoch 987/5000 -- Batch 172/173 -- Loss: 0.01972627 -- Train accuracy: 83.4718\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18916444 -- Accuracy: 51.39802632\n",
      "\n",
      "Training:\n",
      "Epoch 988/5000 -- Batch 172/173 -- Loss: 0.02891247 -- Train accuracy: 83.4086\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19076769 -- Accuracy: 52.46710526\n",
      "\n",
      "Training:\n",
      "Epoch 989/5000 -- Batch 172/173 -- Loss: 0.05908831 -- Train accuracy: 83.4267\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18658272 -- Accuracy: 51.97368421\n",
      "\n",
      "Training:\n",
      "Epoch 990/5000 -- Batch 172/173 -- Loss: 0.03308534 -- Train accuracy: 83.3092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19038509 -- Accuracy: 52.13815789\n",
      "\n",
      "Training:\n",
      "Epoch 991/5000 -- Batch 172/173 -- Loss: 0.01165732 -- Train accuracy: 82.9751\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18919417 -- Accuracy: 52.22039474\n",
      "\n",
      "Training:\n",
      "Epoch 992/5000 -- Batch 172/173 -- Loss: 0.02495315 -- Train accuracy: 83.1557\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18791316 -- Accuracy: 52.38486842\n",
      "\n",
      "Training:\n",
      "Epoch 993/5000 -- Batch 172/173 -- Loss: 0.01083872 -- Train accuracy: 83.5712\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19022957 -- Accuracy: 52.13815789\n",
      "\n",
      "Training:\n",
      "Epoch 994/5000 -- Batch 172/173 -- Loss: 0.02182048 -- Train accuracy: 83.0022\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19784332 -- Accuracy: 53.04276316\n",
      "\n",
      "Training:\n",
      "Epoch 995/5000 -- Batch 172/173 -- Loss: 0.00628542 -- Train accuracy: 83.2912\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19655608 -- Accuracy: 52.79605263\n",
      "\n",
      "Training:\n",
      "Epoch 996/5000 -- Batch 172/173 -- Loss: 0.01519283 -- Train accuracy: 83.3905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19597493 -- Accuracy: 52.87828947\n",
      "\n",
      "Training:\n",
      "Epoch 997/5000 -- Batch 172/173 -- Loss: 0.02659364 -- Train accuracy: 83.0925\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19196195 -- Accuracy: 52.30263158\n",
      "\n",
      "Training:\n",
      "Epoch 998/5000 -- Batch 172/173 -- Loss: 0.01332903 -- Train accuracy: 83.3815\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19801604 -- Accuracy: 52.87828947\n",
      "\n",
      "Training:\n",
      "Epoch 999/5000 -- Batch 172/173 -- Loss: 0.03137790 -- Train accuracy: 83.5712\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19464557 -- Accuracy: 52.22039474\n",
      "\n",
      "Training:\n",
      "Epoch 1000/5000 -- Batch 172/173 -- Loss: 0.01103633 -- Train accuracy: 83.5531\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19291255 -- Accuracy: 53.37171053\n",
      "\n",
      "Training:\n",
      "Epoch 1001/5000 -- Batch 172/173 -- Loss: 0.01406862 -- Train accuracy: 83.4989\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19818619 -- Accuracy: 51.97368421\n",
      "\n",
      "Training:\n",
      "Epoch 1002/5000 -- Batch 172/173 -- Loss: 0.01941284 -- Train accuracy: 83.5531\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19235399 -- Accuracy: 51.89144737\n",
      "\n",
      "Training:\n",
      "Epoch 1003/5000 -- Batch 172/173 -- Loss: 0.04397673 -- Train accuracy: 83.4086\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19636026 -- Accuracy: 52.30263158\n",
      "\n",
      "Training:\n",
      "Epoch 1004/5000 -- Batch 172/173 -- Loss: 0.02637364 -- Train accuracy: 82.9209\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18080686 -- Accuracy: 52.54934211\n",
      "\n",
      "Training:\n",
      "Epoch 1005/5000 -- Batch 172/173 -- Loss: 0.02014367 -- Train accuracy: 83.3725\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19105796 -- Accuracy: 52.05592105\n",
      "\n",
      "Training:\n",
      "Epoch 1006/5000 -- Batch 172/173 -- Loss: 0.04193306 -- Train accuracy: 83.3815\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18598432 -- Accuracy: 51.15131579\n",
      "\n",
      "Training:\n",
      "Epoch 1007/5000 -- Batch 172/173 -- Loss: 0.02190759 -- Train accuracy: 83.6073\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18747975 -- Accuracy: 52.05592105\n",
      "\n",
      "Training:\n",
      "Epoch 1008/5000 -- Batch 172/173 -- Loss: 0.02180149 -- Train accuracy: 83.5260\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18783658 -- Accuracy: 51.97368421\n",
      "\n",
      "Training:\n",
      "Epoch 1009/5000 -- Batch 172/173 -- Loss: 0.03731118 -- Train accuracy: 83.4176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18228637 -- Accuracy: 52.38486842\n",
      "\n",
      "Training:\n",
      "Epoch 1010/5000 -- Batch 172/173 -- Loss: 0.03659305 -- Train accuracy: 83.6796\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19177297 -- Accuracy: 52.22039474\n",
      "\n",
      "Training:\n",
      "Epoch 1011/5000 -- Batch 172/173 -- Loss: 0.02207527 -- Train accuracy: 83.1738\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18117335 -- Accuracy: 52.96052632\n",
      "\n",
      "Training:\n",
      "Epoch 1012/5000 -- Batch 172/173 -- Loss: 0.02368105 -- Train accuracy: 83.1467\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19013512 -- Accuracy: 53.37171053\n",
      "\n",
      "Training:\n",
      "Epoch 1013/5000 -- Batch 172/173 -- Loss: 0.02096713 -- Train accuracy: 83.1376\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18880305 -- Accuracy: 52.22039474\n",
      "\n",
      "Training:\n",
      "Epoch 1014/5000 -- Batch 172/173 -- Loss: 0.05403876 -- Train accuracy: 83.5170\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19171231 -- Accuracy: 52.05592105\n",
      "\n",
      "Training:\n",
      "Epoch 1015/5000 -- Batch 172/173 -- Loss: 0.02331377 -- Train accuracy: 82.8396\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18974035 -- Accuracy: 51.97368421\n",
      "\n",
      "Training:\n",
      "Epoch 1016/5000 -- Batch 172/173 -- Loss: 0.02382154 -- Train accuracy: 83.4809\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19649538 -- Accuracy: 52.79605263\n",
      "\n",
      "Training:\n",
      "Epoch 1017/5000 -- Batch 172/173 -- Loss: 0.05009773 -- Train accuracy: 83.4357\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19353328 -- Accuracy: 52.71381579\n",
      "\n",
      "Training:\n",
      "Epoch 1018/5000 -- Batch 172/173 -- Loss: 0.01291794 -- Train accuracy: 83.7337\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19168285 -- Accuracy: 52.22039474\n",
      "\n",
      "Training:\n",
      "Epoch 1019/5000 -- Batch 172/173 -- Loss: 0.06113965 -- Train accuracy: 83.3273\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18892243 -- Accuracy: 52.46710526\n",
      "\n",
      "Training:\n",
      "Epoch 1020/5000 -- Batch 172/173 -- Loss: 0.01996051 -- Train accuracy: 83.2912\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20167314 -- Accuracy: 52.38486842\n",
      "\n",
      "Training:\n",
      "Epoch 1021/5000 -- Batch 172/173 -- Loss: 0.02678574 -- Train accuracy: 83.7699\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19476331 -- Accuracy: 53.12500000\n",
      "\n",
      "Training:\n",
      "Epoch 1022/5000 -- Batch 172/173 -- Loss: 0.01353790 -- Train accuracy: 83.5170\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18865974 -- Accuracy: 53.04276316\n",
      "\n",
      "Training:\n",
      "Epoch 1023/5000 -- Batch 172/173 -- Loss: 0.02214389 -- Train accuracy: 83.5441\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19579966 -- Accuracy: 52.54934211\n",
      "\n",
      "Training:\n",
      "Epoch 1024/5000 -- Batch 172/173 -- Loss: 0.01565382 -- Train accuracy: 83.3363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19734990 -- Accuracy: 52.54934211\n",
      "\n",
      "Training:\n",
      "Epoch 1025/5000 -- Batch 172/173 -- Loss: 0.02021078 -- Train accuracy: 83.2822\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18581707 -- Accuracy: 52.96052632\n",
      "\n",
      "Training:\n",
      "Epoch 1026/5000 -- Batch 172/173 -- Loss: 0.02091230 -- Train accuracy: 83.7066\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18594858 -- Accuracy: 52.71381579\n",
      "\n",
      "Training:\n",
      "Epoch 1027/5000 -- Batch 172/173 -- Loss: 0.03759700 -- Train accuracy: 83.1557\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19070813 -- Accuracy: 52.38486842\n",
      "\n",
      "Training:\n",
      "Epoch 1028/5000 -- Batch 172/173 -- Loss: 0.03153245 -- Train accuracy: 83.6434\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19320055 -- Accuracy: 52.87828947\n",
      "\n",
      "Training:\n",
      "Epoch 1029/5000 -- Batch 172/173 -- Loss: 0.03240795 -- Train accuracy: 83.6434\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19683665 -- Accuracy: 52.79605263\n",
      "\n",
      "Training:\n",
      "Epoch 1030/5000 -- Batch 172/173 -- Loss: 0.02649919 -- Train accuracy: 83.6434\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19284564 -- Accuracy: 52.96052632\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1031/5000 -- Batch 172/173 -- Loss: 0.01672921 -- Train accuracy: 83.6163\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20155424 -- Accuracy: 53.04276316\n",
      "\n",
      "Training:\n",
      "Epoch 1032/5000 -- Batch 172/173 -- Loss: 0.04690306 -- Train accuracy: 83.4809\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18724034 -- Accuracy: 52.87828947\n",
      "\n",
      "Training:\n",
      "Epoch 1033/5000 -- Batch 172/173 -- Loss: 0.03089209 -- Train accuracy: 83.0293\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18464049 -- Accuracy: 53.04276316\n",
      "\n",
      "Training:\n",
      "Epoch 1034/5000 -- Batch 172/173 -- Loss: 0.01328602 -- Train accuracy: 83.4899\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18271336 -- Accuracy: 53.78289474\n",
      "\n",
      "Training:\n",
      "Epoch 1035/5000 -- Batch 172/173 -- Loss: 0.03634804 -- Train accuracy: 83.5621\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17633240 -- Accuracy: 52.54934211\n",
      "\n",
      "Training:\n",
      "Epoch 1036/5000 -- Batch 172/173 -- Loss: 0.03225581 -- Train accuracy: 83.4989\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18929811 -- Accuracy: 52.71381579\n",
      "\n",
      "Training:\n",
      "Epoch 1037/5000 -- Batch 172/173 -- Loss: 0.04928027 -- Train accuracy: 83.6705\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19139366 -- Accuracy: 53.20723684\n",
      "\n",
      "Training:\n",
      "Epoch 1038/5000 -- Batch 172/173 -- Loss: 0.02984509 -- Train accuracy: 83.7157\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19020679 -- Accuracy: 53.28947368\n",
      "\n",
      "Training:\n",
      "Epoch 1039/5000 -- Batch 172/173 -- Loss: 0.01778052 -- Train accuracy: 83.9324\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19436073 -- Accuracy: 53.28947368\n",
      "\n",
      "Training:\n",
      "Epoch 1040/5000 -- Batch 172/173 -- Loss: 0.00827100 -- Train accuracy: 83.7247\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19034940 -- Accuracy: 53.12500000\n",
      "\n",
      "Training:\n",
      "Epoch 1041/5000 -- Batch 172/173 -- Loss: 0.01719016 -- Train accuracy: 83.6344\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19169266 -- Accuracy: 52.79605263\n",
      "\n",
      "Training:\n",
      "Epoch 1042/5000 -- Batch 172/173 -- Loss: 0.01601909 -- Train accuracy: 83.6434\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18985610 -- Accuracy: 52.71381579\n",
      "\n",
      "Training:\n",
      "Epoch 1043/5000 -- Batch 172/173 -- Loss: 0.03232028 -- Train accuracy: 83.5350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17004953 -- Accuracy: 52.87828947\n",
      "\n",
      "Training:\n",
      "Epoch 1044/5000 -- Batch 172/173 -- Loss: 0.02264752 -- Train accuracy: 83.0112\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17935344 -- Accuracy: 53.61842105\n",
      "\n",
      "Training:\n",
      "Epoch 1045/5000 -- Batch 172/173 -- Loss: 0.04003333 -- Train accuracy: 83.4086\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17721929 -- Accuracy: 52.87828947\n",
      "\n",
      "Training:\n",
      "Epoch 1046/5000 -- Batch 172/173 -- Loss: 0.03954375 -- Train accuracy: 83.8692\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18457921 -- Accuracy: 53.37171053\n",
      "\n",
      "Training:\n",
      "Epoch 1047/5000 -- Batch 172/173 -- Loss: 0.01567302 -- Train accuracy: 83.3725\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17848177 -- Accuracy: 52.54934211\n",
      "\n",
      "Training:\n",
      "Epoch 1048/5000 -- Batch 172/173 -- Loss: 0.01013502 -- Train accuracy: 83.3544\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17205513 -- Accuracy: 53.86513158\n",
      "\n",
      "Training:\n",
      "Epoch 1049/5000 -- Batch 172/173 -- Loss: 0.03313144 -- Train accuracy: 83.7879\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18055366 -- Accuracy: 54.02960526\n",
      "\n",
      "Training:\n",
      "Epoch 1050/5000 -- Batch 172/173 -- Loss: 0.01158044 -- Train accuracy: 83.3002\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17086044 -- Accuracy: 52.96052632\n",
      "\n",
      "Training:\n",
      "Epoch 1051/5000 -- Batch 172/173 -- Loss: 0.02325784 -- Train accuracy: 83.3273\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18236808 -- Accuracy: 54.11184211\n",
      "\n",
      "Training:\n",
      "Epoch 1052/5000 -- Batch 172/173 -- Loss: 0.03701459 -- Train accuracy: 83.6615\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18406130 -- Accuracy: 53.20723684\n",
      "\n",
      "Training:\n",
      "Epoch 1053/5000 -- Batch 172/173 -- Loss: 0.02278038 -- Train accuracy: 83.5712\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19275381 -- Accuracy: 52.79605263\n",
      "\n",
      "Training:\n",
      "Epoch 1054/5000 -- Batch 172/173 -- Loss: 0.01635375 -- Train accuracy: 83.7608\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18770881 -- Accuracy: 53.86513158\n",
      "\n",
      "Training:\n",
      "Epoch 1055/5000 -- Batch 172/173 -- Loss: 0.03215118 -- Train accuracy: 83.2370\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17903669 -- Accuracy: 52.96052632\n",
      "\n",
      "Training:\n",
      "Epoch 1056/5000 -- Batch 172/173 -- Loss: 0.04047984 -- Train accuracy: 83.7879\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18769117 -- Accuracy: 53.37171053\n",
      "\n",
      "Training:\n",
      "Epoch 1057/5000 -- Batch 172/173 -- Loss: 0.03865039 -- Train accuracy: 83.6163\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19246677 -- Accuracy: 52.71381579\n",
      "\n",
      "Training:\n",
      "Epoch 1058/5000 -- Batch 172/173 -- Loss: 0.02905411 -- Train accuracy: 83.6525\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18683357 -- Accuracy: 53.86513158\n",
      "\n",
      "Training:\n",
      "Epoch 1059/5000 -- Batch 172/173 -- Loss: 0.01180569 -- Train accuracy: 83.6976\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19173123 -- Accuracy: 53.37171053\n",
      "\n",
      "Training:\n",
      "Epoch 1060/5000 -- Batch 172/173 -- Loss: 0.01334225 -- Train accuracy: 83.8421\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19245001 -- Accuracy: 53.37171053\n",
      "\n",
      "Training:\n",
      "Epoch 1061/5000 -- Batch 172/173 -- Loss: 0.02222637 -- Train accuracy: 83.6615\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19027049 -- Accuracy: 54.02960526\n",
      "\n",
      "Training:\n",
      "Epoch 1062/5000 -- Batch 172/173 -- Loss: 0.02444679 -- Train accuracy: 83.6615\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19845003 -- Accuracy: 54.27631579\n",
      "\n",
      "Training:\n",
      "Epoch 1063/5000 -- Batch 172/173 -- Loss: 0.02553882 -- Train accuracy: 82.9480\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18264767 -- Accuracy: 53.45394737\n",
      "\n",
      "Training:\n",
      "Epoch 1064/5000 -- Batch 172/173 -- Loss: 0.03876913 -- Train accuracy: 83.4809\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18287457 -- Accuracy: 53.53618421\n",
      "\n",
      "Training:\n",
      "Epoch 1065/5000 -- Batch 172/173 -- Loss: 0.01700717 -- Train accuracy: 83.3454\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17183123 -- Accuracy: 53.12500000\n",
      "\n",
      "Training:\n",
      "Epoch 1066/5000 -- Batch 172/173 -- Loss: 0.02827911 -- Train accuracy: 83.7789\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17772746 -- Accuracy: 53.70065789\n",
      "\n",
      "Training:\n",
      "Epoch 1067/5000 -- Batch 172/173 -- Loss: 0.04809896 -- Train accuracy: 83.6344\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18278080 -- Accuracy: 53.37171053\n",
      "\n",
      "Training:\n",
      "Epoch 1068/5000 -- Batch 172/173 -- Loss: 0.03095913 -- Train accuracy: 83.6434\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18538252 -- Accuracy: 54.11184211\n",
      "\n",
      "Training:\n",
      "Epoch 1069/5000 -- Batch 172/173 -- Loss: 0.01433870 -- Train accuracy: 83.9053\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18269466 -- Accuracy: 53.45394737\n",
      "\n",
      "Training:\n",
      "Epoch 1070/5000 -- Batch 172/173 -- Loss: 0.04968718 -- Train accuracy: 83.5621\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18052163 -- Accuracy: 53.70065789\n",
      "\n",
      "Training:\n",
      "Epoch 1071/5000 -- Batch 172/173 -- Loss: 0.03562062 -- Train accuracy: 83.8512\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18110170 -- Accuracy: 53.53618421\n",
      "\n",
      "Training:\n",
      "Epoch 1072/5000 -- Batch 172/173 -- Loss: 0.05661767 -- Train accuracy: 84.1402\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17642735 -- Accuracy: 53.61842105\n",
      "\n",
      "Training:\n",
      "Epoch 1073/5000 -- Batch 172/173 -- Loss: 0.02869404 -- Train accuracy: 83.7518\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18683917 -- Accuracy: 53.70065789\n",
      "\n",
      "Training:\n",
      "Epoch 1074/5000 -- Batch 172/173 -- Loss: 0.01130690 -- Train accuracy: 83.5983\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18854855 -- Accuracy: 53.61842105\n",
      "\n",
      "Training:\n",
      "Epoch 1075/5000 -- Batch 172/173 -- Loss: 0.03016821 -- Train accuracy: 83.9957\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18895657 -- Accuracy: 53.45394737\n",
      "\n",
      "Training:\n",
      "Epoch 1076/5000 -- Batch 172/173 -- Loss: 0.01351768 -- Train accuracy: 83.5350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18687975 -- Accuracy: 53.86513158\n",
      "\n",
      "Training:\n",
      "Epoch 1077/5000 -- Batch 172/173 -- Loss: 0.02724690 -- Train accuracy: 83.4176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17199246 -- Accuracy: 53.53618421\n",
      "\n",
      "Training:\n",
      "Epoch 1078/5000 -- Batch 172/173 -- Loss: 0.02525309 -- Train accuracy: 83.5079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17850650 -- Accuracy: 54.11184211\n",
      "\n",
      "Training:\n",
      "Epoch 1079/5000 -- Batch 172/173 -- Loss: 0.01778048 -- Train accuracy: 84.0589\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17415000 -- Accuracy: 54.11184211\n",
      "\n",
      "Training:\n",
      "Epoch 1080/5000 -- Batch 172/173 -- Loss: 0.01740032 -- Train accuracy: 83.5621\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19596391 -- Accuracy: 53.45394737\n",
      "\n",
      "Training:\n",
      "Epoch 1081/5000 -- Batch 172/173 -- Loss: 0.02216739 -- Train accuracy: 84.0047\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17740012 -- Accuracy: 53.61842105\n",
      "\n",
      "Training:\n",
      "Epoch 1082/5000 -- Batch 172/173 -- Loss: 0.00852447 -- Train accuracy: 83.8421\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18100857 -- Accuracy: 53.70065789\n",
      "\n",
      "Training:\n",
      "Epoch 1083/5000 -- Batch 172/173 -- Loss: 0.02324649 -- Train accuracy: 83.1105\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17955062 -- Accuracy: 53.37171053\n",
      "\n",
      "Training:\n",
      "Epoch 1084/5000 -- Batch 172/173 -- Loss: 0.07335248 -- Train accuracy: 83.9686\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17652451 -- Accuracy: 53.86513158\n",
      "\n",
      "Training:\n",
      "Epoch 1085/5000 -- Batch 172/173 -- Loss: 0.03255615 -- Train accuracy: 83.9144\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17529885 -- Accuracy: 53.20723684\n",
      "\n",
      "Training:\n",
      "Epoch 1086/5000 -- Batch 172/173 -- Loss: 0.03784458 -- Train accuracy: 83.7157\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17971516 -- Accuracy: 53.94736842\n",
      "\n",
      "Training:\n",
      "Epoch 1087/5000 -- Batch 172/173 -- Loss: 0.01426718 -- Train accuracy: 83.6886\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17481265 -- Accuracy: 53.28947368\n",
      "\n",
      "Training:\n",
      "Epoch 1088/5000 -- Batch 172/173 -- Loss: 0.02853335 -- Train accuracy: 83.9686\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17731796 -- Accuracy: 54.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 1089/5000 -- Batch 172/173 -- Loss: 0.01700810 -- Train accuracy: 83.6615\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17975067 -- Accuracy: 54.19407895\n",
      "\n",
      "Training:\n",
      "Epoch 1090/5000 -- Batch 172/173 -- Loss: 0.02406451 -- Train accuracy: 83.9053\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17716529 -- Accuracy: 53.37171053\n",
      "\n",
      "Training:\n",
      "Epoch 1091/5000 -- Batch 172/173 -- Loss: 0.01320186 -- Train accuracy: 83.6976\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17720648 -- Accuracy: 54.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 1092/5000 -- Batch 172/173 -- Loss: 0.02557492 -- Train accuracy: 83.8512\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17338183 -- Accuracy: 53.86513158\n",
      "\n",
      "Training:\n",
      "Epoch 1093/5000 -- Batch 172/173 -- Loss: 0.01874861 -- Train accuracy: 83.9053\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17924751 -- Accuracy: 53.78289474\n",
      "\n",
      "Training:\n",
      "Epoch 1094/5000 -- Batch 172/173 -- Loss: 0.03362855 -- Train accuracy: 83.9957\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18288160 -- Accuracy: 53.94736842\n",
      "\n",
      "Training:\n",
      "Epoch 1095/5000 -- Batch 172/173 -- Loss: 0.04434394 -- Train accuracy: 83.9324\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18141776 -- Accuracy: 54.60526316\n",
      "\n",
      "Training:\n",
      "Epoch 1096/5000 -- Batch 172/173 -- Loss: 0.01760478 -- Train accuracy: 84.0047\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17863815 -- Accuracy: 53.86513158\n",
      "\n",
      "Training:\n",
      "Epoch 1097/5000 -- Batch 172/173 -- Loss: 0.01785149 -- Train accuracy: 83.2731\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17891516 -- Accuracy: 54.27631579\n",
      "\n",
      "Training:\n",
      "Epoch 1098/5000 -- Batch 172/173 -- Loss: 0.03306902 -- Train accuracy: 83.7518\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18414149 -- Accuracy: 54.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 1099/5000 -- Batch 172/173 -- Loss: 0.03150791 -- Train accuracy: 83.9505\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18076318 -- Accuracy: 53.86513158\n",
      "\n",
      "Training:\n",
      "Epoch 1100/5000 -- Batch 172/173 -- Loss: 0.01600329 -- Train accuracy: 83.7066\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18191962 -- Accuracy: 53.45394737\n",
      "\n",
      "Training:\n",
      "Epoch 1101/5000 -- Batch 172/173 -- Loss: 0.02248630 -- Train accuracy: 84.0950\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18463816 -- Accuracy: 54.11184211\n",
      "\n",
      "Training:\n",
      "Epoch 1102/5000 -- Batch 172/173 -- Loss: 0.03965484 -- Train accuracy: 83.7428\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18214507 -- Accuracy: 54.60526316\n",
      "\n",
      "Training:\n",
      "Epoch 1103/5000 -- Batch 172/173 -- Loss: 0.04017253 -- Train accuracy: 83.7879\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17463628 -- Accuracy: 54.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 1104/5000 -- Batch 172/173 -- Loss: 0.01398118 -- Train accuracy: 83.6254\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19003155 -- Accuracy: 54.27631579\n",
      "\n",
      "Training:\n",
      "Epoch 1105/5000 -- Batch 172/173 -- Loss: 0.03150275 -- Train accuracy: 84.1492\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18118059 -- Accuracy: 53.94736842\n",
      "\n",
      "Training:\n",
      "Epoch 1106/5000 -- Batch 172/173 -- Loss: 0.02099236 -- Train accuracy: 83.9234\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18445555 -- Accuracy: 54.19407895\n",
      "\n",
      "Training:\n",
      "Epoch 1107/5000 -- Batch 172/173 -- Loss: 0.03812526 -- Train accuracy: 84.2034\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18070369 -- Accuracy: 54.52302632\n",
      "\n",
      "Training:\n",
      "Epoch 1108/5000 -- Batch 172/173 -- Loss: 0.02820896 -- Train accuracy: 84.0408\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19101243 -- Accuracy: 54.27631579\n",
      "\n",
      "Training:\n",
      "Epoch 1109/5000 -- Batch 172/173 -- Loss: 0.01731826 -- Train accuracy: 83.7608\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18226604 -- Accuracy: 54.27631579\n",
      "\n",
      "Training:\n",
      "Epoch 1110/5000 -- Batch 172/173 -- Loss: 0.03947539 -- Train accuracy: 83.8421\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19902729 -- Accuracy: 53.94736842\n",
      "\n",
      "Training:\n",
      "Epoch 1111/5000 -- Batch 172/173 -- Loss: 0.02001260 -- Train accuracy: 83.7608\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17813203 -- Accuracy: 54.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 1112/5000 -- Batch 172/173 -- Loss: 0.02123688 -- Train accuracy: 83.8873\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18105281 -- Accuracy: 54.68750000\n",
      "\n",
      "Training:\n",
      "Epoch 1113/5000 -- Batch 172/173 -- Loss: 0.03142571 -- Train accuracy: 84.0408\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18352766 -- Accuracy: 53.70065789\n",
      "\n",
      "Training:\n",
      "Epoch 1114/5000 -- Batch 172/173 -- Loss: 0.01653648 -- Train accuracy: 83.8602\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18329069 -- Accuracy: 54.68750000\n",
      "\n",
      "Training:\n",
      "Epoch 1115/5000 -- Batch 172/173 -- Loss: 0.01474321 -- Train accuracy: 83.8060\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18348904 -- Accuracy: 54.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 1116/5000 -- Batch 172/173 -- Loss: 0.02319193 -- Train accuracy: 84.1492\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19271647 -- Accuracy: 53.78289474\n",
      "\n",
      "Training:\n",
      "Epoch 1117/5000 -- Batch 172/173 -- Loss: 0.01383001 -- Train accuracy: 84.1221\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18399941 -- Accuracy: 54.19407895\n",
      "\n",
      "Training:\n",
      "Epoch 1118/5000 -- Batch 172/173 -- Loss: 0.03156412 -- Train accuracy: 84.0228\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17777788 -- Accuracy: 55.01644737\n",
      "\n",
      "Training:\n",
      "Epoch 1119/5000 -- Batch 172/173 -- Loss: 0.04102374 -- Train accuracy: 84.0137\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18955390 -- Accuracy: 54.44078947\n",
      "\n",
      "Training:\n",
      "Epoch 1120/5000 -- Batch 172/173 -- Loss: 0.01981757 -- Train accuracy: 83.8873\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18244099 -- Accuracy: 54.85197368\n",
      "\n",
      "Training:\n",
      "Epoch 1121/5000 -- Batch 172/173 -- Loss: 0.02216053 -- Train accuracy: 83.9957\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17775387 -- Accuracy: 53.86513158\n",
      "\n",
      "Training:\n",
      "Epoch 1122/5000 -- Batch 172/173 -- Loss: 0.03621435 -- Train accuracy: 83.8692\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17351539 -- Accuracy: 54.76973684\n",
      "\n",
      "Training:\n",
      "Epoch 1123/5000 -- Batch 172/173 -- Loss: 0.02127981 -- Train accuracy: 83.1647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16615814 -- Accuracy: 54.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 1124/5000 -- Batch 172/173 -- Loss: 0.03006003 -- Train accuracy: 83.5712\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17442671 -- Accuracy: 54.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 1125/5000 -- Batch 172/173 -- Loss: 0.01139255 -- Train accuracy: 83.9234\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18686059 -- Accuracy: 53.70065789\n",
      "\n",
      "Training:\n",
      "Epoch 1126/5000 -- Batch 172/173 -- Loss: 0.01531921 -- Train accuracy: 84.0228\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19608023 -- Accuracy: 54.19407895\n",
      "\n",
      "Training:\n",
      "Epoch 1127/5000 -- Batch 172/173 -- Loss: 0.03517875 -- Train accuracy: 83.9866\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17517935 -- Accuracy: 54.27631579\n",
      "\n",
      "Training:\n",
      "Epoch 1128/5000 -- Batch 172/173 -- Loss: 0.01558361 -- Train accuracy: 84.0589\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18691102 -- Accuracy: 54.93421053\n",
      "\n",
      "Training:\n",
      "Epoch 1129/5000 -- Batch 172/173 -- Loss: 0.02314477 -- Train accuracy: 83.9776\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17119167 -- Accuracy: 55.26315789\n",
      "\n",
      "Training:\n",
      "Epoch 1130/5000 -- Batch 172/173 -- Loss: 0.02969491 -- Train accuracy: 84.1221\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16876466 -- Accuracy: 54.52302632\n",
      "\n",
      "Training:\n",
      "Epoch 1131/5000 -- Batch 172/173 -- Loss: 0.02904741 -- Train accuracy: 83.9776\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17894416 -- Accuracy: 55.18092105\n",
      "\n",
      "Training:\n",
      "Epoch 1132/5000 -- Batch 172/173 -- Loss: 0.04662345 -- Train accuracy: 84.1311\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17871984 -- Accuracy: 54.76973684\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1133/5000 -- Batch 172/173 -- Loss: 0.01099110 -- Train accuracy: 83.9957\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17981815 -- Accuracy: 55.01644737\n",
      "\n",
      "Training:\n",
      "Epoch 1134/5000 -- Batch 172/173 -- Loss: 0.02373156 -- Train accuracy: 83.9686\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17473556 -- Accuracy: 54.52302632\n",
      "\n",
      "Training:\n",
      "Epoch 1135/5000 -- Batch 172/173 -- Loss: 0.05821548 -- Train accuracy: 83.9595\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17194197 -- Accuracy: 54.60526316\n",
      "\n",
      "Training:\n",
      "Epoch 1136/5000 -- Batch 172/173 -- Loss: 0.04259723 -- Train accuracy: 84.0499\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17852950 -- Accuracy: 55.34539474\n",
      "\n",
      "Training:\n",
      "Epoch 1137/5000 -- Batch 172/173 -- Loss: 0.00766997 -- Train accuracy: 83.9415\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18426808 -- Accuracy: 55.34539474\n",
      "\n",
      "Training:\n",
      "Epoch 1138/5000 -- Batch 172/173 -- Loss: 0.03746565 -- Train accuracy: 84.1040\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17735680 -- Accuracy: 55.01644737\n",
      "\n",
      "Training:\n",
      "Epoch 1139/5000 -- Batch 172/173 -- Loss: 0.01386085 -- Train accuracy: 84.0770\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18792216 -- Accuracy: 55.75657895\n",
      "\n",
      "Training:\n",
      "Epoch 1140/5000 -- Batch 172/173 -- Loss: 0.02170463 -- Train accuracy: 83.9053\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17855660 -- Accuracy: 54.93421053\n",
      "\n",
      "Training:\n",
      "Epoch 1141/5000 -- Batch 172/173 -- Loss: 0.01280859 -- Train accuracy: 84.0950\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18260138 -- Accuracy: 54.85197368\n",
      "\n",
      "Training:\n",
      "Epoch 1142/5000 -- Batch 172/173 -- Loss: 0.02726093 -- Train accuracy: 83.8512\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17943565 -- Accuracy: 55.09868421\n",
      "\n",
      "Training:\n",
      "Epoch 1143/5000 -- Batch 172/173 -- Loss: 0.03086304 -- Train accuracy: 84.0499\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18756322 -- Accuracy: 54.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 1144/5000 -- Batch 172/173 -- Loss: 0.03988914 -- Train accuracy: 83.8150\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17513474 -- Accuracy: 55.18092105\n",
      "\n",
      "Training:\n",
      "Epoch 1145/5000 -- Batch 172/173 -- Loss: 0.01941079 -- Train accuracy: 84.1402\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18763495 -- Accuracy: 54.35855263\n",
      "\n",
      "Training:\n",
      "Epoch 1146/5000 -- Batch 172/173 -- Loss: 0.01476679 -- Train accuracy: 84.2395\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18469838 -- Accuracy: 55.18092105\n",
      "\n",
      "Training:\n",
      "Epoch 1147/5000 -- Batch 172/173 -- Loss: 0.02995642 -- Train accuracy: 83.7970\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17837884 -- Accuracy: 55.42763158\n",
      "\n",
      "Training:\n",
      "Epoch 1148/5000 -- Batch 172/173 -- Loss: 0.03251079 -- Train accuracy: 84.1402\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19528401 -- Accuracy: 55.59210526\n",
      "\n",
      "Training:\n",
      "Epoch 1149/5000 -- Batch 172/173 -- Loss: 0.05285397 -- Train accuracy: 84.0228\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19268005 -- Accuracy: 55.18092105\n",
      "\n",
      "Training:\n",
      "Epoch 1150/5000 -- Batch 172/173 -- Loss: 0.02326069 -- Train accuracy: 83.7337\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17944216 -- Accuracy: 55.09868421\n",
      "\n",
      "Training:\n",
      "Epoch 1151/5000 -- Batch 172/173 -- Loss: 0.03228323 -- Train accuracy: 84.2305\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18331902 -- Accuracy: 55.92105263\n",
      "\n",
      "Training:\n",
      "Epoch 1152/5000 -- Batch 172/173 -- Loss: 0.05526622 -- Train accuracy: 84.2034\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19496665 -- Accuracy: 54.85197368\n",
      "\n",
      "Training:\n",
      "Epoch 1153/5000 -- Batch 172/173 -- Loss: 0.01592171 -- Train accuracy: 84.2124\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17733726 -- Accuracy: 55.34539474\n",
      "\n",
      "Training:\n",
      "Epoch 1154/5000 -- Batch 172/173 -- Loss: 0.04097494 -- Train accuracy: 83.7699\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18910788 -- Accuracy: 55.50986842\n",
      "\n",
      "Training:\n",
      "Epoch 1155/5000 -- Batch 172/173 -- Loss: 0.03126305 -- Train accuracy: 84.2034\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19630253 -- Accuracy: 54.85197368\n",
      "\n",
      "Training:\n",
      "Epoch 1156/5000 -- Batch 172/173 -- Loss: 0.02900698 -- Train accuracy: 83.9776\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18688535 -- Accuracy: 55.01644737\n",
      "\n",
      "Training:\n",
      "Epoch 1157/5000 -- Batch 172/173 -- Loss: 0.01810500 -- Train accuracy: 83.9595\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18820377 -- Accuracy: 56.00328947\n",
      "\n",
      "Training:\n",
      "Epoch 1158/5000 -- Batch 172/173 -- Loss: 0.03817357 -- Train accuracy: 84.1763\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18201666 -- Accuracy: 54.85197368\n",
      "\n",
      "Training:\n",
      "Epoch 1159/5000 -- Batch 172/173 -- Loss: 0.02144497 -- Train accuracy: 84.0589\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18721590 -- Accuracy: 55.09868421\n",
      "\n",
      "Training:\n",
      "Epoch 1160/5000 -- Batch 172/173 -- Loss: 0.04296011 -- Train accuracy: 84.1853\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17945093 -- Accuracy: 55.92105263\n",
      "\n",
      "Training:\n",
      "Epoch 1161/5000 -- Batch 172/173 -- Loss: 0.02351383 -- Train accuracy: 84.1853\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18024721 -- Accuracy: 55.50986842\n",
      "\n",
      "Training:\n",
      "Epoch 1162/5000 -- Batch 172/173 -- Loss: 0.01259587 -- Train accuracy: 83.9324\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18296693 -- Accuracy: 55.50986842\n",
      "\n",
      "Training:\n",
      "Epoch 1163/5000 -- Batch 172/173 -- Loss: 0.03194154 -- Train accuracy: 84.1402\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17907793 -- Accuracy: 55.50986842\n",
      "\n",
      "Training:\n",
      "Epoch 1164/5000 -- Batch 172/173 -- Loss: 0.00780075 -- Train accuracy: 83.9324\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18455450 -- Accuracy: 54.85197368\n",
      "\n",
      "Training:\n",
      "Epoch 1165/5000 -- Batch 172/173 -- Loss: 0.06305148 -- Train accuracy: 84.2576\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19340247 -- Accuracy: 54.76973684\n",
      "\n",
      "Training:\n",
      "Epoch 1166/5000 -- Batch 172/173 -- Loss: 0.01236997 -- Train accuracy: 84.1492\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17645506 -- Accuracy: 55.34539474\n",
      "\n",
      "Training:\n",
      "Epoch 1167/5000 -- Batch 172/173 -- Loss: 0.03415748 -- Train accuracy: 84.3298\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18809521 -- Accuracy: 55.67434211\n",
      "\n",
      "Training:\n",
      "Epoch 1168/5000 -- Batch 172/173 -- Loss: 0.02290866 -- Train accuracy: 83.8241\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18207016 -- Accuracy: 55.26315789\n",
      "\n",
      "Training:\n",
      "Epoch 1169/5000 -- Batch 172/173 -- Loss: 0.02034726 -- Train accuracy: 84.3027\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18046474 -- Accuracy: 55.42763158\n",
      "\n",
      "Training:\n",
      "Epoch 1170/5000 -- Batch 172/173 -- Loss: 0.03562223 -- Train accuracy: 84.2215\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18692485 -- Accuracy: 54.85197368\n",
      "\n",
      "Training:\n",
      "Epoch 1171/5000 -- Batch 172/173 -- Loss: 0.03426388 -- Train accuracy: 84.2757\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18327429 -- Accuracy: 55.09868421\n",
      "\n",
      "Training:\n",
      "Epoch 1172/5000 -- Batch 172/173 -- Loss: 0.02109217 -- Train accuracy: 84.1221\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19072379 -- Accuracy: 55.18092105\n",
      "\n",
      "Training:\n",
      "Epoch 1173/5000 -- Batch 172/173 -- Loss: 0.09361262 -- Train accuracy: 84.1853\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18962280 -- Accuracy: 55.75657895\n",
      "\n",
      "Training:\n",
      "Epoch 1174/5000 -- Batch 172/173 -- Loss: 0.03540334 -- Train accuracy: 84.0589\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18435309 -- Accuracy: 54.68750000\n",
      "\n",
      "Training:\n",
      "Epoch 1175/5000 -- Batch 172/173 -- Loss: 0.00659510 -- Train accuracy: 84.2666\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19104960 -- Accuracy: 55.50986842\n",
      "\n",
      "Training:\n",
      "Epoch 1176/5000 -- Batch 172/173 -- Loss: 0.00916029 -- Train accuracy: 84.2757\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19391397 -- Accuracy: 55.26315789\n",
      "\n",
      "Training:\n",
      "Epoch 1177/5000 -- Batch 172/173 -- Loss: 0.02442519 -- Train accuracy: 84.2124\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17578332 -- Accuracy: 55.01644737\n",
      "\n",
      "Training:\n",
      "Epoch 1178/5000 -- Batch 172/173 -- Loss: 0.02280015 -- Train accuracy: 84.3027\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17766394 -- Accuracy: 55.83881579\n",
      "\n",
      "Training:\n",
      "Epoch 1179/5000 -- Batch 172/173 -- Loss: 0.01426133 -- Train accuracy: 84.3118\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18610924 -- Accuracy: 56.33223684\n",
      "\n",
      "Training:\n",
      "Epoch 1180/5000 -- Batch 172/173 -- Loss: 0.04540852 -- Train accuracy: 83.5983\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17997460 -- Accuracy: 55.92105263\n",
      "\n",
      "Training:\n",
      "Epoch 1181/5000 -- Batch 172/173 -- Loss: 0.02429815 -- Train accuracy: 84.0770\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18140126 -- Accuracy: 56.33223684\n",
      "\n",
      "Training:\n",
      "Epoch 1182/5000 -- Batch 172/173 -- Loss: 0.03460201 -- Train accuracy: 84.3118\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18339998 -- Accuracy: 56.25000000\n",
      "\n",
      "Training:\n",
      "Epoch 1183/5000 -- Batch 172/173 -- Loss: 0.01835975 -- Train accuracy: 84.1763\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18089678 -- Accuracy: 55.59210526\n",
      "\n",
      "Training:\n",
      "Epoch 1184/5000 -- Batch 172/173 -- Loss: 0.02806539 -- Train accuracy: 84.3298\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18027286 -- Accuracy: 55.42763158\n",
      "\n",
      "Training:\n",
      "Epoch 1185/5000 -- Batch 172/173 -- Loss: 0.03521927 -- Train accuracy: 84.4021\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17922394 -- Accuracy: 56.00328947\n",
      "\n",
      "Training:\n",
      "Epoch 1186/5000 -- Batch 172/173 -- Loss: 0.02946320 -- Train accuracy: 84.3840\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18923483 -- Accuracy: 55.75657895\n",
      "\n",
      "Training:\n",
      "Epoch 1187/5000 -- Batch 172/173 -- Loss: 0.03800856 -- Train accuracy: 84.3027\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18400299 -- Accuracy: 55.92105263\n",
      "\n",
      "Training:\n",
      "Epoch 1188/5000 -- Batch 172/173 -- Loss: 0.00838915 -- Train accuracy: 84.4292\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18806971 -- Accuracy: 55.59210526\n",
      "\n",
      "Training:\n",
      "Epoch 1189/5000 -- Batch 172/173 -- Loss: 0.02850869 -- Train accuracy: 84.3840\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18785393 -- Accuracy: 56.25000000\n",
      "\n",
      "Training:\n",
      "Epoch 1190/5000 -- Batch 172/173 -- Loss: 0.02211944 -- Train accuracy: 84.1492\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17955652 -- Accuracy: 55.83881579\n",
      "\n",
      "Training:\n",
      "Epoch 1191/5000 -- Batch 172/173 -- Loss: 0.02172741 -- Train accuracy: 84.2847\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18767662 -- Accuracy: 55.59210526\n",
      "\n",
      "Training:\n",
      "Epoch 1192/5000 -- Batch 172/173 -- Loss: 0.02284271 -- Train accuracy: 84.4111\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17659076 -- Accuracy: 55.34539474\n",
      "\n",
      "Training:\n",
      "Epoch 1193/5000 -- Batch 172/173 -- Loss: 0.05695634 -- Train accuracy: 84.2666\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17648256 -- Accuracy: 55.59210526\n",
      "\n",
      "Training:\n",
      "Epoch 1194/5000 -- Batch 172/173 -- Loss: 0.02461231 -- Train accuracy: 84.2486\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17837510 -- Accuracy: 55.34539474\n",
      "\n",
      "Training:\n",
      "Epoch 1195/5000 -- Batch 172/173 -- Loss: 0.02232689 -- Train accuracy: 84.2486\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18670919 -- Accuracy: 56.57894737\n",
      "\n",
      "Training:\n",
      "Epoch 1196/5000 -- Batch 172/173 -- Loss: 0.04390498 -- Train accuracy: 84.2124\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17826413 -- Accuracy: 56.16776316\n",
      "\n",
      "Training:\n",
      "Epoch 1197/5000 -- Batch 172/173 -- Loss: 0.01465484 -- Train accuracy: 84.3027\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17657435 -- Accuracy: 56.25000000\n",
      "\n",
      "Training:\n",
      "Epoch 1198/5000 -- Batch 172/173 -- Loss: 0.04304169 -- Train accuracy: 84.2757\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17278862 -- Accuracy: 56.00328947\n",
      "\n",
      "Training:\n",
      "Epoch 1199/5000 -- Batch 172/173 -- Loss: 0.02861771 -- Train accuracy: 84.4473\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16340409 -- Accuracy: 55.67434211\n",
      "\n",
      "Training:\n",
      "Epoch 1200/5000 -- Batch 172/173 -- Loss: 0.01599289 -- Train accuracy: 84.4021\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17484960 -- Accuracy: 55.75657895\n",
      "\n",
      "Training:\n",
      "Epoch 1201/5000 -- Batch 172/173 -- Loss: 0.05747693 -- Train accuracy: 83.9415\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16061220 -- Accuracy: 56.41447368\n",
      "\n",
      "Training:\n",
      "Epoch 1202/5000 -- Batch 172/173 -- Loss: 0.01767237 -- Train accuracy: 84.2486\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16593993 -- Accuracy: 55.50986842\n",
      "\n",
      "Training:\n",
      "Epoch 1203/5000 -- Batch 172/173 -- Loss: 0.03045360 -- Train accuracy: 83.9686\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15650587 -- Accuracy: 55.50986842\n",
      "\n",
      "Training:\n",
      "Epoch 1204/5000 -- Batch 172/173 -- Loss: 0.01939362 -- Train accuracy: 84.3208\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18526140 -- Accuracy: 55.83881579\n",
      "\n",
      "Training:\n",
      "Epoch 1205/5000 -- Batch 172/173 -- Loss: 0.01952459 -- Train accuracy: 84.5105\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18397894 -- Accuracy: 55.92105263\n",
      "\n",
      "Training:\n",
      "Epoch 1206/5000 -- Batch 172/173 -- Loss: 0.02651341 -- Train accuracy: 84.2395\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17888485 -- Accuracy: 55.83881579\n",
      "\n",
      "Training:\n",
      "Epoch 1207/5000 -- Batch 172/173 -- Loss: 0.02186758 -- Train accuracy: 84.4473\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18144339 -- Accuracy: 55.50986842\n",
      "\n",
      "Training:\n",
      "Epoch 1208/5000 -- Batch 172/173 -- Loss: 0.03911814 -- Train accuracy: 84.2305\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17751317 -- Accuracy: 55.50986842\n",
      "\n",
      "Training:\n",
      "Epoch 1209/5000 -- Batch 172/173 -- Loss: 0.01764130 -- Train accuracy: 84.3208\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17581181 -- Accuracy: 55.75657895\n",
      "\n",
      "Training:\n",
      "Epoch 1210/5000 -- Batch 172/173 -- Loss: 0.02553903 -- Train accuracy: 84.2757\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16814223 -- Accuracy: 56.16776316\n",
      "\n",
      "Training:\n",
      "Epoch 1211/5000 -- Batch 172/173 -- Loss: 0.02141644 -- Train accuracy: 84.3027\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19300586 -- Accuracy: 56.16776316\n",
      "\n",
      "Training:\n",
      "Epoch 1212/5000 -- Batch 172/173 -- Loss: 0.08632456 -- Train accuracy: 84.3750\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17627893 -- Accuracy: 56.08552632\n",
      "\n",
      "Training:\n",
      "Epoch 1213/5000 -- Batch 172/173 -- Loss: 0.03727999 -- Train accuracy: 84.0860\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16798666 -- Accuracy: 55.67434211\n",
      "\n",
      "Training:\n",
      "Epoch 1214/5000 -- Batch 172/173 -- Loss: 0.02002038 -- Train accuracy: 84.4111\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18434924 -- Accuracy: 56.57894737\n",
      "\n",
      "Training:\n",
      "Epoch 1215/5000 -- Batch 172/173 -- Loss: 0.02780748 -- Train accuracy: 84.2486\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17749632 -- Accuracy: 56.25000000\n",
      "\n",
      "Training:\n",
      "Epoch 1216/5000 -- Batch 172/173 -- Loss: 0.01760706 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18688575 -- Accuracy: 56.00328947\n",
      "\n",
      "Training:\n",
      "Epoch 1217/5000 -- Batch 172/173 -- Loss: 0.01433426 -- Train accuracy: 84.3389\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17505548 -- Accuracy: 56.49671053\n",
      "\n",
      "Training:\n",
      "Epoch 1218/5000 -- Batch 172/173 -- Loss: 0.01617163 -- Train accuracy: 84.4292\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17743079 -- Accuracy: 56.08552632\n",
      "\n",
      "Training:\n",
      "Epoch 1219/5000 -- Batch 172/173 -- Loss: 0.04176126 -- Train accuracy: 84.3208\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17552523 -- Accuracy: 56.08552632\n",
      "\n",
      "Training:\n",
      "Epoch 1220/5000 -- Batch 172/173 -- Loss: 0.00825652 -- Train accuracy: 84.4653\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18200229 -- Accuracy: 56.16776316\n",
      "\n",
      "Training:\n",
      "Epoch 1221/5000 -- Batch 172/173 -- Loss: 0.03752860 -- Train accuracy: 84.4292\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16849681 -- Accuracy: 56.41447368\n",
      "\n",
      "Training:\n",
      "Epoch 1222/5000 -- Batch 172/173 -- Loss: 0.02656228 -- Train accuracy: 84.2847\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16423874 -- Accuracy: 56.08552632\n",
      "\n",
      "Training:\n",
      "Epoch 1223/5000 -- Batch 172/173 -- Loss: 0.02670535 -- Train accuracy: 84.4021\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17063509 -- Accuracy: 56.41447368\n",
      "\n",
      "Training:\n",
      "Epoch 1224/5000 -- Batch 172/173 -- Loss: 0.03077205 -- Train accuracy: 84.2847\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17776728 -- Accuracy: 56.82565789\n",
      "\n",
      "Training:\n",
      "Epoch 1225/5000 -- Batch 172/173 -- Loss: 0.02343467 -- Train accuracy: 84.5466\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17854993 -- Accuracy: 56.16776316\n",
      "\n",
      "Training:\n",
      "Epoch 1226/5000 -- Batch 172/173 -- Loss: 0.03083577 -- Train accuracy: 84.2215\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16596721 -- Accuracy: 56.41447368\n",
      "\n",
      "Training:\n",
      "Epoch 1227/5000 -- Batch 172/173 -- Loss: 0.03693122 -- Train accuracy: 84.3027\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17966970 -- Accuracy: 56.49671053\n",
      "\n",
      "Training:\n",
      "Epoch 1228/5000 -- Batch 172/173 -- Loss: 0.04363831 -- Train accuracy: 84.3840\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17063105 -- Accuracy: 56.49671053\n",
      "\n",
      "Training:\n",
      "Epoch 1229/5000 -- Batch 172/173 -- Loss: 0.03900696 -- Train accuracy: 84.3479\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17850756 -- Accuracy: 56.90789474\n",
      "\n",
      "Training:\n",
      "Epoch 1230/5000 -- Batch 172/173 -- Loss: 0.02453223 -- Train accuracy: 84.3750\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17192939 -- Accuracy: 56.00328947\n",
      "\n",
      "Training:\n",
      "Epoch 1231/5000 -- Batch 172/173 -- Loss: 0.02763579 -- Train accuracy: 84.3118\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16681000 -- Accuracy: 56.90789474\n",
      "\n",
      "Training:\n",
      "Epoch 1232/5000 -- Batch 172/173 -- Loss: 0.02565899 -- Train accuracy: 84.3298\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16422067 -- Accuracy: 56.41447368\n",
      "\n",
      "Training:\n",
      "Epoch 1233/5000 -- Batch 172/173 -- Loss: 0.02264578 -- Train accuracy: 84.3750\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17090468 -- Accuracy: 56.99013158\n",
      "\n",
      "Training:\n",
      "Epoch 1234/5000 -- Batch 172/173 -- Loss: 0.02402374 -- Train accuracy: 84.4292\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17106428 -- Accuracy: 56.33223684\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1235/5000 -- Batch 172/173 -- Loss: 0.00912440 -- Train accuracy: 84.4743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17566047 -- Accuracy: 56.74342105\n",
      "\n",
      "Training:\n",
      "Epoch 1236/5000 -- Batch 172/173 -- Loss: 0.02418703 -- Train accuracy: 84.5285\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.20135198 -- Accuracy: 56.00328947\n",
      "\n",
      "Training:\n",
      "Epoch 1237/5000 -- Batch 172/173 -- Loss: 0.02512405 -- Train accuracy: 84.2847\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19633218 -- Accuracy: 56.82565789\n",
      "\n",
      "Training:\n",
      "Epoch 1238/5000 -- Batch 172/173 -- Loss: 0.00887441 -- Train accuracy: 84.3389\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16443717 -- Accuracy: 56.82565789\n",
      "\n",
      "Training:\n",
      "Epoch 1239/5000 -- Batch 172/173 -- Loss: 0.03298764 -- Train accuracy: 84.2757\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15458022 -- Accuracy: 56.16776316\n",
      "\n",
      "Training:\n",
      "Epoch 1240/5000 -- Batch 172/173 -- Loss: 0.00672889 -- Train accuracy: 84.3389\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17621023 -- Accuracy: 57.23684211\n",
      "\n",
      "Training:\n",
      "Epoch 1241/5000 -- Batch 172/173 -- Loss: 0.02466753 -- Train accuracy: 84.4021\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16650586 -- Accuracy: 56.66118421\n",
      "\n",
      "Training:\n",
      "Epoch 1242/5000 -- Batch 172/173 -- Loss: 0.01285879 -- Train accuracy: 84.4563\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18124262 -- Accuracy: 56.08552632\n",
      "\n",
      "Training:\n",
      "Epoch 1243/5000 -- Batch 172/173 -- Loss: 0.02045199 -- Train accuracy: 84.4653\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16911952 -- Accuracy: 57.31907895\n",
      "\n",
      "Training:\n",
      "Epoch 1244/5000 -- Batch 172/173 -- Loss: 0.02009885 -- Train accuracy: 84.3298\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17262101 -- Accuracy: 56.99013158\n",
      "\n",
      "Training:\n",
      "Epoch 1245/5000 -- Batch 172/173 -- Loss: 0.02068117 -- Train accuracy: 84.2576\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16909913 -- Accuracy: 57.15460526\n",
      "\n",
      "Training:\n",
      "Epoch 1246/5000 -- Batch 172/173 -- Loss: 0.02018400 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16925699 -- Accuracy: 56.57894737\n",
      "\n",
      "Training:\n",
      "Epoch 1247/5000 -- Batch 172/173 -- Loss: 0.02177172 -- Train accuracy: 84.1311\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17766972 -- Accuracy: 57.89473684\n",
      "\n",
      "Training:\n",
      "Epoch 1248/5000 -- Batch 172/173 -- Loss: 0.03528330 -- Train accuracy: 84.2034\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19929582 -- Accuracy: 57.31907895\n",
      "\n",
      "Training:\n",
      "Epoch 1249/5000 -- Batch 172/173 -- Loss: 0.02895670 -- Train accuracy: 84.4924\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16761678 -- Accuracy: 57.89473684\n",
      "\n",
      "Training:\n",
      "Epoch 1250/5000 -- Batch 172/173 -- Loss: 0.02775123 -- Train accuracy: 84.0950\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16831232 -- Accuracy: 56.99013158\n",
      "\n",
      "Training:\n",
      "Epoch 1251/5000 -- Batch 172/173 -- Loss: 0.03364603 -- Train accuracy: 84.1311\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15696925 -- Accuracy: 57.40131579\n",
      "\n",
      "Training:\n",
      "Epoch 1252/5000 -- Batch 172/173 -- Loss: 0.03542530 -- Train accuracy: 84.5827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15926115 -- Accuracy: 57.23684211\n",
      "\n",
      "Training:\n",
      "Epoch 1253/5000 -- Batch 172/173 -- Loss: 0.01124443 -- Train accuracy: 83.9234\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17726627 -- Accuracy: 57.73026316\n",
      "\n",
      "Training:\n",
      "Epoch 1254/5000 -- Batch 172/173 -- Loss: 0.03146967 -- Train accuracy: 84.0137\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16936920 -- Accuracy: 57.81250000\n",
      "\n",
      "Training:\n",
      "Epoch 1255/5000 -- Batch 172/173 -- Loss: 0.05911382 -- Train accuracy: 84.3118\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17051487 -- Accuracy: 57.64802632\n",
      "\n",
      "Training:\n",
      "Epoch 1256/5000 -- Batch 172/173 -- Loss: 0.01786826 -- Train accuracy: 84.4021\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18463944 -- Accuracy: 56.41447368\n",
      "\n",
      "Training:\n",
      "Epoch 1257/5000 -- Batch 172/173 -- Loss: 0.09048821 -- Train accuracy: 84.4653\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17093169 -- Accuracy: 57.89473684\n",
      "\n",
      "Training:\n",
      "Epoch 1258/5000 -- Batch 172/173 -- Loss: 0.05331869 -- Train accuracy: 84.4743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17044733 -- Accuracy: 56.99013158\n",
      "\n",
      "Training:\n",
      "Epoch 1259/5000 -- Batch 172/173 -- Loss: 0.02332849 -- Train accuracy: 84.4834\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17187470 -- Accuracy: 57.23684211\n",
      "\n",
      "Training:\n",
      "Epoch 1260/5000 -- Batch 172/173 -- Loss: 0.02872149 -- Train accuracy: 84.1763\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16118806 -- Accuracy: 56.57894737\n",
      "\n",
      "Training:\n",
      "Epoch 1261/5000 -- Batch 172/173 -- Loss: 0.03981119 -- Train accuracy: 84.2847\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16227332 -- Accuracy: 57.48355263\n",
      "\n",
      "Training:\n",
      "Epoch 1262/5000 -- Batch 172/173 -- Loss: 0.01005472 -- Train accuracy: 84.5376\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17292074 -- Accuracy: 57.07236842\n",
      "\n",
      "Training:\n",
      "Epoch 1263/5000 -- Batch 172/173 -- Loss: 0.02180487 -- Train accuracy: 84.5376\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16560064 -- Accuracy: 56.99013158\n",
      "\n",
      "Training:\n",
      "Epoch 1264/5000 -- Batch 172/173 -- Loss: 0.03886141 -- Train accuracy: 84.4111\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18368448 -- Accuracy: 56.90789474\n",
      "\n",
      "Training:\n",
      "Epoch 1265/5000 -- Batch 172/173 -- Loss: 0.01642523 -- Train accuracy: 84.4563\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16312774 -- Accuracy: 57.56578947\n",
      "\n",
      "Training:\n",
      "Epoch 1266/5000 -- Batch 172/173 -- Loss: 0.04272360 -- Train accuracy: 84.3750\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14958486 -- Accuracy: 56.82565789\n",
      "\n",
      "Training:\n",
      "Epoch 1267/5000 -- Batch 172/173 -- Loss: 0.01485729 -- Train accuracy: 84.4021\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16657335 -- Accuracy: 57.23684211\n",
      "\n",
      "Training:\n",
      "Epoch 1268/5000 -- Batch 172/173 -- Loss: 0.03663376 -- Train accuracy: 84.4743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17991135 -- Accuracy: 57.23684211\n",
      "\n",
      "Training:\n",
      "Epoch 1269/5000 -- Batch 172/173 -- Loss: 0.03120672 -- Train accuracy: 84.5918\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16218748 -- Accuracy: 56.49671053\n",
      "\n",
      "Training:\n",
      "Epoch 1270/5000 -- Batch 172/173 -- Loss: 0.01063466 -- Train accuracy: 84.4111\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15600522 -- Accuracy: 57.64802632\n",
      "\n",
      "Training:\n",
      "Epoch 1271/5000 -- Batch 172/173 -- Loss: 0.02184237 -- Train accuracy: 84.1402\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16241519 -- Accuracy: 57.31907895\n",
      "\n",
      "Training:\n",
      "Epoch 1272/5000 -- Batch 172/173 -- Loss: 0.04323252 -- Train accuracy: 84.5556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16002753 -- Accuracy: 57.56578947\n",
      "\n",
      "Training:\n",
      "Epoch 1273/5000 -- Batch 172/173 -- Loss: 0.03254037 -- Train accuracy: 84.4653\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18605848 -- Accuracy: 56.33223684\n",
      "\n",
      "Training:\n",
      "Epoch 1274/5000 -- Batch 172/173 -- Loss: 0.02836191 -- Train accuracy: 84.5014\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18291092 -- Accuracy: 56.08552632\n",
      "\n",
      "Training:\n",
      "Epoch 1275/5000 -- Batch 172/173 -- Loss: 0.04063535 -- Train accuracy: 84.5556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17298609 -- Accuracy: 57.81250000\n",
      "\n",
      "Training:\n",
      "Epoch 1276/5000 -- Batch 172/173 -- Loss: 0.02650809 -- Train accuracy: 84.4563\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16633199 -- Accuracy: 56.49671053\n",
      "\n",
      "Training:\n",
      "Epoch 1277/5000 -- Batch 172/173 -- Loss: 0.04504491 -- Train accuracy: 84.5827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16969351 -- Accuracy: 56.99013158\n",
      "\n",
      "Training:\n",
      "Epoch 1278/5000 -- Batch 172/173 -- Loss: 0.04154469 -- Train accuracy: 84.4653\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16197127 -- Accuracy: 57.48355263\n",
      "\n",
      "Training:\n",
      "Epoch 1279/5000 -- Batch 172/173 -- Loss: 0.02851508 -- Train accuracy: 84.5556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16979414 -- Accuracy: 57.23684211\n",
      "\n",
      "Training:\n",
      "Epoch 1280/5000 -- Batch 172/173 -- Loss: 0.02089591 -- Train accuracy: 84.2757\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17016359 -- Accuracy: 57.97697368\n",
      "\n",
      "Training:\n",
      "Epoch 1281/5000 -- Batch 172/173 -- Loss: 0.01191693 -- Train accuracy: 84.5918\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16310477 -- Accuracy: 57.40131579\n",
      "\n",
      "Training:\n",
      "Epoch 1282/5000 -- Batch 172/173 -- Loss: 0.06629401 -- Train accuracy: 84.4834\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16376835 -- Accuracy: 56.74342105\n",
      "\n",
      "Training:\n",
      "Epoch 1283/5000 -- Batch 172/173 -- Loss: 0.02394212 -- Train accuracy: 84.3027\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18076266 -- Accuracy: 57.89473684\n",
      "\n",
      "Training:\n",
      "Epoch 1284/5000 -- Batch 172/173 -- Loss: 0.03553912 -- Train accuracy: 84.4924\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18244361 -- Accuracy: 57.48355263\n",
      "\n",
      "Training:\n",
      "Epoch 1285/5000 -- Batch 172/173 -- Loss: 0.01838829 -- Train accuracy: 84.5918\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17256187 -- Accuracy: 57.73026316\n",
      "\n",
      "Training:\n",
      "Epoch 1286/5000 -- Batch 172/173 -- Loss: 0.02587933 -- Train accuracy: 84.4202\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16474880 -- Accuracy: 58.30592105\n",
      "\n",
      "Training:\n",
      "Epoch 1287/5000 -- Batch 172/173 -- Loss: 0.01934555 -- Train accuracy: 84.5827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16617911 -- Accuracy: 58.63486842\n",
      "\n",
      "Training:\n",
      "Epoch 1288/5000 -- Batch 172/173 -- Loss: 0.02547605 -- Train accuracy: 84.4653\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16992152 -- Accuracy: 57.23684211\n",
      "\n",
      "Training:\n",
      "Epoch 1289/5000 -- Batch 172/173 -- Loss: 0.02954421 -- Train accuracy: 84.4382\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17306547 -- Accuracy: 57.15460526\n",
      "\n",
      "Training:\n",
      "Epoch 1290/5000 -- Batch 172/173 -- Loss: 0.03684326 -- Train accuracy: 84.4834\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17213733 -- Accuracy: 56.74342105\n",
      "\n",
      "Training:\n",
      "Epoch 1291/5000 -- Batch 172/173 -- Loss: 0.01924975 -- Train accuracy: 84.5376\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16743543 -- Accuracy: 57.81250000\n",
      "\n",
      "Training:\n",
      "Epoch 1292/5000 -- Batch 172/173 -- Loss: 0.02912134 -- Train accuracy: 84.3479\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17458339 -- Accuracy: 57.64802632\n",
      "\n",
      "Training:\n",
      "Epoch 1293/5000 -- Batch 172/173 -- Loss: 0.03270547 -- Train accuracy: 84.3479\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16880733 -- Accuracy: 56.08552632\n",
      "\n",
      "Training:\n",
      "Epoch 1294/5000 -- Batch 172/173 -- Loss: 0.01243680 -- Train accuracy: 84.3118\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17535345 -- Accuracy: 57.48355263\n",
      "\n",
      "Training:\n",
      "Epoch 1295/5000 -- Batch 172/173 -- Loss: 0.02894707 -- Train accuracy: 84.3569\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15565946 -- Accuracy: 57.40131579\n",
      "\n",
      "Training:\n",
      "Epoch 1296/5000 -- Batch 172/173 -- Loss: 0.03576253 -- Train accuracy: 84.4202\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17715623 -- Accuracy: 57.40131579\n",
      "\n",
      "Training:\n",
      "Epoch 1297/5000 -- Batch 172/173 -- Loss: 0.03556496 -- Train accuracy: 84.3027\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16068669 -- Accuracy: 56.90789474\n",
      "\n",
      "Training:\n",
      "Epoch 1298/5000 -- Batch 172/173 -- Loss: 0.02989713 -- Train accuracy: 84.5556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16461804 -- Accuracy: 59.04605263\n",
      "\n",
      "Training:\n",
      "Epoch 1299/5000 -- Batch 172/173 -- Loss: 0.02324550 -- Train accuracy: 84.2034\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16851614 -- Accuracy: 56.74342105\n",
      "\n",
      "Training:\n",
      "Epoch 1300/5000 -- Batch 172/173 -- Loss: 0.03303686 -- Train accuracy: 84.2847\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15339983 -- Accuracy: 57.56578947\n",
      "\n",
      "Training:\n",
      "Epoch 1301/5000 -- Batch 172/173 -- Loss: 0.01556208 -- Train accuracy: 84.5556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16455790 -- Accuracy: 57.48355263\n",
      "\n",
      "Training:\n",
      "Epoch 1302/5000 -- Batch 172/173 -- Loss: 0.02579945 -- Train accuracy: 84.5556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16844668 -- Accuracy: 57.31907895\n",
      "\n",
      "Training:\n",
      "Epoch 1303/5000 -- Batch 172/173 -- Loss: 0.03006500 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16320140 -- Accuracy: 57.64802632\n",
      "\n",
      "Training:\n",
      "Epoch 1304/5000 -- Batch 172/173 -- Loss: 0.04055246 -- Train accuracy: 84.1673\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14393729 -- Accuracy: 57.97697368\n",
      "\n",
      "Training:\n",
      "Epoch 1305/5000 -- Batch 172/173 -- Loss: 0.02877244 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14955025 -- Accuracy: 57.48355263\n",
      "\n",
      "Training:\n",
      "Epoch 1306/5000 -- Batch 172/173 -- Loss: 0.02685230 -- Train accuracy: 84.4653\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16383282 -- Accuracy: 57.15460526\n",
      "\n",
      "Training:\n",
      "Epoch 1307/5000 -- Batch 172/173 -- Loss: 0.01076764 -- Train accuracy: 84.4924\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16340420 -- Accuracy: 57.48355263\n",
      "\n",
      "Training:\n",
      "Epoch 1308/5000 -- Batch 172/173 -- Loss: 0.03471774 -- Train accuracy: 84.4653\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15888141 -- Accuracy: 57.48355263\n",
      "\n",
      "Training:\n",
      "Epoch 1309/5000 -- Batch 172/173 -- Loss: 0.01890496 -- Train accuracy: 84.4111\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16420065 -- Accuracy: 57.31907895\n",
      "\n",
      "Training:\n",
      "Epoch 1310/5000 -- Batch 172/173 -- Loss: 0.00343386 -- Train accuracy: 84.4924\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17474007 -- Accuracy: 57.73026316\n",
      "\n",
      "Training:\n",
      "Epoch 1311/5000 -- Batch 172/173 -- Loss: 0.02778671 -- Train accuracy: 84.4743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15927531 -- Accuracy: 57.97697368\n",
      "\n",
      "Training:\n",
      "Epoch 1312/5000 -- Batch 172/173 -- Loss: 0.03065040 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16049255 -- Accuracy: 57.07236842\n",
      "\n",
      "Training:\n",
      "Epoch 1313/5000 -- Batch 172/173 -- Loss: 0.01189633 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16184119 -- Accuracy: 58.14144737\n",
      "\n",
      "Training:\n",
      "Epoch 1314/5000 -- Batch 172/173 -- Loss: 0.02769268 -- Train accuracy: 84.3660\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17136765 -- Accuracy: 57.31907895\n",
      "\n",
      "Training:\n",
      "Epoch 1315/5000 -- Batch 172/173 -- Loss: 0.03267479 -- Train accuracy: 84.1311\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15503235 -- Accuracy: 57.40131579\n",
      "\n",
      "Training:\n",
      "Epoch 1316/5000 -- Batch 172/173 -- Loss: 0.03571367 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15998615 -- Accuracy: 57.97697368\n",
      "\n",
      "Training:\n",
      "Epoch 1317/5000 -- Batch 172/173 -- Loss: 0.01809972 -- Train accuracy: 84.4021\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16930336 -- Accuracy: 57.97697368\n",
      "\n",
      "Training:\n",
      "Epoch 1318/5000 -- Batch 172/173 -- Loss: 0.01767518 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15515042 -- Accuracy: 57.64802632\n",
      "\n",
      "Training:\n",
      "Epoch 1319/5000 -- Batch 172/173 -- Loss: 0.01611378 -- Train accuracy: 84.5737\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17525653 -- Accuracy: 57.56578947\n",
      "\n",
      "Training:\n",
      "Epoch 1320/5000 -- Batch 172/173 -- Loss: 0.03713356 -- Train accuracy: 84.3118\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16551805 -- Accuracy: 58.30592105\n",
      "\n",
      "Training:\n",
      "Epoch 1321/5000 -- Batch 172/173 -- Loss: 0.02704570 -- Train accuracy: 84.5737\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17235624 -- Accuracy: 58.30592105\n",
      "\n",
      "Training:\n",
      "Epoch 1322/5000 -- Batch 172/173 -- Loss: 0.01327461 -- Train accuracy: 84.4743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17996020 -- Accuracy: 57.23684211\n",
      "\n",
      "Training:\n",
      "Epoch 1323/5000 -- Batch 172/173 -- Loss: 0.02132849 -- Train accuracy: 84.5827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16385832 -- Accuracy: 58.71710526\n",
      "\n",
      "Training:\n",
      "Epoch 1324/5000 -- Batch 172/173 -- Loss: 0.00956379 -- Train accuracy: 84.5105\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17899162 -- Accuracy: 57.73026316\n",
      "\n",
      "Training:\n",
      "Epoch 1325/5000 -- Batch 172/173 -- Loss: 0.04313129 -- Train accuracy: 84.5195\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16323253 -- Accuracy: 57.89473684\n",
      "\n",
      "Training:\n",
      "Epoch 1326/5000 -- Batch 172/173 -- Loss: 0.02075278 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16812719 -- Accuracy: 58.14144737\n",
      "\n",
      "Training:\n",
      "Epoch 1327/5000 -- Batch 172/173 -- Loss: 0.05511294 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15965736 -- Accuracy: 58.30592105\n",
      "\n",
      "Training:\n",
      "Epoch 1328/5000 -- Batch 172/173 -- Loss: 0.01461518 -- Train accuracy: 84.5014\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.19015596 -- Accuracy: 58.05921053\n",
      "\n",
      "Training:\n",
      "Epoch 1329/5000 -- Batch 172/173 -- Loss: 0.03085716 -- Train accuracy: 84.3840\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15678138 -- Accuracy: 59.04605263\n",
      "\n",
      "Training:\n",
      "Epoch 1330/5000 -- Batch 172/173 -- Loss: 0.05045240 -- Train accuracy: 84.3840\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16834806 -- Accuracy: 58.38815789\n",
      "\n",
      "Training:\n",
      "Epoch 1331/5000 -- Batch 172/173 -- Loss: 0.04114186 -- Train accuracy: 84.6821\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17685301 -- Accuracy: 58.38815789\n",
      "\n",
      "Training:\n",
      "Epoch 1332/5000 -- Batch 172/173 -- Loss: 0.01994719 -- Train accuracy: 84.5195\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16503092 -- Accuracy: 59.04605263\n",
      "\n",
      "Training:\n",
      "Epoch 1333/5000 -- Batch 172/173 -- Loss: 0.03109254 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17543457 -- Accuracy: 58.05921053\n",
      "\n",
      "Training:\n",
      "Epoch 1334/5000 -- Batch 172/173 -- Loss: 0.03769189 -- Train accuracy: 84.4563\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17022629 -- Accuracy: 58.22368421\n",
      "\n",
      "Training:\n",
      "Epoch 1335/5000 -- Batch 172/173 -- Loss: 0.09909213 -- Train accuracy: 84.5195\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17823093 -- Accuracy: 57.97697368\n",
      "\n",
      "Training:\n",
      "Epoch 1336/5000 -- Batch 172/173 -- Loss: 0.01042204 -- Train accuracy: 84.5556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15847515 -- Accuracy: 58.30592105\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1337/5000 -- Batch 172/173 -- Loss: 0.02186466 -- Train accuracy: 84.1853\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15582627 -- Accuracy: 58.38815789\n",
      "\n",
      "Training:\n",
      "Epoch 1338/5000 -- Batch 172/173 -- Loss: 0.01779439 -- Train accuracy: 84.5556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17071231 -- Accuracy: 58.14144737\n",
      "\n",
      "Training:\n",
      "Epoch 1339/5000 -- Batch 172/173 -- Loss: 0.05651810 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16247909 -- Accuracy: 58.38815789\n",
      "\n",
      "Training:\n",
      "Epoch 1340/5000 -- Batch 172/173 -- Loss: 0.04353515 -- Train accuracy: 84.6279\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16867202 -- Accuracy: 58.30592105\n",
      "\n",
      "Training:\n",
      "Epoch 1341/5000 -- Batch 172/173 -- Loss: 0.01975002 -- Train accuracy: 84.3027\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16238135 -- Accuracy: 57.64802632\n",
      "\n",
      "Training:\n",
      "Epoch 1342/5000 -- Batch 172/173 -- Loss: 0.03540687 -- Train accuracy: 84.6008\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16053491 -- Accuracy: 58.38815789\n",
      "\n",
      "Training:\n",
      "Epoch 1343/5000 -- Batch 172/173 -- Loss: 0.03714762 -- Train accuracy: 84.3660\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15783067 -- Accuracy: 58.38815789\n",
      "\n",
      "Training:\n",
      "Epoch 1344/5000 -- Batch 172/173 -- Loss: 0.01122884 -- Train accuracy: 84.5376\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16888459 -- Accuracy: 57.89473684\n",
      "\n",
      "Training:\n",
      "Epoch 1345/5000 -- Batch 172/173 -- Loss: 0.02349741 -- Train accuracy: 84.6460\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16064217 -- Accuracy: 58.14144737\n",
      "\n",
      "Training:\n",
      "Epoch 1346/5000 -- Batch 172/173 -- Loss: 0.03181517 -- Train accuracy: 84.4382\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15936823 -- Accuracy: 58.05921053\n",
      "\n",
      "Training:\n",
      "Epoch 1347/5000 -- Batch 172/173 -- Loss: 0.04634546 -- Train accuracy: 84.4653\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18018349 -- Accuracy: 58.79934211\n",
      "\n",
      "Training:\n",
      "Epoch 1348/5000 -- Batch 172/173 -- Loss: 0.01857851 -- Train accuracy: 84.5285\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16647232 -- Accuracy: 57.64802632\n",
      "\n",
      "Training:\n",
      "Epoch 1349/5000 -- Batch 172/173 -- Loss: 0.03121736 -- Train accuracy: 84.6098\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16559072 -- Accuracy: 58.55263158\n",
      "\n",
      "Training:\n",
      "Epoch 1350/5000 -- Batch 172/173 -- Loss: 0.04681399 -- Train accuracy: 84.6460\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16828215 -- Accuracy: 58.55263158\n",
      "\n",
      "Training:\n",
      "Epoch 1351/5000 -- Batch 172/173 -- Loss: 0.02743074 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17343908 -- Accuracy: 58.14144737\n",
      "\n",
      "Training:\n",
      "Epoch 1352/5000 -- Batch 172/173 -- Loss: 0.00754396 -- Train accuracy: 84.6369\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16945183 -- Accuracy: 57.81250000\n",
      "\n",
      "Training:\n",
      "Epoch 1353/5000 -- Batch 172/173 -- Loss: 0.02724130 -- Train accuracy: 84.7092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17420314 -- Accuracy: 58.63486842\n",
      "\n",
      "Training:\n",
      "Epoch 1354/5000 -- Batch 172/173 -- Loss: 0.01170844 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17197029 -- Accuracy: 57.81250000\n",
      "\n",
      "Training:\n",
      "Epoch 1355/5000 -- Batch 172/173 -- Loss: 0.01439872 -- Train accuracy: 84.6279\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17231327 -- Accuracy: 57.73026316\n",
      "\n",
      "Training:\n",
      "Epoch 1356/5000 -- Batch 172/173 -- Loss: 0.01572945 -- Train accuracy: 84.6098\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17154781 -- Accuracy: 58.96381579\n",
      "\n",
      "Training:\n",
      "Epoch 1357/5000 -- Batch 172/173 -- Loss: 0.02673603 -- Train accuracy: 84.5737\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17029140 -- Accuracy: 58.14144737\n",
      "\n",
      "Training:\n",
      "Epoch 1358/5000 -- Batch 172/173 -- Loss: 0.03473042 -- Train accuracy: 84.5195\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16869404 -- Accuracy: 58.47039474\n",
      "\n",
      "Training:\n",
      "Epoch 1359/5000 -- Batch 172/173 -- Loss: 0.04520487 -- Train accuracy: 84.7001\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17003980 -- Accuracy: 58.63486842\n",
      "\n",
      "Training:\n",
      "Epoch 1360/5000 -- Batch 172/173 -- Loss: 0.04045166 -- Train accuracy: 84.5737\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15954795 -- Accuracy: 58.63486842\n",
      "\n",
      "Training:\n",
      "Epoch 1361/5000 -- Batch 172/173 -- Loss: 0.02458220 -- Train accuracy: 84.5556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16035204 -- Accuracy: 59.04605263\n",
      "\n",
      "Training:\n",
      "Epoch 1362/5000 -- Batch 172/173 -- Loss: 0.04333792 -- Train accuracy: 84.4021\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16494180 -- Accuracy: 58.63486842\n",
      "\n",
      "Training:\n",
      "Epoch 1363/5000 -- Batch 172/173 -- Loss: 0.03044949 -- Train accuracy: 84.5827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16874685 -- Accuracy: 59.21052632\n",
      "\n",
      "Training:\n",
      "Epoch 1364/5000 -- Batch 172/173 -- Loss: 0.00816650 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17548534 -- Accuracy: 59.12828947\n",
      "\n",
      "Training:\n",
      "Epoch 1365/5000 -- Batch 172/173 -- Loss: 0.01910934 -- Train accuracy: 84.5466\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17231086 -- Accuracy: 59.45723684\n",
      "\n",
      "Training:\n",
      "Epoch 1366/5000 -- Batch 172/173 -- Loss: 0.01483952 -- Train accuracy: 84.4382\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17171707 -- Accuracy: 58.30592105\n",
      "\n",
      "Training:\n",
      "Epoch 1367/5000 -- Batch 172/173 -- Loss: 0.01720143 -- Train accuracy: 84.5014\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16845189 -- Accuracy: 59.45723684\n",
      "\n",
      "Training:\n",
      "Epoch 1368/5000 -- Batch 172/173 -- Loss: 0.02690163 -- Train accuracy: 84.4834\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16515530 -- Accuracy: 57.89473684\n",
      "\n",
      "Training:\n",
      "Epoch 1369/5000 -- Batch 172/173 -- Loss: 0.03065306 -- Train accuracy: 84.4563\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15544727 -- Accuracy: 59.37500000\n",
      "\n",
      "Training:\n",
      "Epoch 1370/5000 -- Batch 172/173 -- Loss: 0.01762520 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16464655 -- Accuracy: 58.63486842\n",
      "\n",
      "Training:\n",
      "Epoch 1371/5000 -- Batch 172/173 -- Loss: 0.02100831 -- Train accuracy: 84.5014\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15641619 -- Accuracy: 58.47039474\n",
      "\n",
      "Training:\n",
      "Epoch 1372/5000 -- Batch 172/173 -- Loss: 0.02945726 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16273059 -- Accuracy: 59.29276316\n",
      "\n",
      "Training:\n",
      "Epoch 1373/5000 -- Batch 172/173 -- Loss: 0.03211515 -- Train accuracy: 84.6279\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16674396 -- Accuracy: 59.45723684\n",
      "\n",
      "Training:\n",
      "Epoch 1374/5000 -- Batch 172/173 -- Loss: 0.01022345 -- Train accuracy: 84.5105\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16298639 -- Accuracy: 59.29276316\n",
      "\n",
      "Training:\n",
      "Epoch 1375/5000 -- Batch 172/173 -- Loss: 0.01298264 -- Train accuracy: 84.6279\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16945799 -- Accuracy: 59.12828947\n",
      "\n",
      "Training:\n",
      "Epoch 1376/5000 -- Batch 172/173 -- Loss: 0.06080532 -- Train accuracy: 84.6279\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17006553 -- Accuracy: 59.37500000\n",
      "\n",
      "Training:\n",
      "Epoch 1377/5000 -- Batch 172/173 -- Loss: 0.01521283 -- Train accuracy: 84.5827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17440240 -- Accuracy: 58.38815789\n",
      "\n",
      "Training:\n",
      "Epoch 1378/5000 -- Batch 172/173 -- Loss: 0.02776600 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15458157 -- Accuracy: 58.96381579\n",
      "\n",
      "Training:\n",
      "Epoch 1379/5000 -- Batch 172/173 -- Loss: 0.02900464 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17507997 -- Accuracy: 59.12828947\n",
      "\n",
      "Training:\n",
      "Epoch 1380/5000 -- Batch 172/173 -- Loss: 0.02586999 -- Train accuracy: 84.5737\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17244089 -- Accuracy: 59.29276316\n",
      "\n",
      "Training:\n",
      "Epoch 1381/5000 -- Batch 172/173 -- Loss: 0.01234346 -- Train accuracy: 84.6640\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16429413 -- Accuracy: 59.04605263\n",
      "\n",
      "Training:\n",
      "Epoch 1382/5000 -- Batch 172/173 -- Loss: 0.05517349 -- Train accuracy: 84.5466\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16226098 -- Accuracy: 59.78618421\n",
      "\n",
      "Training:\n",
      "Epoch 1383/5000 -- Batch 172/173 -- Loss: 0.04523465 -- Train accuracy: 84.6279\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15692805 -- Accuracy: 59.37500000\n",
      "\n",
      "Training:\n",
      "Epoch 1384/5000 -- Batch 172/173 -- Loss: 0.02696057 -- Train accuracy: 84.5195\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16571588 -- Accuracy: 59.04605263\n",
      "\n",
      "Training:\n",
      "Epoch 1385/5000 -- Batch 172/173 -- Loss: 0.03027344 -- Train accuracy: 84.6730\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17129099 -- Accuracy: 58.88157895\n",
      "\n",
      "Training:\n",
      "Epoch 1386/5000 -- Batch 172/173 -- Loss: 0.03842434 -- Train accuracy: 84.4563\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17824832 -- Accuracy: 58.63486842\n",
      "\n",
      "Training:\n",
      "Epoch 1387/5000 -- Batch 172/173 -- Loss: 0.02497771 -- Train accuracy: 84.6008\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17693412 -- Accuracy: 59.29276316\n",
      "\n",
      "Training:\n",
      "Epoch 1388/5000 -- Batch 172/173 -- Loss: 0.01315434 -- Train accuracy: 84.6821\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17388242 -- Accuracy: 59.78618421\n",
      "\n",
      "Training:\n",
      "Epoch 1389/5000 -- Batch 172/173 -- Loss: 0.02639436 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17458395 -- Accuracy: 59.21052632\n",
      "\n",
      "Training:\n",
      "Epoch 1390/5000 -- Batch 172/173 -- Loss: 0.01623751 -- Train accuracy: 84.6279\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18618495 -- Accuracy: 59.95065789\n",
      "\n",
      "Training:\n",
      "Epoch 1391/5000 -- Batch 172/173 -- Loss: 0.01534232 -- Train accuracy: 84.6821\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17704432 -- Accuracy: 59.78618421\n",
      "\n",
      "Training:\n",
      "Epoch 1392/5000 -- Batch 172/173 -- Loss: 0.04408161 -- Train accuracy: 84.4292\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16358674 -- Accuracy: 59.70394737\n",
      "\n",
      "Training:\n",
      "Epoch 1393/5000 -- Batch 172/173 -- Loss: 0.02610206 -- Train accuracy: 84.5827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17246915 -- Accuracy: 59.04605263\n",
      "\n",
      "Training:\n",
      "Epoch 1394/5000 -- Batch 172/173 -- Loss: 0.05254021 -- Train accuracy: 84.6821\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16596326 -- Accuracy: 60.27960526\n",
      "\n",
      "Training:\n",
      "Epoch 1395/5000 -- Batch 172/173 -- Loss: 0.03100337 -- Train accuracy: 84.6460\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16592619 -- Accuracy: 59.62171053\n",
      "\n",
      "Training:\n",
      "Epoch 1396/5000 -- Batch 172/173 -- Loss: 0.02933888 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16765756 -- Accuracy: 59.70394737\n",
      "\n",
      "Training:\n",
      "Epoch 1397/5000 -- Batch 172/173 -- Loss: 0.01424240 -- Train accuracy: 84.4743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16845884 -- Accuracy: 59.29276316\n",
      "\n",
      "Training:\n",
      "Epoch 1398/5000 -- Batch 172/173 -- Loss: 0.04871759 -- Train accuracy: 84.5376\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16723789 -- Accuracy: 59.95065789\n",
      "\n",
      "Training:\n",
      "Epoch 1399/5000 -- Batch 172/173 -- Loss: 0.02366981 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15588036 -- Accuracy: 59.86842105\n",
      "\n",
      "Training:\n",
      "Epoch 1400/5000 -- Batch 172/173 -- Loss: 0.11066727 -- Train accuracy: 84.6911\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16437522 -- Accuracy: 60.27960526\n",
      "\n",
      "Training:\n",
      "Epoch 1401/5000 -- Batch 172/173 -- Loss: 0.01261397 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16920369 -- Accuracy: 60.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 1402/5000 -- Batch 172/173 -- Loss: 0.00656543 -- Train accuracy: 84.6279\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15926720 -- Accuracy: 60.11513158\n",
      "\n",
      "Training:\n",
      "Epoch 1403/5000 -- Batch 172/173 -- Loss: 0.01738315 -- Train accuracy: 84.7092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15807378 -- Accuracy: 60.11513158\n",
      "\n",
      "Training:\n",
      "Epoch 1404/5000 -- Batch 172/173 -- Loss: 0.04481952 -- Train accuracy: 84.5105\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16341398 -- Accuracy: 60.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 1405/5000 -- Batch 172/173 -- Loss: 0.02036412 -- Train accuracy: 84.5827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16750026 -- Accuracy: 59.53947368\n",
      "\n",
      "Training:\n",
      "Epoch 1406/5000 -- Batch 172/173 -- Loss: 0.03763188 -- Train accuracy: 84.6460\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16446135 -- Accuracy: 60.77302632\n",
      "\n",
      "Training:\n",
      "Epoch 1407/5000 -- Batch 172/173 -- Loss: 0.03108766 -- Train accuracy: 84.6911\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16263984 -- Accuracy: 59.62171053\n",
      "\n",
      "Training:\n",
      "Epoch 1408/5000 -- Batch 172/173 -- Loss: 0.02131356 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18119895 -- Accuracy: 59.45723684\n",
      "\n",
      "Training:\n",
      "Epoch 1409/5000 -- Batch 172/173 -- Loss: 0.02802798 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17475948 -- Accuracy: 59.78618421\n",
      "\n",
      "Training:\n",
      "Epoch 1410/5000 -- Batch 172/173 -- Loss: 0.03385576 -- Train accuracy: 84.5556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16715895 -- Accuracy: 60.11513158\n",
      "\n",
      "Training:\n",
      "Epoch 1411/5000 -- Batch 172/173 -- Loss: 0.01620770 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17031534 -- Accuracy: 60.03289474\n",
      "\n",
      "Training:\n",
      "Epoch 1412/5000 -- Batch 172/173 -- Loss: 0.02447179 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15694315 -- Accuracy: 59.12828947\n",
      "\n",
      "Training:\n",
      "Epoch 1413/5000 -- Batch 172/173 -- Loss: 0.02277305 -- Train accuracy: 84.6369\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16953454 -- Accuracy: 59.37500000\n",
      "\n",
      "Training:\n",
      "Epoch 1414/5000 -- Batch 172/173 -- Loss: 0.01769738 -- Train accuracy: 84.7272\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17699069 -- Accuracy: 60.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 1415/5000 -- Batch 172/173 -- Loss: 0.02032232 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17267489 -- Accuracy: 59.37500000\n",
      "\n",
      "Training:\n",
      "Epoch 1416/5000 -- Batch 172/173 -- Loss: 0.02963574 -- Train accuracy: 84.6821\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16249969 -- Accuracy: 59.78618421\n",
      "\n",
      "Training:\n",
      "Epoch 1417/5000 -- Batch 172/173 -- Loss: 0.01874276 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16375713 -- Accuracy: 59.45723684\n",
      "\n",
      "Training:\n",
      "Epoch 1418/5000 -- Batch 172/173 -- Loss: 0.02460627 -- Train accuracy: 84.6279\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16178532 -- Accuracy: 59.78618421\n",
      "\n",
      "Training:\n",
      "Epoch 1419/5000 -- Batch 172/173 -- Loss: 0.01641599 -- Train accuracy: 84.6098\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16635707 -- Accuracy: 60.03289474\n",
      "\n",
      "Training:\n",
      "Epoch 1420/5000 -- Batch 172/173 -- Loss: 0.04389285 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16577170 -- Accuracy: 60.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 1421/5000 -- Batch 172/173 -- Loss: 0.02054011 -- Train accuracy: 84.6369\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15688382 -- Accuracy: 59.45723684\n",
      "\n",
      "Training:\n",
      "Epoch 1422/5000 -- Batch 172/173 -- Loss: 0.03700285 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16201405 -- Accuracy: 59.70394737\n",
      "\n",
      "Training:\n",
      "Epoch 1423/5000 -- Batch 172/173 -- Loss: 0.02261594 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15503961 -- Accuracy: 60.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 1424/5000 -- Batch 172/173 -- Loss: 0.00800006 -- Train accuracy: 84.6640\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17296722 -- Accuracy: 59.70394737\n",
      "\n",
      "Training:\n",
      "Epoch 1425/5000 -- Batch 172/173 -- Loss: 0.03261704 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17554341 -- Accuracy: 60.27960526\n",
      "\n",
      "Training:\n",
      "Epoch 1426/5000 -- Batch 172/173 -- Loss: 0.03542418 -- Train accuracy: 84.4473\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14535404 -- Accuracy: 60.27960526\n",
      "\n",
      "Training:\n",
      "Epoch 1427/5000 -- Batch 172/173 -- Loss: 0.02426647 -- Train accuracy: 84.5466\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15309508 -- Accuracy: 60.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 1428/5000 -- Batch 172/173 -- Loss: 0.02352158 -- Train accuracy: 84.4743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16438184 -- Accuracy: 60.27960526\n",
      "\n",
      "Training:\n",
      "Epoch 1429/5000 -- Batch 172/173 -- Loss: 0.04196294 -- Train accuracy: 84.7001\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16816220 -- Accuracy: 59.78618421\n",
      "\n",
      "Training:\n",
      "Epoch 1430/5000 -- Batch 172/173 -- Loss: 0.03005518 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14737387 -- Accuracy: 60.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 1431/5000 -- Batch 172/173 -- Loss: 0.02503032 -- Train accuracy: 84.6008\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16324649 -- Accuracy: 60.11513158\n",
      "\n",
      "Training:\n",
      "Epoch 1432/5000 -- Batch 172/173 -- Loss: 0.01551044 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16692496 -- Accuracy: 59.21052632\n",
      "\n",
      "Training:\n",
      "Epoch 1433/5000 -- Batch 172/173 -- Loss: 0.06694423 -- Train accuracy: 84.5556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17130991 -- Accuracy: 60.60855263\n",
      "\n",
      "Training:\n",
      "Epoch 1434/5000 -- Batch 172/173 -- Loss: 0.03094147 -- Train accuracy: 84.4743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16717272 -- Accuracy: 60.11513158\n",
      "\n",
      "Training:\n",
      "Epoch 1435/5000 -- Batch 172/173 -- Loss: 0.00723609 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16932590 -- Accuracy: 60.44407895\n",
      "\n",
      "Training:\n",
      "Epoch 1436/5000 -- Batch 172/173 -- Loss: 0.01028889 -- Train accuracy: 84.6640\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16535042 -- Accuracy: 60.60855263\n",
      "\n",
      "Training:\n",
      "Epoch 1437/5000 -- Batch 172/173 -- Loss: 0.01641096 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15970841 -- Accuracy: 60.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 1438/5000 -- Batch 172/173 -- Loss: 0.03956062 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16617919 -- Accuracy: 60.52631579\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1439/5000 -- Batch 172/173 -- Loss: 0.02984084 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14994865 -- Accuracy: 60.03289474\n",
      "\n",
      "Training:\n",
      "Epoch 1440/5000 -- Batch 172/173 -- Loss: 0.02022605 -- Train accuracy: 84.7272\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17996746 -- Accuracy: 59.62171053\n",
      "\n",
      "Training:\n",
      "Epoch 1441/5000 -- Batch 172/173 -- Loss: 0.01828597 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16957461 -- Accuracy: 59.53947368\n",
      "\n",
      "Training:\n",
      "Epoch 1442/5000 -- Batch 172/173 -- Loss: 0.03244053 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16377809 -- Accuracy: 60.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 1443/5000 -- Batch 172/173 -- Loss: 0.02847612 -- Train accuracy: 84.6369\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15963191 -- Accuracy: 60.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 1444/5000 -- Batch 172/173 -- Loss: 0.02897125 -- Train accuracy: 84.6460\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15563753 -- Accuracy: 60.27960526\n",
      "\n",
      "Training:\n",
      "Epoch 1445/5000 -- Batch 172/173 -- Loss: 0.01601090 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16630564 -- Accuracy: 59.62171053\n",
      "\n",
      "Training:\n",
      "Epoch 1446/5000 -- Batch 172/173 -- Loss: 0.02297419 -- Train accuracy: 84.6460\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16328973 -- Accuracy: 60.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 1447/5000 -- Batch 172/173 -- Loss: 0.02784409 -- Train accuracy: 84.6911\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15928427 -- Accuracy: 60.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 1448/5000 -- Batch 172/173 -- Loss: 0.03183696 -- Train accuracy: 84.6730\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16734915 -- Accuracy: 60.03289474\n",
      "\n",
      "Training:\n",
      "Epoch 1449/5000 -- Batch 172/173 -- Loss: 0.00341172 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17816303 -- Accuracy: 60.44407895\n",
      "\n",
      "Training:\n",
      "Epoch 1450/5000 -- Batch 172/173 -- Loss: 0.02116708 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17019095 -- Accuracy: 61.59539474\n",
      "\n",
      "Training:\n",
      "Epoch 1451/5000 -- Batch 172/173 -- Loss: 0.01949413 -- Train accuracy: 84.6821\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16701460 -- Accuracy: 59.29276316\n",
      "\n",
      "Training:\n",
      "Epoch 1452/5000 -- Batch 172/173 -- Loss: 0.02550535 -- Train accuracy: 84.6911\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18223543 -- Accuracy: 60.36184211\n",
      "\n",
      "Training:\n",
      "Epoch 1453/5000 -- Batch 172/173 -- Loss: 0.02523324 -- Train accuracy: 84.5827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16664111 -- Accuracy: 60.03289474\n",
      "\n",
      "Training:\n",
      "Epoch 1454/5000 -- Batch 172/173 -- Loss: 0.02900109 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17365832 -- Accuracy: 60.11513158\n",
      "\n",
      "Training:\n",
      "Epoch 1455/5000 -- Batch 172/173 -- Loss: 0.03098013 -- Train accuracy: 84.7001\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16280144 -- Accuracy: 60.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 1456/5000 -- Batch 172/173 -- Loss: 0.04046560 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15166507 -- Accuracy: 60.27960526\n",
      "\n",
      "Training:\n",
      "Epoch 1457/5000 -- Batch 172/173 -- Loss: 0.02555470 -- Train accuracy: 84.6911\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15712942 -- Accuracy: 60.36184211\n",
      "\n",
      "Training:\n",
      "Epoch 1458/5000 -- Batch 172/173 -- Loss: 0.03137787 -- Train accuracy: 84.6730\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16550202 -- Accuracy: 59.70394737\n",
      "\n",
      "Training:\n",
      "Epoch 1459/5000 -- Batch 172/173 -- Loss: 0.00886064 -- Train accuracy: 84.5466\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14735322 -- Accuracy: 60.60855263\n",
      "\n",
      "Training:\n",
      "Epoch 1460/5000 -- Batch 172/173 -- Loss: 0.02712783 -- Train accuracy: 84.4202\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13868603 -- Accuracy: 60.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 1461/5000 -- Batch 172/173 -- Loss: 0.03782324 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14261101 -- Accuracy: 60.69078947\n",
      "\n",
      "Training:\n",
      "Epoch 1462/5000 -- Batch 172/173 -- Loss: 0.03718618 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15423362 -- Accuracy: 60.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 1463/5000 -- Batch 172/173 -- Loss: 0.05272062 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15457476 -- Accuracy: 60.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 1464/5000 -- Batch 172/173 -- Loss: 0.02948871 -- Train accuracy: 84.5466\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14666347 -- Accuracy: 60.03289474\n",
      "\n",
      "Training:\n",
      "Epoch 1465/5000 -- Batch 172/173 -- Loss: 0.02358062 -- Train accuracy: 84.4743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15187025 -- Accuracy: 59.95065789\n",
      "\n",
      "Training:\n",
      "Epoch 1466/5000 -- Batch 172/173 -- Loss: 0.01639348 -- Train accuracy: 84.5827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14210680 -- Accuracy: 60.69078947\n",
      "\n",
      "Training:\n",
      "Epoch 1467/5000 -- Batch 172/173 -- Loss: 0.02499229 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16894226 -- Accuracy: 60.11513158\n",
      "\n",
      "Training:\n",
      "Epoch 1468/5000 -- Batch 172/173 -- Loss: 0.02152040 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14790724 -- Accuracy: 61.01973684\n",
      "\n",
      "Training:\n",
      "Epoch 1469/5000 -- Batch 172/173 -- Loss: 0.00796226 -- Train accuracy: 84.7001\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16881645 -- Accuracy: 60.36184211\n",
      "\n",
      "Training:\n",
      "Epoch 1470/5000 -- Batch 172/173 -- Loss: 0.03109093 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15421252 -- Accuracy: 60.69078947\n",
      "\n",
      "Training:\n",
      "Epoch 1471/5000 -- Batch 172/173 -- Loss: 0.02781611 -- Train accuracy: 84.7272\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16902784 -- Accuracy: 60.11513158\n",
      "\n",
      "Training:\n",
      "Epoch 1472/5000 -- Batch 172/173 -- Loss: 0.02538372 -- Train accuracy: 84.7092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16879456 -- Accuracy: 60.44407895\n",
      "\n",
      "Training:\n",
      "Epoch 1473/5000 -- Batch 172/173 -- Loss: 0.01118657 -- Train accuracy: 84.7001\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16316315 -- Accuracy: 60.60855263\n",
      "\n",
      "Training:\n",
      "Epoch 1474/5000 -- Batch 172/173 -- Loss: 0.04493095 -- Train accuracy: 84.6369\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15102558 -- Accuracy: 60.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 1475/5000 -- Batch 172/173 -- Loss: 0.02972357 -- Train accuracy: 84.4743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13867171 -- Accuracy: 60.36184211\n",
      "\n",
      "Training:\n",
      "Epoch 1476/5000 -- Batch 172/173 -- Loss: 0.02582109 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14609212 -- Accuracy: 59.62171053\n",
      "\n",
      "Training:\n",
      "Epoch 1477/5000 -- Batch 172/173 -- Loss: 0.03123127 -- Train accuracy: 84.6911\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15049279 -- Accuracy: 59.29276316\n",
      "\n",
      "Training:\n",
      "Epoch 1478/5000 -- Batch 172/173 -- Loss: 0.03107369 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17140164 -- Accuracy: 60.11513158\n",
      "\n",
      "Training:\n",
      "Epoch 1479/5000 -- Batch 172/173 -- Loss: 0.01128144 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14343686 -- Accuracy: 60.27960526\n",
      "\n",
      "Training:\n",
      "Epoch 1480/5000 -- Batch 172/173 -- Loss: 0.01529774 -- Train accuracy: 84.7272\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17508071 -- Accuracy: 59.86842105\n",
      "\n",
      "Training:\n",
      "Epoch 1481/5000 -- Batch 172/173 -- Loss: 0.01431975 -- Train accuracy: 84.6640\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17270389 -- Accuracy: 60.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 1482/5000 -- Batch 172/173 -- Loss: 0.05716321 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16167678 -- Accuracy: 60.03289474\n",
      "\n",
      "Training:\n",
      "Epoch 1483/5000 -- Batch 172/173 -- Loss: 0.02060871 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15101796 -- Accuracy: 60.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 1484/5000 -- Batch 172/173 -- Loss: 0.01805550 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13843777 -- Accuracy: 60.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 1485/5000 -- Batch 172/173 -- Loss: 0.02244432 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16399900 -- Accuracy: 59.95065789\n",
      "\n",
      "Training:\n",
      "Epoch 1486/5000 -- Batch 172/173 -- Loss: 0.00799363 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16967685 -- Accuracy: 60.27960526\n",
      "\n",
      "Training:\n",
      "Epoch 1487/5000 -- Batch 172/173 -- Loss: 0.01945739 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17183969 -- Accuracy: 59.95065789\n",
      "\n",
      "Training:\n",
      "Epoch 1488/5000 -- Batch 172/173 -- Loss: 0.02070981 -- Train accuracy: 84.6008\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15848706 -- Accuracy: 59.78618421\n",
      "\n",
      "Training:\n",
      "Epoch 1489/5000 -- Batch 172/173 -- Loss: 0.04558043 -- Train accuracy: 84.7001\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14312013 -- Accuracy: 60.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 1490/5000 -- Batch 172/173 -- Loss: 0.06326551 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15017726 -- Accuracy: 60.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 1491/5000 -- Batch 172/173 -- Loss: 0.01985890 -- Train accuracy: 84.7092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15404020 -- Accuracy: 60.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 1492/5000 -- Batch 172/173 -- Loss: 0.04025948 -- Train accuracy: 84.7272\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16656008 -- Accuracy: 60.19736842\n",
      "\n",
      "Training:\n",
      "Epoch 1493/5000 -- Batch 172/173 -- Loss: 0.06464433 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17504303 -- Accuracy: 60.77302632\n",
      "\n",
      "Training:\n",
      "Epoch 1494/5000 -- Batch 172/173 -- Loss: 0.03033501 -- Train accuracy: 84.7272\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16706718 -- Accuracy: 61.01973684\n",
      "\n",
      "Training:\n",
      "Epoch 1495/5000 -- Batch 172/173 -- Loss: 0.04108021 -- Train accuracy: 84.6821\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14564670 -- Accuracy: 60.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 1496/5000 -- Batch 172/173 -- Loss: 0.06607201 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15439310 -- Accuracy: 60.69078947\n",
      "\n",
      "Training:\n",
      "Epoch 1497/5000 -- Batch 172/173 -- Loss: 0.06198745 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16029630 -- Accuracy: 61.10197368\n",
      "\n",
      "Training:\n",
      "Epoch 1498/5000 -- Batch 172/173 -- Loss: 0.02087487 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17713073 -- Accuracy: 59.78618421\n",
      "\n",
      "Training:\n",
      "Epoch 1499/5000 -- Batch 172/173 -- Loss: 0.09022532 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17205158 -- Accuracy: 60.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 1500/5000 -- Batch 172/173 -- Loss: 0.02430374 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16934702 -- Accuracy: 60.60855263\n",
      "\n",
      "Training:\n",
      "Epoch 1501/5000 -- Batch 172/173 -- Loss: 0.02647635 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17805648 -- Accuracy: 60.44407895\n",
      "\n",
      "Training:\n",
      "Epoch 1502/5000 -- Batch 172/173 -- Loss: 0.01076473 -- Train accuracy: 84.6911\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18215040 -- Accuracy: 60.69078947\n",
      "\n",
      "Training:\n",
      "Epoch 1503/5000 -- Batch 172/173 -- Loss: 0.11070447 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18155884 -- Accuracy: 60.27960526\n",
      "\n",
      "Training:\n",
      "Epoch 1504/5000 -- Batch 172/173 -- Loss: 0.06032007 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16294991 -- Accuracy: 60.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 1505/5000 -- Batch 172/173 -- Loss: 0.02943886 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16277423 -- Accuracy: 60.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 1506/5000 -- Batch 172/173 -- Loss: 0.03804234 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15373662 -- Accuracy: 61.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 1507/5000 -- Batch 172/173 -- Loss: 0.01897279 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.18121852 -- Accuracy: 60.60855263\n",
      "\n",
      "Training:\n",
      "Epoch 1508/5000 -- Batch 172/173 -- Loss: 0.02161537 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17396037 -- Accuracy: 60.69078947\n",
      "\n",
      "Training:\n",
      "Epoch 1509/5000 -- Batch 172/173 -- Loss: 0.02333676 -- Train accuracy: 84.6369\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17566995 -- Accuracy: 61.10197368\n",
      "\n",
      "Training:\n",
      "Epoch 1510/5000 -- Batch 172/173 -- Loss: 0.01009749 -- Train accuracy: 84.6821\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16819912 -- Accuracy: 61.43092105\n",
      "\n",
      "Training:\n",
      "Epoch 1511/5000 -- Batch 172/173 -- Loss: 0.01442965 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16696320 -- Accuracy: 61.59539474\n",
      "\n",
      "Training:\n",
      "Epoch 1512/5000 -- Batch 172/173 -- Loss: 0.00214918 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17873086 -- Accuracy: 60.69078947\n",
      "\n",
      "Training:\n",
      "Epoch 1513/5000 -- Batch 172/173 -- Loss: 0.03303170 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15491083 -- Accuracy: 60.52631579\n",
      "\n",
      "Training:\n",
      "Epoch 1514/5000 -- Batch 172/173 -- Loss: 0.04669692 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14846416 -- Accuracy: 60.85526316\n",
      "\n",
      "Training:\n",
      "Epoch 1515/5000 -- Batch 172/173 -- Loss: 0.01896969 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15621068 -- Accuracy: 61.43092105\n",
      "\n",
      "Training:\n",
      "Epoch 1516/5000 -- Batch 172/173 -- Loss: 0.01204099 -- Train accuracy: 84.5376\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17910100 -- Accuracy: 60.44407895\n",
      "\n",
      "Training:\n",
      "Epoch 1517/5000 -- Batch 172/173 -- Loss: 0.03701986 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16726264 -- Accuracy: 61.34868421\n",
      "\n",
      "Training:\n",
      "Epoch 1518/5000 -- Batch 172/173 -- Loss: 0.02607551 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17405250 -- Accuracy: 60.44407895\n",
      "\n",
      "Training:\n",
      "Epoch 1519/5000 -- Batch 172/173 -- Loss: 0.05354153 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16148816 -- Accuracy: 61.10197368\n",
      "\n",
      "Training:\n",
      "Epoch 1520/5000 -- Batch 172/173 -- Loss: 0.02194554 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15805367 -- Accuracy: 61.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 1521/5000 -- Batch 172/173 -- Loss: 0.00920718 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15779256 -- Accuracy: 60.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 1522/5000 -- Batch 172/173 -- Loss: 0.02427327 -- Train accuracy: 84.7092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13199951 -- Accuracy: 61.34868421\n",
      "\n",
      "Training:\n",
      "Epoch 1523/5000 -- Batch 172/173 -- Loss: 0.01971845 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15667652 -- Accuracy: 61.26644737\n",
      "\n",
      "Training:\n",
      "Epoch 1524/5000 -- Batch 172/173 -- Loss: 0.02045068 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15618107 -- Accuracy: 62.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 1525/5000 -- Batch 172/173 -- Loss: 0.01511929 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14558346 -- Accuracy: 60.77302632\n",
      "\n",
      "Training:\n",
      "Epoch 1526/5000 -- Batch 172/173 -- Loss: 0.02241206 -- Train accuracy: 84.5737\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13035720 -- Accuracy: 61.18421053\n",
      "\n",
      "Training:\n",
      "Epoch 1527/5000 -- Batch 172/173 -- Loss: 0.01692417 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13831521 -- Accuracy: 60.77302632\n",
      "\n",
      "Training:\n",
      "Epoch 1528/5000 -- Batch 172/173 -- Loss: 0.01363328 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15354417 -- Accuracy: 61.01973684\n",
      "\n",
      "Training:\n",
      "Epoch 1529/5000 -- Batch 172/173 -- Loss: 0.01479818 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14313303 -- Accuracy: 60.60855263\n",
      "\n",
      "Training:\n",
      "Epoch 1530/5000 -- Batch 172/173 -- Loss: 0.01203873 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15441252 -- Accuracy: 61.34868421\n",
      "\n",
      "Training:\n",
      "Epoch 1531/5000 -- Batch 172/173 -- Loss: 0.02533273 -- Train accuracy: 84.6730\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14725275 -- Accuracy: 60.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 1532/5000 -- Batch 172/173 -- Loss: 0.01898308 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14183477 -- Accuracy: 61.18421053\n",
      "\n",
      "Training:\n",
      "Epoch 1533/5000 -- Batch 172/173 -- Loss: 0.02587437 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15716309 -- Accuracy: 61.01973684\n",
      "\n",
      "Training:\n",
      "Epoch 1534/5000 -- Batch 172/173 -- Loss: 0.01823364 -- Train accuracy: 84.6911\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14875814 -- Accuracy: 61.43092105\n",
      "\n",
      "Training:\n",
      "Epoch 1535/5000 -- Batch 172/173 -- Loss: 0.01533723 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14567975 -- Accuracy: 61.18421053\n",
      "\n",
      "Training:\n",
      "Epoch 1536/5000 -- Batch 172/173 -- Loss: 0.03078102 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13672886 -- Accuracy: 61.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 1537/5000 -- Batch 172/173 -- Loss: 0.03279009 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15355815 -- Accuracy: 61.10197368\n",
      "\n",
      "Training:\n",
      "Epoch 1538/5000 -- Batch 172/173 -- Loss: 0.02237318 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14853386 -- Accuracy: 61.43092105\n",
      "\n",
      "Training:\n",
      "Epoch 1539/5000 -- Batch 172/173 -- Loss: 0.01358853 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14956257 -- Accuracy: 61.67763158\n",
      "\n",
      "Training:\n",
      "Epoch 1540/5000 -- Batch 172/173 -- Loss: 0.09828401 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14521689 -- Accuracy: 60.93750000\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1541/5000 -- Batch 172/173 -- Loss: 0.01219154 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15431109 -- Accuracy: 62.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 1542/5000 -- Batch 172/173 -- Loss: 0.01905063 -- Train accuracy: 84.6821\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17130725 -- Accuracy: 61.01973684\n",
      "\n",
      "Training:\n",
      "Epoch 1543/5000 -- Batch 172/173 -- Loss: 0.01207728 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14238124 -- Accuracy: 61.26644737\n",
      "\n",
      "Training:\n",
      "Epoch 1544/5000 -- Batch 172/173 -- Loss: 0.01369251 -- Train accuracy: 84.6730\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15503381 -- Accuracy: 61.26644737\n",
      "\n",
      "Training:\n",
      "Epoch 1545/5000 -- Batch 172/173 -- Loss: 0.07219110 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15318563 -- Accuracy: 61.34868421\n",
      "\n",
      "Training:\n",
      "Epoch 1546/5000 -- Batch 172/173 -- Loss: 0.02024828 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16838808 -- Accuracy: 61.18421053\n",
      "\n",
      "Training:\n",
      "Epoch 1547/5000 -- Batch 172/173 -- Loss: 0.01778162 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15992654 -- Accuracy: 61.67763158\n",
      "\n",
      "Training:\n",
      "Epoch 1548/5000 -- Batch 172/173 -- Loss: 0.00684657 -- Train accuracy: 84.6098\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13597616 -- Accuracy: 61.26644737\n",
      "\n",
      "Training:\n",
      "Epoch 1549/5000 -- Batch 172/173 -- Loss: 0.02007739 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13758326 -- Accuracy: 61.84210526\n",
      "\n",
      "Training:\n",
      "Epoch 1550/5000 -- Batch 172/173 -- Loss: 0.01618411 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13268977 -- Accuracy: 61.67763158\n",
      "\n",
      "Training:\n",
      "Epoch 1551/5000 -- Batch 172/173 -- Loss: 0.02476247 -- Train accuracy: 84.6730\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14971365 -- Accuracy: 61.10197368\n",
      "\n",
      "Training:\n",
      "Epoch 1552/5000 -- Batch 172/173 -- Loss: 0.03792229 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15106237 -- Accuracy: 61.59539474\n",
      "\n",
      "Training:\n",
      "Epoch 1553/5000 -- Batch 172/173 -- Loss: 0.02630292 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14540578 -- Accuracy: 62.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 1554/5000 -- Batch 172/173 -- Loss: 0.01482483 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14202494 -- Accuracy: 61.43092105\n",
      "\n",
      "Training:\n",
      "Epoch 1555/5000 -- Batch 172/173 -- Loss: 0.03957485 -- Train accuracy: 84.7001\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15795333 -- Accuracy: 61.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 1556/5000 -- Batch 172/173 -- Loss: 0.02168633 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15444448 -- Accuracy: 61.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 1557/5000 -- Batch 172/173 -- Loss: 0.02981086 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16183972 -- Accuracy: 60.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 1558/5000 -- Batch 172/173 -- Loss: 0.02533663 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15354671 -- Accuracy: 61.75986842\n",
      "\n",
      "Training:\n",
      "Epoch 1559/5000 -- Batch 172/173 -- Loss: 0.00396030 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16887030 -- Accuracy: 62.17105263\n",
      "\n",
      "Training:\n",
      "Epoch 1560/5000 -- Batch 172/173 -- Loss: 0.02211103 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16203670 -- Accuracy: 61.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 1561/5000 -- Batch 172/173 -- Loss: 0.02773137 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16155175 -- Accuracy: 61.10197368\n",
      "\n",
      "Training:\n",
      "Epoch 1562/5000 -- Batch 172/173 -- Loss: 0.01628077 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15694251 -- Accuracy: 61.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 1563/5000 -- Batch 172/173 -- Loss: 0.02048190 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15971120 -- Accuracy: 61.59539474\n",
      "\n",
      "Training:\n",
      "Epoch 1564/5000 -- Batch 172/173 -- Loss: 0.02097796 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15549285 -- Accuracy: 61.92434211\n",
      "\n",
      "Training:\n",
      "Epoch 1565/5000 -- Batch 172/173 -- Loss: 0.02504176 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15614799 -- Accuracy: 61.26644737\n",
      "\n",
      "Training:\n",
      "Epoch 1566/5000 -- Batch 172/173 -- Loss: 0.02570152 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15727010 -- Accuracy: 61.67763158\n",
      "\n",
      "Training:\n",
      "Epoch 1567/5000 -- Batch 172/173 -- Loss: 0.02172433 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15579139 -- Accuracy: 61.43092105\n",
      "\n",
      "Training:\n",
      "Epoch 1568/5000 -- Batch 172/173 -- Loss: 0.01156429 -- Train accuracy: 84.4111\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13995926 -- Accuracy: 61.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 1569/5000 -- Batch 172/173 -- Loss: 0.03396914 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14586057 -- Accuracy: 61.92434211\n",
      "\n",
      "Training:\n",
      "Epoch 1570/5000 -- Batch 172/173 -- Loss: 0.01259875 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12962190 -- Accuracy: 61.67763158\n",
      "\n",
      "Training:\n",
      "Epoch 1571/5000 -- Batch 172/173 -- Loss: 0.03378469 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14130863 -- Accuracy: 61.59539474\n",
      "\n",
      "Training:\n",
      "Epoch 1572/5000 -- Batch 172/173 -- Loss: 0.01850763 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13451423 -- Accuracy: 61.43092105\n",
      "\n",
      "Training:\n",
      "Epoch 1573/5000 -- Batch 172/173 -- Loss: 0.01005377 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13767096 -- Accuracy: 61.10197368\n",
      "\n",
      "Training:\n",
      "Epoch 1574/5000 -- Batch 172/173 -- Loss: 0.02742532 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14671235 -- Accuracy: 61.43092105\n",
      "\n",
      "Training:\n",
      "Epoch 1575/5000 -- Batch 172/173 -- Loss: 0.04038401 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14213513 -- Accuracy: 61.67763158\n",
      "\n",
      "Training:\n",
      "Epoch 1576/5000 -- Batch 172/173 -- Loss: 0.02313129 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14396961 -- Accuracy: 61.18421053\n",
      "\n",
      "Training:\n",
      "Epoch 1577/5000 -- Batch 172/173 -- Loss: 0.02795331 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14306900 -- Accuracy: 61.84210526\n",
      "\n",
      "Training:\n",
      "Epoch 1578/5000 -- Batch 172/173 -- Loss: 0.06981497 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14363979 -- Accuracy: 61.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 1579/5000 -- Batch 172/173 -- Loss: 0.01220026 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15458171 -- Accuracy: 61.18421053\n",
      "\n",
      "Training:\n",
      "Epoch 1580/5000 -- Batch 172/173 -- Loss: 0.02035054 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14064487 -- Accuracy: 61.34868421\n",
      "\n",
      "Training:\n",
      "Epoch 1581/5000 -- Batch 172/173 -- Loss: 0.01086584 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14679996 -- Accuracy: 61.43092105\n",
      "\n",
      "Training:\n",
      "Epoch 1582/5000 -- Batch 172/173 -- Loss: 0.01495154 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15280661 -- Accuracy: 61.75986842\n",
      "\n",
      "Training:\n",
      "Epoch 1583/5000 -- Batch 172/173 -- Loss: 0.00773372 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15121391 -- Accuracy: 62.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 1584/5000 -- Batch 172/173 -- Loss: 0.01555357 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15312938 -- Accuracy: 61.67763158\n",
      "\n",
      "Training:\n",
      "Epoch 1585/5000 -- Batch 172/173 -- Loss: 0.02297022 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15828440 -- Accuracy: 61.92434211\n",
      "\n",
      "Training:\n",
      "Epoch 1586/5000 -- Batch 172/173 -- Loss: 0.02302786 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16981480 -- Accuracy: 61.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 1587/5000 -- Batch 172/173 -- Loss: 0.01073993 -- Train accuracy: 84.6640\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14899696 -- Accuracy: 61.34868421\n",
      "\n",
      "Training:\n",
      "Epoch 1588/5000 -- Batch 172/173 -- Loss: 0.01586347 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15327763 -- Accuracy: 62.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 1589/5000 -- Batch 172/173 -- Loss: 0.02372805 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14747667 -- Accuracy: 61.92434211\n",
      "\n",
      "Training:\n",
      "Epoch 1590/5000 -- Batch 172/173 -- Loss: 0.03616061 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14782622 -- Accuracy: 61.59539474\n",
      "\n",
      "Training:\n",
      "Epoch 1591/5000 -- Batch 172/173 -- Loss: 0.02468153 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16591672 -- Accuracy: 61.84210526\n",
      "\n",
      "Training:\n",
      "Epoch 1592/5000 -- Batch 172/173 -- Loss: 0.00906937 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16089548 -- Accuracy: 61.75986842\n",
      "\n",
      "Training:\n",
      "Epoch 1593/5000 -- Batch 172/173 -- Loss: 0.02204139 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15049210 -- Accuracy: 60.93750000\n",
      "\n",
      "Training:\n",
      "Epoch 1594/5000 -- Batch 172/173 -- Loss: 0.05788652 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15919411 -- Accuracy: 62.33552632\n",
      "\n",
      "Training:\n",
      "Epoch 1595/5000 -- Batch 172/173 -- Loss: 0.03612214 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15826833 -- Accuracy: 61.84210526\n",
      "\n",
      "Training:\n",
      "Epoch 1596/5000 -- Batch 172/173 -- Loss: 0.03574538 -- Train accuracy: 84.5556\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14822847 -- Accuracy: 61.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 1597/5000 -- Batch 172/173 -- Loss: 0.03314245 -- Train accuracy: 84.6730\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15090949 -- Accuracy: 62.33552632\n",
      "\n",
      "Training:\n",
      "Epoch 1598/5000 -- Batch 172/173 -- Loss: 0.00513820 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15026810 -- Accuracy: 62.58223684\n",
      "\n",
      "Training:\n",
      "Epoch 1599/5000 -- Batch 172/173 -- Loss: 0.01086146 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14335385 -- Accuracy: 61.59539474\n",
      "\n",
      "Training:\n",
      "Epoch 1600/5000 -- Batch 172/173 -- Loss: 0.03095147 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16234415 -- Accuracy: 61.92434211\n",
      "\n",
      "Training:\n",
      "Epoch 1601/5000 -- Batch 172/173 -- Loss: 0.03047794 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14768512 -- Accuracy: 62.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 1602/5000 -- Batch 172/173 -- Loss: 0.02729932 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14266492 -- Accuracy: 62.33552632\n",
      "\n",
      "Training:\n",
      "Epoch 1603/5000 -- Batch 172/173 -- Loss: 0.02361401 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14576847 -- Accuracy: 61.92434211\n",
      "\n",
      "Training:\n",
      "Epoch 1604/5000 -- Batch 172/173 -- Loss: 0.01893218 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14610603 -- Accuracy: 62.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 1605/5000 -- Batch 172/173 -- Loss: 0.03484111 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14858761 -- Accuracy: 62.17105263\n",
      "\n",
      "Training:\n",
      "Epoch 1606/5000 -- Batch 172/173 -- Loss: 0.02758511 -- Train accuracy: 84.5376\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13184872 -- Accuracy: 62.50000000\n",
      "\n",
      "Training:\n",
      "Epoch 1607/5000 -- Batch 172/173 -- Loss: 0.01694048 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13083399 -- Accuracy: 61.34868421\n",
      "\n",
      "Training:\n",
      "Epoch 1608/5000 -- Batch 172/173 -- Loss: 0.03771459 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13964243 -- Accuracy: 62.25328947\n",
      "\n",
      "Training:\n",
      "Epoch 1609/5000 -- Batch 172/173 -- Loss: 0.02764102 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14483957 -- Accuracy: 62.33552632\n",
      "\n",
      "Training:\n",
      "Epoch 1610/5000 -- Batch 172/173 -- Loss: 0.02441514 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13520482 -- Accuracy: 62.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 1611/5000 -- Batch 172/173 -- Loss: 0.02768053 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15000263 -- Accuracy: 61.75986842\n",
      "\n",
      "Training:\n",
      "Epoch 1612/5000 -- Batch 172/173 -- Loss: 0.05905902 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13820499 -- Accuracy: 62.50000000\n",
      "\n",
      "Training:\n",
      "Epoch 1613/5000 -- Batch 172/173 -- Loss: 0.03482452 -- Train accuracy: 84.7092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13763250 -- Accuracy: 62.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 1614/5000 -- Batch 172/173 -- Loss: 0.02070128 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14571607 -- Accuracy: 61.75986842\n",
      "\n",
      "Training:\n",
      "Epoch 1615/5000 -- Batch 172/173 -- Loss: 0.03460486 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14097551 -- Accuracy: 61.84210526\n",
      "\n",
      "Training:\n",
      "Epoch 1616/5000 -- Batch 172/173 -- Loss: 0.00910703 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15393444 -- Accuracy: 62.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 1617/5000 -- Batch 172/173 -- Loss: 0.03676261 -- Train accuracy: 84.6911\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13995966 -- Accuracy: 62.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 1618/5000 -- Batch 172/173 -- Loss: 0.01087127 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14505035 -- Accuracy: 61.75986842\n",
      "\n",
      "Training:\n",
      "Epoch 1619/5000 -- Batch 172/173 -- Loss: 0.02915072 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14170492 -- Accuracy: 62.17105263\n",
      "\n",
      "Training:\n",
      "Epoch 1620/5000 -- Batch 172/173 -- Loss: 0.02848293 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14820443 -- Accuracy: 62.25328947\n",
      "\n",
      "Training:\n",
      "Epoch 1621/5000 -- Batch 172/173 -- Loss: 0.03897807 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13825265 -- Accuracy: 62.58223684\n",
      "\n",
      "Training:\n",
      "Epoch 1622/5000 -- Batch 172/173 -- Loss: 0.02559867 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15667046 -- Accuracy: 62.17105263\n",
      "\n",
      "Training:\n",
      "Epoch 1623/5000 -- Batch 172/173 -- Loss: 0.03005097 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14611542 -- Accuracy: 62.33552632\n",
      "\n",
      "Training:\n",
      "Epoch 1624/5000 -- Batch 172/173 -- Loss: 0.03583136 -- Train accuracy: 84.5285\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13815515 -- Accuracy: 62.82894737\n",
      "\n",
      "Training:\n",
      "Epoch 1625/5000 -- Batch 172/173 -- Loss: 0.03466734 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14535141 -- Accuracy: 62.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 1626/5000 -- Batch 172/173 -- Loss: 0.01460286 -- Train accuracy: 84.7272\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13896096 -- Accuracy: 62.25328947\n",
      "\n",
      "Training:\n",
      "Epoch 1627/5000 -- Batch 172/173 -- Loss: 0.02653994 -- Train accuracy: 84.6911\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15415100 -- Accuracy: 62.25328947\n",
      "\n",
      "Training:\n",
      "Epoch 1628/5000 -- Batch 172/173 -- Loss: 0.02928984 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15040538 -- Accuracy: 62.33552632\n",
      "\n",
      "Training:\n",
      "Epoch 1629/5000 -- Batch 172/173 -- Loss: 0.04017475 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14311735 -- Accuracy: 62.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 1630/5000 -- Batch 172/173 -- Loss: 0.06437437 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15350164 -- Accuracy: 62.74671053\n",
      "\n",
      "Training:\n",
      "Epoch 1631/5000 -- Batch 172/173 -- Loss: 0.01281835 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15307417 -- Accuracy: 62.50000000\n",
      "\n",
      "Training:\n",
      "Epoch 1632/5000 -- Batch 172/173 -- Loss: 0.06564873 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14202763 -- Accuracy: 62.33552632\n",
      "\n",
      "Training:\n",
      "Epoch 1633/5000 -- Batch 172/173 -- Loss: 0.03779838 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15784476 -- Accuracy: 62.50000000\n",
      "\n",
      "Training:\n",
      "Epoch 1634/5000 -- Batch 172/173 -- Loss: 0.02467384 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15358377 -- Accuracy: 62.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 1635/5000 -- Batch 172/173 -- Loss: 0.02785351 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14185550 -- Accuracy: 62.50000000\n",
      "\n",
      "Training:\n",
      "Epoch 1636/5000 -- Batch 172/173 -- Loss: 0.01795358 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15282475 -- Accuracy: 62.66447368\n",
      "\n",
      "Training:\n",
      "Epoch 1637/5000 -- Batch 172/173 -- Loss: 0.03738523 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15417997 -- Accuracy: 62.33552632\n",
      "\n",
      "Training:\n",
      "Epoch 1638/5000 -- Batch 172/173 -- Loss: 0.03043713 -- Train accuracy: 84.5647\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13885314 -- Accuracy: 62.91118421\n",
      "\n",
      "Training:\n",
      "Epoch 1639/5000 -- Batch 172/173 -- Loss: 0.02072672 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13814797 -- Accuracy: 62.99342105\n",
      "\n",
      "Training:\n",
      "Epoch 1640/5000 -- Batch 172/173 -- Loss: 0.02682884 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14106333 -- Accuracy: 62.00657895\n",
      "\n",
      "Training:\n",
      "Epoch 1641/5000 -- Batch 172/173 -- Loss: 0.02076470 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.17412890 -- Accuracy: 62.91118421\n",
      "\n",
      "Training:\n",
      "Epoch 1642/5000 -- Batch 172/173 -- Loss: 0.02211919 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16613928 -- Accuracy: 62.25328947\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1643/5000 -- Batch 172/173 -- Loss: 0.04059530 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13822628 -- Accuracy: 63.15789474\n",
      "\n",
      "Training:\n",
      "Epoch 1644/5000 -- Batch 172/173 -- Loss: 0.04033705 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14401779 -- Accuracy: 61.51315789\n",
      "\n",
      "Training:\n",
      "Epoch 1645/5000 -- Batch 172/173 -- Loss: 0.02204164 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14590027 -- Accuracy: 62.74671053\n",
      "\n",
      "Training:\n",
      "Epoch 1646/5000 -- Batch 172/173 -- Loss: 0.02543246 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14518105 -- Accuracy: 62.08881579\n",
      "\n",
      "Training:\n",
      "Epoch 1647/5000 -- Batch 172/173 -- Loss: 0.01432775 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14517867 -- Accuracy: 62.82894737\n",
      "\n",
      "Training:\n",
      "Epoch 1648/5000 -- Batch 172/173 -- Loss: 0.04218945 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12941281 -- Accuracy: 62.66447368\n",
      "\n",
      "Training:\n",
      "Epoch 1649/5000 -- Batch 172/173 -- Loss: 0.02400937 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16500956 -- Accuracy: 61.75986842\n",
      "\n",
      "Training:\n",
      "Epoch 1650/5000 -- Batch 172/173 -- Loss: 0.04106076 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15894602 -- Accuracy: 62.25328947\n",
      "\n",
      "Training:\n",
      "Epoch 1651/5000 -- Batch 172/173 -- Loss: 0.01846923 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16656505 -- Accuracy: 62.50000000\n",
      "\n",
      "Training:\n",
      "Epoch 1652/5000 -- Batch 172/173 -- Loss: 0.03699872 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16015437 -- Accuracy: 62.08881579\n",
      "\n",
      "Training:\n",
      "Epoch 1653/5000 -- Batch 172/173 -- Loss: 0.01323391 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13386405 -- Accuracy: 62.50000000\n",
      "\n",
      "Training:\n",
      "Epoch 1654/5000 -- Batch 172/173 -- Loss: 0.02445108 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14469282 -- Accuracy: 62.33552632\n",
      "\n",
      "Training:\n",
      "Epoch 1655/5000 -- Batch 172/173 -- Loss: 0.02480207 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13800923 -- Accuracy: 62.50000000\n",
      "\n",
      "Training:\n",
      "Epoch 1656/5000 -- Batch 172/173 -- Loss: 0.03648458 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14337120 -- Accuracy: 62.66447368\n",
      "\n",
      "Training:\n",
      "Epoch 1657/5000 -- Batch 172/173 -- Loss: 0.03056569 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15432154 -- Accuracy: 61.75986842\n",
      "\n",
      "Training:\n",
      "Epoch 1658/5000 -- Batch 172/173 -- Loss: 0.00673541 -- Train accuracy: 84.6369\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13198357 -- Accuracy: 63.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 1659/5000 -- Batch 172/173 -- Loss: 0.01889443 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15649992 -- Accuracy: 62.25328947\n",
      "\n",
      "Training:\n",
      "Epoch 1660/5000 -- Batch 172/173 -- Loss: 0.01139031 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14921074 -- Accuracy: 62.25328947\n",
      "\n",
      "Training:\n",
      "Epoch 1661/5000 -- Batch 172/173 -- Loss: 0.05828945 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14936914 -- Accuracy: 62.25328947\n",
      "\n",
      "Training:\n",
      "Epoch 1662/5000 -- Batch 172/173 -- Loss: 0.03144053 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15330150 -- Accuracy: 61.84210526\n",
      "\n",
      "Training:\n",
      "Epoch 1663/5000 -- Batch 172/173 -- Loss: 0.01786554 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15162751 -- Accuracy: 62.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 1664/5000 -- Batch 172/173 -- Loss: 0.03105872 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15377639 -- Accuracy: 62.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 1665/5000 -- Batch 172/173 -- Loss: 0.06787446 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15734635 -- Accuracy: 61.92434211\n",
      "\n",
      "Training:\n",
      "Epoch 1666/5000 -- Batch 172/173 -- Loss: 0.03627475 -- Train accuracy: 84.7001\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15698464 -- Accuracy: 62.82894737\n",
      "\n",
      "Training:\n",
      "Epoch 1667/5000 -- Batch 172/173 -- Loss: 0.02069396 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15365677 -- Accuracy: 62.50000000\n",
      "\n",
      "Training:\n",
      "Epoch 1668/5000 -- Batch 172/173 -- Loss: 0.01316039 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15605763 -- Accuracy: 62.50000000\n",
      "\n",
      "Training:\n",
      "Epoch 1669/5000 -- Batch 172/173 -- Loss: 0.01026664 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15276539 -- Accuracy: 62.17105263\n",
      "\n",
      "Training:\n",
      "Epoch 1670/5000 -- Batch 172/173 -- Loss: 0.03878309 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15406678 -- Accuracy: 62.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 1671/5000 -- Batch 172/173 -- Loss: 0.04408623 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15323251 -- Accuracy: 63.15789474\n",
      "\n",
      "Training:\n",
      "Epoch 1672/5000 -- Batch 172/173 -- Loss: 0.02633038 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15148794 -- Accuracy: 63.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 1673/5000 -- Batch 172/173 -- Loss: 0.01640521 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15155828 -- Accuracy: 62.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 1674/5000 -- Batch 172/173 -- Loss: 0.02055947 -- Train accuracy: 84.9530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15111521 -- Accuracy: 62.66447368\n",
      "\n",
      "Training:\n",
      "Epoch 1675/5000 -- Batch 172/173 -- Loss: 0.01451666 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15306250 -- Accuracy: 62.58223684\n",
      "\n",
      "Training:\n",
      "Epoch 1676/5000 -- Batch 172/173 -- Loss: 0.01867758 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15773374 -- Accuracy: 62.99342105\n",
      "\n",
      "Training:\n",
      "Epoch 1677/5000 -- Batch 172/173 -- Loss: 0.02770060 -- Train accuracy: 84.6911\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15202216 -- Accuracy: 62.58223684\n",
      "\n",
      "Training:\n",
      "Epoch 1678/5000 -- Batch 172/173 -- Loss: 0.03418497 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14149087 -- Accuracy: 62.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 1679/5000 -- Batch 172/173 -- Loss: 0.02302740 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14905838 -- Accuracy: 62.99342105\n",
      "\n",
      "Training:\n",
      "Epoch 1680/5000 -- Batch 172/173 -- Loss: 0.02921769 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15424281 -- Accuracy: 62.58223684\n",
      "\n",
      "Training:\n",
      "Epoch 1681/5000 -- Batch 172/173 -- Loss: 0.04584198 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14817309 -- Accuracy: 62.91118421\n",
      "\n",
      "Training:\n",
      "Epoch 1682/5000 -- Batch 172/173 -- Loss: 0.02745838 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15611525 -- Accuracy: 62.74671053\n",
      "\n",
      "Training:\n",
      "Epoch 1683/5000 -- Batch 172/173 -- Loss: 0.02915648 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15211377 -- Accuracy: 62.66447368\n",
      "\n",
      "Training:\n",
      "Epoch 1684/5000 -- Batch 172/173 -- Loss: 0.02590407 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14164797 -- Accuracy: 62.66447368\n",
      "\n",
      "Training:\n",
      "Epoch 1685/5000 -- Batch 172/173 -- Loss: 0.02486628 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15388309 -- Accuracy: 62.66447368\n",
      "\n",
      "Training:\n",
      "Epoch 1686/5000 -- Batch 172/173 -- Loss: 0.01505173 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15410136 -- Accuracy: 63.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 1687/5000 -- Batch 172/173 -- Loss: 0.04314082 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14473550 -- Accuracy: 62.91118421\n",
      "\n",
      "Training:\n",
      "Epoch 1688/5000 -- Batch 172/173 -- Loss: 0.02087542 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14681299 -- Accuracy: 63.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 1689/5000 -- Batch 172/173 -- Loss: 0.01348736 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14598599 -- Accuracy: 62.74671053\n",
      "\n",
      "Training:\n",
      "Epoch 1690/5000 -- Batch 172/173 -- Loss: 0.01295972 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14981421 -- Accuracy: 62.82894737\n",
      "\n",
      "Training:\n",
      "Epoch 1691/5000 -- Batch 172/173 -- Loss: 0.03033984 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14980155 -- Accuracy: 63.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 1692/5000 -- Batch 172/173 -- Loss: 0.02545677 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15575966 -- Accuracy: 63.48684211\n",
      "\n",
      "Training:\n",
      "Epoch 1693/5000 -- Batch 172/173 -- Loss: 0.03451571 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15555449 -- Accuracy: 63.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 1694/5000 -- Batch 172/173 -- Loss: 0.00831432 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15491391 -- Accuracy: 62.82894737\n",
      "\n",
      "Training:\n",
      "Epoch 1695/5000 -- Batch 172/173 -- Loss: 0.00994216 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15681718 -- Accuracy: 62.74671053\n",
      "\n",
      "Training:\n",
      "Epoch 1696/5000 -- Batch 172/173 -- Loss: 0.00630790 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15281282 -- Accuracy: 63.15789474\n",
      "\n",
      "Training:\n",
      "Epoch 1697/5000 -- Batch 172/173 -- Loss: 0.03349789 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15938664 -- Accuracy: 62.66447368\n",
      "\n",
      "Training:\n",
      "Epoch 1698/5000 -- Batch 172/173 -- Loss: 0.00893223 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16437604 -- Accuracy: 63.48684211\n",
      "\n",
      "Training:\n",
      "Epoch 1699/5000 -- Batch 172/173 -- Loss: 0.01852032 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16176587 -- Accuracy: 62.82894737\n",
      "\n",
      "Training:\n",
      "Epoch 1700/5000 -- Batch 172/173 -- Loss: 0.04325432 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14701750 -- Accuracy: 62.74671053\n",
      "\n",
      "Training:\n",
      "Epoch 1701/5000 -- Batch 172/173 -- Loss: 0.01890294 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14964675 -- Accuracy: 62.41776316\n",
      "\n",
      "Training:\n",
      "Epoch 1702/5000 -- Batch 172/173 -- Loss: 0.02583001 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15186612 -- Accuracy: 63.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 1703/5000 -- Batch 172/173 -- Loss: 0.02713116 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15168103 -- Accuracy: 62.82894737\n",
      "\n",
      "Training:\n",
      "Epoch 1704/5000 -- Batch 172/173 -- Loss: 0.01491131 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15783173 -- Accuracy: 63.40460526\n",
      "\n",
      "Training:\n",
      "Epoch 1705/5000 -- Batch 172/173 -- Loss: 0.05388416 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16069952 -- Accuracy: 63.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 1706/5000 -- Batch 172/173 -- Loss: 0.03244670 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14492766 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1707/5000 -- Batch 172/173 -- Loss: 0.06474020 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14092181 -- Accuracy: 63.15789474\n",
      "\n",
      "Training:\n",
      "Epoch 1708/5000 -- Batch 172/173 -- Loss: 0.04014360 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15254283 -- Accuracy: 63.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 1709/5000 -- Batch 172/173 -- Loss: 0.02984533 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15434054 -- Accuracy: 63.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 1710/5000 -- Batch 172/173 -- Loss: 0.01531989 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15128444 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1711/5000 -- Batch 172/173 -- Loss: 0.01575163 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14824095 -- Accuracy: 62.82894737\n",
      "\n",
      "Training:\n",
      "Epoch 1712/5000 -- Batch 172/173 -- Loss: 0.02803681 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14802173 -- Accuracy: 63.48684211\n",
      "\n",
      "Training:\n",
      "Epoch 1713/5000 -- Batch 172/173 -- Loss: 0.03173649 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15022148 -- Accuracy: 63.48684211\n",
      "\n",
      "Training:\n",
      "Epoch 1714/5000 -- Batch 172/173 -- Loss: 0.04025231 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14843968 -- Accuracy: 63.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 1715/5000 -- Batch 172/173 -- Loss: 0.02946973 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14046479 -- Accuracy: 62.91118421\n",
      "\n",
      "Training:\n",
      "Epoch 1716/5000 -- Batch 172/173 -- Loss: 0.03400893 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15063311 -- Accuracy: 63.65131579\n",
      "\n",
      "Training:\n",
      "Epoch 1717/5000 -- Batch 172/173 -- Loss: 0.02098207 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15290498 -- Accuracy: 63.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 1718/5000 -- Batch 172/173 -- Loss: 0.01923474 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15036218 -- Accuracy: 63.40460526\n",
      "\n",
      "Training:\n",
      "Epoch 1719/5000 -- Batch 172/173 -- Loss: 0.03395110 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14731841 -- Accuracy: 63.15789474\n",
      "\n",
      "Training:\n",
      "Epoch 1720/5000 -- Batch 172/173 -- Loss: 0.03625125 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14811111 -- Accuracy: 63.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 1721/5000 -- Batch 172/173 -- Loss: 0.03225088 -- Train accuracy: 84.4653\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13794289 -- Accuracy: 63.40460526\n",
      "\n",
      "Training:\n",
      "Epoch 1722/5000 -- Batch 172/173 -- Loss: 0.03386363 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13582643 -- Accuracy: 63.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 1723/5000 -- Batch 172/173 -- Loss: 0.07141675 -- Train accuracy: 84.7272\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13990230 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1724/5000 -- Batch 172/173 -- Loss: 0.03146689 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13463153 -- Accuracy: 63.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 1725/5000 -- Batch 172/173 -- Loss: 0.03694442 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13973112 -- Accuracy: 63.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 1726/5000 -- Batch 172/173 -- Loss: 0.01664846 -- Train accuracy: 84.4653\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14016244 -- Accuracy: 63.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 1727/5000 -- Batch 172/173 -- Loss: 0.02408832 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13340911 -- Accuracy: 62.74671053\n",
      "\n",
      "Training:\n",
      "Epoch 1728/5000 -- Batch 172/173 -- Loss: 0.02169266 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13808399 -- Accuracy: 62.66447368\n",
      "\n",
      "Training:\n",
      "Epoch 1729/5000 -- Batch 172/173 -- Loss: 0.01172070 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13828534 -- Accuracy: 63.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 1730/5000 -- Batch 172/173 -- Loss: 0.02834573 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13868104 -- Accuracy: 63.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 1731/5000 -- Batch 172/173 -- Loss: 0.02279256 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13995737 -- Accuracy: 62.74671053\n",
      "\n",
      "Training:\n",
      "Epoch 1732/5000 -- Batch 172/173 -- Loss: 0.02282049 -- Train accuracy: 84.7272\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13775714 -- Accuracy: 62.50000000\n",
      "\n",
      "Training:\n",
      "Epoch 1733/5000 -- Batch 172/173 -- Loss: 0.00882145 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13587233 -- Accuracy: 62.33552632\n",
      "\n",
      "Training:\n",
      "Epoch 1734/5000 -- Batch 172/173 -- Loss: 0.02257819 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13902697 -- Accuracy: 63.48684211\n",
      "\n",
      "Training:\n",
      "Epoch 1735/5000 -- Batch 172/173 -- Loss: 0.00760528 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13812667 -- Accuracy: 63.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 1736/5000 -- Batch 172/173 -- Loss: 0.01345951 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13324298 -- Accuracy: 63.48684211\n",
      "\n",
      "Training:\n",
      "Epoch 1737/5000 -- Batch 172/173 -- Loss: 0.02665865 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13974292 -- Accuracy: 63.40460526\n",
      "\n",
      "Training:\n",
      "Epoch 1738/5000 -- Batch 172/173 -- Loss: 0.01798557 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13759851 -- Accuracy: 63.56907895\n",
      "\n",
      "Training:\n",
      "Epoch 1739/5000 -- Batch 172/173 -- Loss: 0.03845703 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14129691 -- Accuracy: 63.07565789\n",
      "\n",
      "Training:\n",
      "Epoch 1740/5000 -- Batch 172/173 -- Loss: 0.03060012 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13893164 -- Accuracy: 62.91118421\n",
      "\n",
      "Training:\n",
      "Epoch 1741/5000 -- Batch 172/173 -- Loss: 0.00965583 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14060980 -- Accuracy: 63.15789474\n",
      "\n",
      "Training:\n",
      "Epoch 1742/5000 -- Batch 172/173 -- Loss: 0.02676867 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13587963 -- Accuracy: 62.91118421\n",
      "\n",
      "Training:\n",
      "Epoch 1743/5000 -- Batch 172/173 -- Loss: 0.02639963 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14167985 -- Accuracy: 63.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 1744/5000 -- Batch 172/173 -- Loss: 0.00895253 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14834339 -- Accuracy: 63.32236842\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1745/5000 -- Batch 172/173 -- Loss: 0.01158624 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14160489 -- Accuracy: 63.15789474\n",
      "\n",
      "Training:\n",
      "Epoch 1746/5000 -- Batch 172/173 -- Loss: 0.00318019 -- Train accuracy: 84.7001\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15083092 -- Accuracy: 63.56907895\n",
      "\n",
      "Training:\n",
      "Epoch 1747/5000 -- Batch 172/173 -- Loss: 0.01848060 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14360189 -- Accuracy: 63.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 1748/5000 -- Batch 172/173 -- Loss: 0.02207550 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13603345 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1749/5000 -- Batch 172/173 -- Loss: 0.08226750 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14471913 -- Accuracy: 63.15789474\n",
      "\n",
      "Training:\n",
      "Epoch 1750/5000 -- Batch 172/173 -- Loss: 0.01936959 -- Train accuracy: 84.7092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14816054 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1751/5000 -- Batch 172/173 -- Loss: 0.02925656 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14967408 -- Accuracy: 63.56907895\n",
      "\n",
      "Training:\n",
      "Epoch 1752/5000 -- Batch 172/173 -- Loss: 0.02261775 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13688575 -- Accuracy: 62.74671053\n",
      "\n",
      "Training:\n",
      "Epoch 1753/5000 -- Batch 172/173 -- Loss: 0.01899481 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14094739 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1754/5000 -- Batch 172/173 -- Loss: 0.01613417 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13651280 -- Accuracy: 63.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 1755/5000 -- Batch 172/173 -- Loss: 0.01824658 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14295052 -- Accuracy: 63.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 1756/5000 -- Batch 172/173 -- Loss: 0.03566414 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14237743 -- Accuracy: 63.56907895\n",
      "\n",
      "Training:\n",
      "Epoch 1757/5000 -- Batch 172/173 -- Loss: 0.04141057 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14485762 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1758/5000 -- Batch 172/173 -- Loss: 0.02094329 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14919930 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1759/5000 -- Batch 172/173 -- Loss: 0.00922989 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15114537 -- Accuracy: 63.89802632\n",
      "\n",
      "Training:\n",
      "Epoch 1760/5000 -- Batch 172/173 -- Loss: 0.03072041 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15510501 -- Accuracy: 63.65131579\n",
      "\n",
      "Training:\n",
      "Epoch 1761/5000 -- Batch 172/173 -- Loss: 0.01973890 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14330892 -- Accuracy: 63.15789474\n",
      "\n",
      "Training:\n",
      "Epoch 1762/5000 -- Batch 172/173 -- Loss: 0.01968783 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15005661 -- Accuracy: 63.56907895\n",
      "\n",
      "Training:\n",
      "Epoch 1763/5000 -- Batch 172/173 -- Loss: 0.03524748 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14682842 -- Accuracy: 63.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 1764/5000 -- Batch 172/173 -- Loss: 0.04553359 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14760382 -- Accuracy: 63.48684211\n",
      "\n",
      "Training:\n",
      "Epoch 1765/5000 -- Batch 172/173 -- Loss: 0.03907577 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14920649 -- Accuracy: 63.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 1766/5000 -- Batch 172/173 -- Loss: 0.01270073 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14792159 -- Accuracy: 63.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 1767/5000 -- Batch 172/173 -- Loss: 0.02531902 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14229598 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1768/5000 -- Batch 172/173 -- Loss: 0.03233176 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14374669 -- Accuracy: 63.65131579\n",
      "\n",
      "Training:\n",
      "Epoch 1769/5000 -- Batch 172/173 -- Loss: 0.04651266 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14102727 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1770/5000 -- Batch 172/173 -- Loss: 0.01965322 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14803064 -- Accuracy: 64.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 1771/5000 -- Batch 172/173 -- Loss: 0.03398280 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14415781 -- Accuracy: 63.89802632\n",
      "\n",
      "Training:\n",
      "Epoch 1772/5000 -- Batch 172/173 -- Loss: 0.03470178 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14376095 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1773/5000 -- Batch 172/173 -- Loss: 0.01169523 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14401306 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1774/5000 -- Batch 172/173 -- Loss: 0.04071499 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14550600 -- Accuracy: 63.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 1775/5000 -- Batch 172/173 -- Loss: 0.01682283 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14747719 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1776/5000 -- Batch 172/173 -- Loss: 0.01797443 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14156571 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1777/5000 -- Batch 172/173 -- Loss: 0.07827924 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14762037 -- Accuracy: 63.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 1778/5000 -- Batch 172/173 -- Loss: 0.03549301 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14780157 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1779/5000 -- Batch 172/173 -- Loss: 0.01954132 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14516491 -- Accuracy: 63.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 1780/5000 -- Batch 172/173 -- Loss: 0.03377141 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14089939 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1781/5000 -- Batch 172/173 -- Loss: 0.03167322 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14384803 -- Accuracy: 64.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 1782/5000 -- Batch 172/173 -- Loss: 0.02640206 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14019176 -- Accuracy: 63.65131579\n",
      "\n",
      "Training:\n",
      "Epoch 1783/5000 -- Batch 172/173 -- Loss: 0.01995866 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15236460 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1784/5000 -- Batch 172/173 -- Loss: 0.01215467 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15247709 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1785/5000 -- Batch 172/173 -- Loss: 0.03328316 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14999652 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1786/5000 -- Batch 172/173 -- Loss: 0.01378768 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15367211 -- Accuracy: 63.65131579\n",
      "\n",
      "Training:\n",
      "Epoch 1787/5000 -- Batch 172/173 -- Loss: 0.01446325 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15053829 -- Accuracy: 63.24013158\n",
      "\n",
      "Training:\n",
      "Epoch 1788/5000 -- Batch 172/173 -- Loss: 0.01035293 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14265941 -- Accuracy: 64.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 1789/5000 -- Batch 172/173 -- Loss: 0.03851593 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14849619 -- Accuracy: 63.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 1790/5000 -- Batch 172/173 -- Loss: 0.00729920 -- Train accuracy: 84.7092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14829954 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1791/5000 -- Batch 172/173 -- Loss: 0.03084395 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14891809 -- Accuracy: 64.39144737\n",
      "\n",
      "Training:\n",
      "Epoch 1792/5000 -- Batch 172/173 -- Loss: 0.01689480 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14249320 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1793/5000 -- Batch 172/173 -- Loss: 0.01421690 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14350800 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1794/5000 -- Batch 172/173 -- Loss: 0.02891499 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14280321 -- Accuracy: 63.32236842\n",
      "\n",
      "Training:\n",
      "Epoch 1795/5000 -- Batch 172/173 -- Loss: 0.04906441 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14248901 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1796/5000 -- Batch 172/173 -- Loss: 0.01364687 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14670924 -- Accuracy: 63.40460526\n",
      "\n",
      "Training:\n",
      "Epoch 1797/5000 -- Batch 172/173 -- Loss: 0.04752287 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14527365 -- Accuracy: 63.65131579\n",
      "\n",
      "Training:\n",
      "Epoch 1798/5000 -- Batch 172/173 -- Loss: 0.02263099 -- Train accuracy: 84.6008\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15158224 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1799/5000 -- Batch 172/173 -- Loss: 0.01250501 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15196638 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1800/5000 -- Batch 172/173 -- Loss: 0.02659355 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15666306 -- Accuracy: 64.22697368\n",
      "\n",
      "Training:\n",
      "Epoch 1801/5000 -- Batch 172/173 -- Loss: 0.02147252 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14278502 -- Accuracy: 64.22697368\n",
      "\n",
      "Training:\n",
      "Epoch 1802/5000 -- Batch 172/173 -- Loss: 0.02363880 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15021667 -- Accuracy: 64.30921053\n",
      "\n",
      "Training:\n",
      "Epoch 1803/5000 -- Batch 172/173 -- Loss: 0.03667846 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14143912 -- Accuracy: 63.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 1804/5000 -- Batch 172/173 -- Loss: 0.01775941 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15563349 -- Accuracy: 64.30921053\n",
      "\n",
      "Training:\n",
      "Epoch 1805/5000 -- Batch 172/173 -- Loss: 0.00907032 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13872976 -- Accuracy: 64.39144737\n",
      "\n",
      "Training:\n",
      "Epoch 1806/5000 -- Batch 172/173 -- Loss: 0.01026718 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14245036 -- Accuracy: 64.47368421\n",
      "\n",
      "Training:\n",
      "Epoch 1807/5000 -- Batch 172/173 -- Loss: 0.03116515 -- Train accuracy: 84.5827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15194265 -- Accuracy: 63.48684211\n",
      "\n",
      "Training:\n",
      "Epoch 1808/5000 -- Batch 172/173 -- Loss: 0.02249496 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15276982 -- Accuracy: 63.81578947\n",
      "\n",
      "Training:\n",
      "Epoch 1809/5000 -- Batch 172/173 -- Loss: 0.01518141 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15830126 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1810/5000 -- Batch 172/173 -- Loss: 0.01581612 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15361681 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1811/5000 -- Batch 172/173 -- Loss: 0.04212552 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15306137 -- Accuracy: 64.22697368\n",
      "\n",
      "Training:\n",
      "Epoch 1812/5000 -- Batch 172/173 -- Loss: 0.06357985 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15387909 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1813/5000 -- Batch 172/173 -- Loss: 0.02591170 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15415881 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1814/5000 -- Batch 172/173 -- Loss: 0.11037719 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15711566 -- Accuracy: 64.30921053\n",
      "\n",
      "Training:\n",
      "Epoch 1815/5000 -- Batch 172/173 -- Loss: 0.01933727 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14976118 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1816/5000 -- Batch 172/173 -- Loss: 0.01478659 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14627965 -- Accuracy: 63.89802632\n",
      "\n",
      "Training:\n",
      "Epoch 1817/5000 -- Batch 172/173 -- Loss: 0.02411759 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13939920 -- Accuracy: 63.40460526\n",
      "\n",
      "Training:\n",
      "Epoch 1818/5000 -- Batch 172/173 -- Loss: 0.04522653 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15239534 -- Accuracy: 64.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 1819/5000 -- Batch 172/173 -- Loss: 0.03918780 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14157091 -- Accuracy: 63.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 1820/5000 -- Batch 172/173 -- Loss: 0.03802175 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16517760 -- Accuracy: 64.63815789\n",
      "\n",
      "Training:\n",
      "Epoch 1821/5000 -- Batch 172/173 -- Loss: 0.01997897 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14699233 -- Accuracy: 64.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 1822/5000 -- Batch 172/173 -- Loss: 0.01401666 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15126372 -- Accuracy: 63.89802632\n",
      "\n",
      "Training:\n",
      "Epoch 1823/5000 -- Batch 172/173 -- Loss: 0.00700960 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16391111 -- Accuracy: 64.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 1824/5000 -- Batch 172/173 -- Loss: 0.00758398 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16708908 -- Accuracy: 63.89802632\n",
      "\n",
      "Training:\n",
      "Epoch 1825/5000 -- Batch 172/173 -- Loss: 0.01076105 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16231648 -- Accuracy: 64.55592105\n",
      "\n",
      "Training:\n",
      "Epoch 1826/5000 -- Batch 172/173 -- Loss: 0.01908951 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13981825 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1827/5000 -- Batch 172/173 -- Loss: 0.01769628 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14468371 -- Accuracy: 63.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 1828/5000 -- Batch 172/173 -- Loss: 0.03752964 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15258993 -- Accuracy: 64.55592105\n",
      "\n",
      "Training:\n",
      "Epoch 1829/5000 -- Batch 172/173 -- Loss: 0.01873448 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14621758 -- Accuracy: 64.63815789\n",
      "\n",
      "Training:\n",
      "Epoch 1830/5000 -- Batch 172/173 -- Loss: 0.01008935 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15764768 -- Accuracy: 63.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 1831/5000 -- Batch 172/173 -- Loss: 0.04562585 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15536761 -- Accuracy: 63.48684211\n",
      "\n",
      "Training:\n",
      "Epoch 1832/5000 -- Batch 172/173 -- Loss: 0.00847814 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15156553 -- Accuracy: 64.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 1833/5000 -- Batch 172/173 -- Loss: 0.04389708 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14911516 -- Accuracy: 64.55592105\n",
      "\n",
      "Training:\n",
      "Epoch 1834/5000 -- Batch 172/173 -- Loss: 0.00482964 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14864623 -- Accuracy: 63.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 1835/5000 -- Batch 172/173 -- Loss: 0.02540602 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15677497 -- Accuracy: 64.88486842\n",
      "\n",
      "Training:\n",
      "Epoch 1836/5000 -- Batch 172/173 -- Loss: 0.04288712 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14467878 -- Accuracy: 64.63815789\n",
      "\n",
      "Training:\n",
      "Epoch 1837/5000 -- Batch 172/173 -- Loss: 0.03831775 -- Train accuracy: 84.6098\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13233113 -- Accuracy: 64.47368421\n",
      "\n",
      "Training:\n",
      "Epoch 1838/5000 -- Batch 172/173 -- Loss: 0.02457099 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13241372 -- Accuracy: 64.55592105\n",
      "\n",
      "Training:\n",
      "Epoch 1839/5000 -- Batch 172/173 -- Loss: 0.03019077 -- Train accuracy: 84.6369\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13771048 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1840/5000 -- Batch 172/173 -- Loss: 0.01445555 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14810384 -- Accuracy: 64.72039474\n",
      "\n",
      "Training:\n",
      "Epoch 1841/5000 -- Batch 172/173 -- Loss: 0.01323128 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14256138 -- Accuracy: 63.89802632\n",
      "\n",
      "Training:\n",
      "Epoch 1842/5000 -- Batch 172/173 -- Loss: 0.01836245 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13785724 -- Accuracy: 64.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 1843/5000 -- Batch 172/173 -- Loss: 0.05028930 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14645204 -- Accuracy: 64.39144737\n",
      "\n",
      "Training:\n",
      "Epoch 1844/5000 -- Batch 172/173 -- Loss: 0.01781636 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14320818 -- Accuracy: 64.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 1845/5000 -- Batch 172/173 -- Loss: 0.02480307 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14537607 -- Accuracy: 63.40460526\n",
      "\n",
      "Training:\n",
      "Epoch 1846/5000 -- Batch 172/173 -- Loss: 0.01881951 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14388345 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1847/5000 -- Batch 172/173 -- Loss: 0.01658793 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14930881 -- Accuracy: 64.55592105\n",
      "\n",
      "Training:\n",
      "Epoch 1848/5000 -- Batch 172/173 -- Loss: 0.02570797 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13883856 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1849/5000 -- Batch 172/173 -- Loss: 0.04253796 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14253614 -- Accuracy: 63.89802632\n",
      "\n",
      "Training:\n",
      "Epoch 1850/5000 -- Batch 172/173 -- Loss: 0.03643338 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13747205 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1851/5000 -- Batch 172/173 -- Loss: 0.02533414 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14501903 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1852/5000 -- Batch 172/173 -- Loss: 0.01496530 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14523695 -- Accuracy: 64.39144737\n",
      "\n",
      "Training:\n",
      "Epoch 1853/5000 -- Batch 172/173 -- Loss: 0.07376495 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14684528 -- Accuracy: 63.73355263\n",
      "\n",
      "Training:\n",
      "Epoch 1854/5000 -- Batch 172/173 -- Loss: 0.02743724 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14500862 -- Accuracy: 64.63815789\n",
      "\n",
      "Training:\n",
      "Epoch 1855/5000 -- Batch 172/173 -- Loss: 0.04751337 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14172566 -- Accuracy: 64.39144737\n",
      "\n",
      "Training:\n",
      "Epoch 1856/5000 -- Batch 172/173 -- Loss: 0.01805678 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14419094 -- Accuracy: 64.55592105\n",
      "\n",
      "Training:\n",
      "Epoch 1857/5000 -- Batch 172/173 -- Loss: 0.00654689 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14211098 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1858/5000 -- Batch 172/173 -- Loss: 0.01270323 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14284719 -- Accuracy: 63.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 1859/5000 -- Batch 172/173 -- Loss: 0.01548278 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14428152 -- Accuracy: 64.22697368\n",
      "\n",
      "Training:\n",
      "Epoch 1860/5000 -- Batch 172/173 -- Loss: 0.02919435 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14687676 -- Accuracy: 64.30921053\n",
      "\n",
      "Training:\n",
      "Epoch 1861/5000 -- Batch 172/173 -- Loss: 0.01727114 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14703945 -- Accuracy: 64.47368421\n",
      "\n",
      "Training:\n",
      "Epoch 1862/5000 -- Batch 172/173 -- Loss: 0.04743075 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15313830 -- Accuracy: 64.30921053\n",
      "\n",
      "Training:\n",
      "Epoch 1863/5000 -- Batch 172/173 -- Loss: 0.02550419 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14349843 -- Accuracy: 64.06250000\n",
      "\n",
      "Training:\n",
      "Epoch 1864/5000 -- Batch 172/173 -- Loss: 0.01389368 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14253098 -- Accuracy: 64.63815789\n",
      "\n",
      "Training:\n",
      "Epoch 1865/5000 -- Batch 172/173 -- Loss: 0.03176659 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14430957 -- Accuracy: 64.72039474\n",
      "\n",
      "Training:\n",
      "Epoch 1866/5000 -- Batch 172/173 -- Loss: 0.02021925 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15366617 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1867/5000 -- Batch 172/173 -- Loss: 0.04459615 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16118175 -- Accuracy: 64.22697368\n",
      "\n",
      "Training:\n",
      "Epoch 1868/5000 -- Batch 172/173 -- Loss: 0.01650320 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14760091 -- Accuracy: 64.30921053\n",
      "\n",
      "Training:\n",
      "Epoch 1869/5000 -- Batch 172/173 -- Loss: 0.02201194 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14708209 -- Accuracy: 64.72039474\n",
      "\n",
      "Training:\n",
      "Epoch 1870/5000 -- Batch 172/173 -- Loss: 0.00715847 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14736291 -- Accuracy: 63.89802632\n",
      "\n",
      "Training:\n",
      "Epoch 1871/5000 -- Batch 172/173 -- Loss: 0.02155811 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14845960 -- Accuracy: 64.22697368\n",
      "\n",
      "Training:\n",
      "Epoch 1872/5000 -- Batch 172/173 -- Loss: 0.02038440 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14878895 -- Accuracy: 64.39144737\n",
      "\n",
      "Training:\n",
      "Epoch 1873/5000 -- Batch 172/173 -- Loss: 0.02614278 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14866150 -- Accuracy: 63.98026316\n",
      "\n",
      "Training:\n",
      "Epoch 1874/5000 -- Batch 172/173 -- Loss: 0.02436391 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14758532 -- Accuracy: 64.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 1875/5000 -- Batch 172/173 -- Loss: 0.01842405 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15306090 -- Accuracy: 64.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 1876/5000 -- Batch 172/173 -- Loss: 0.04572824 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14685944 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1877/5000 -- Batch 172/173 -- Loss: 0.03144898 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15293062 -- Accuracy: 64.88486842\n",
      "\n",
      "Training:\n",
      "Epoch 1878/5000 -- Batch 172/173 -- Loss: 0.02895688 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15037557 -- Accuracy: 64.72039474\n",
      "\n",
      "Training:\n",
      "Epoch 1879/5000 -- Batch 172/173 -- Loss: 0.02155946 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15544771 -- Accuracy: 64.47368421\n",
      "\n",
      "Training:\n",
      "Epoch 1880/5000 -- Batch 172/173 -- Loss: 0.03067911 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14856172 -- Accuracy: 64.72039474\n",
      "\n",
      "Training:\n",
      "Epoch 1881/5000 -- Batch 172/173 -- Loss: 0.03178883 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14489093 -- Accuracy: 65.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 1882/5000 -- Batch 172/173 -- Loss: 0.03546049 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14901495 -- Accuracy: 64.47368421\n",
      "\n",
      "Training:\n",
      "Epoch 1883/5000 -- Batch 172/173 -- Loss: 0.02870037 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15260745 -- Accuracy: 65.21381579\n",
      "\n",
      "Training:\n",
      "Epoch 1884/5000 -- Batch 172/173 -- Loss: 0.01241127 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15215468 -- Accuracy: 65.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 1885/5000 -- Batch 172/173 -- Loss: 0.01442951 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14779131 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 1886/5000 -- Batch 172/173 -- Loss: 0.00745079 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15146514 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1887/5000 -- Batch 172/173 -- Loss: 0.06598482 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15200487 -- Accuracy: 65.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 1888/5000 -- Batch 172/173 -- Loss: 0.02254807 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14900223 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1889/5000 -- Batch 172/173 -- Loss: 0.02729221 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15294717 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1890/5000 -- Batch 172/173 -- Loss: 0.01163295 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14559123 -- Accuracy: 64.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 1891/5000 -- Batch 172/173 -- Loss: 0.03276767 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14874850 -- Accuracy: 64.30921053\n",
      "\n",
      "Training:\n",
      "Epoch 1892/5000 -- Batch 172/173 -- Loss: 0.02479962 -- Train accuracy: 84.5918\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14735593 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1893/5000 -- Batch 172/173 -- Loss: 0.03764132 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15329039 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1894/5000 -- Batch 172/173 -- Loss: 0.00907804 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14862692 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1895/5000 -- Batch 172/173 -- Loss: 0.01524265 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14409762 -- Accuracy: 64.72039474\n",
      "\n",
      "Training:\n",
      "Epoch 1896/5000 -- Batch 172/173 -- Loss: 0.01246107 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15374056 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 1897/5000 -- Batch 172/173 -- Loss: 0.00923259 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14421076 -- Accuracy: 64.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 1898/5000 -- Batch 172/173 -- Loss: 0.01908442 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14861071 -- Accuracy: 64.72039474\n",
      "\n",
      "Training:\n",
      "Epoch 1899/5000 -- Batch 172/173 -- Loss: 0.02114936 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14605552 -- Accuracy: 64.47368421\n",
      "\n",
      "Training:\n",
      "Epoch 1900/5000 -- Batch 172/173 -- Loss: 0.02325734 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15154118 -- Accuracy: 64.14473684\n",
      "\n",
      "Training:\n",
      "Epoch 1901/5000 -- Batch 172/173 -- Loss: 0.01582086 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14757148 -- Accuracy: 64.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 1902/5000 -- Batch 172/173 -- Loss: 0.02020502 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14456156 -- Accuracy: 64.47368421\n",
      "\n",
      "Training:\n",
      "Epoch 1903/5000 -- Batch 172/173 -- Loss: 0.04623599 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14798902 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1904/5000 -- Batch 172/173 -- Loss: 0.04838143 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15353885 -- Accuracy: 65.70723684\n",
      "\n",
      "Training:\n",
      "Epoch 1905/5000 -- Batch 172/173 -- Loss: 0.03828420 -- Train accuracy: 84.7272\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14531048 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1906/5000 -- Batch 172/173 -- Loss: 0.02628948 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14113054 -- Accuracy: 65.21381579\n",
      "\n",
      "Training:\n",
      "Epoch 1907/5000 -- Batch 172/173 -- Loss: 0.01620749 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14615477 -- Accuracy: 64.72039474\n",
      "\n",
      "Training:\n",
      "Epoch 1908/5000 -- Batch 172/173 -- Loss: 0.00921247 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13730470 -- Accuracy: 65.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 1909/5000 -- Batch 172/173 -- Loss: 0.02100352 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14386670 -- Accuracy: 65.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 1910/5000 -- Batch 172/173 -- Loss: 0.01220586 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14274042 -- Accuracy: 64.39144737\n",
      "\n",
      "Training:\n",
      "Epoch 1911/5000 -- Batch 172/173 -- Loss: 0.00915946 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14270884 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 1912/5000 -- Batch 172/173 -- Loss: 0.01742236 -- Train accuracy: 84.6550\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15390820 -- Accuracy: 65.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 1913/5000 -- Batch 172/173 -- Loss: 0.01808683 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13509758 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 1914/5000 -- Batch 172/173 -- Loss: 0.03203503 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12642139 -- Accuracy: 64.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 1915/5000 -- Batch 172/173 -- Loss: 0.02482833 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12834753 -- Accuracy: 65.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 1916/5000 -- Batch 172/173 -- Loss: 0.03063129 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13329349 -- Accuracy: 64.88486842\n",
      "\n",
      "Training:\n",
      "Epoch 1917/5000 -- Batch 172/173 -- Loss: 0.04842115 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14276151 -- Accuracy: 64.88486842\n",
      "\n",
      "Training:\n",
      "Epoch 1918/5000 -- Batch 172/173 -- Loss: 0.03307492 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13870988 -- Accuracy: 64.72039474\n",
      "\n",
      "Training:\n",
      "Epoch 1919/5000 -- Batch 172/173 -- Loss: 0.02208173 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13905501 -- Accuracy: 64.55592105\n",
      "\n",
      "Training:\n",
      "Epoch 1920/5000 -- Batch 172/173 -- Loss: 0.01189280 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13813070 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1921/5000 -- Batch 172/173 -- Loss: 0.02220026 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14293465 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 1922/5000 -- Batch 172/173 -- Loss: 0.01946542 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14085448 -- Accuracy: 65.54276316\n",
      "\n",
      "Training:\n",
      "Epoch 1923/5000 -- Batch 172/173 -- Loss: 0.01271915 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14049043 -- Accuracy: 65.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 1924/5000 -- Batch 172/173 -- Loss: 0.01963042 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14029773 -- Accuracy: 65.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 1925/5000 -- Batch 172/173 -- Loss: 0.01944152 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14896242 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1926/5000 -- Batch 172/173 -- Loss: 0.02781000 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14268474 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 1927/5000 -- Batch 172/173 -- Loss: 0.02107871 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14795887 -- Accuracy: 64.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 1928/5000 -- Batch 172/173 -- Loss: 0.05007116 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15174302 -- Accuracy: 65.21381579\n",
      "\n",
      "Training:\n",
      "Epoch 1929/5000 -- Batch 172/173 -- Loss: 0.03735889 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12209858 -- Accuracy: 64.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 1930/5000 -- Batch 172/173 -- Loss: 0.02790611 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12262722 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1931/5000 -- Batch 172/173 -- Loss: 0.03120083 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12448990 -- Accuracy: 64.88486842\n",
      "\n",
      "Training:\n",
      "Epoch 1932/5000 -- Batch 172/173 -- Loss: 0.03513430 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13237605 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1933/5000 -- Batch 172/173 -- Loss: 0.04191976 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13586932 -- Accuracy: 65.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 1934/5000 -- Batch 172/173 -- Loss: 0.01316005 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13905770 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1935/5000 -- Batch 172/173 -- Loss: 0.03514554 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14582717 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 1936/5000 -- Batch 172/173 -- Loss: 0.05072831 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14553285 -- Accuracy: 65.21381579\n",
      "\n",
      "Training:\n",
      "Epoch 1937/5000 -- Batch 172/173 -- Loss: 0.01787549 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13472491 -- Accuracy: 65.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 1938/5000 -- Batch 172/173 -- Loss: 0.01611639 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14114467 -- Accuracy: 64.88486842\n",
      "\n",
      "Training:\n",
      "Epoch 1939/5000 -- Batch 172/173 -- Loss: 0.01952549 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14819098 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 1940/5000 -- Batch 172/173 -- Loss: 0.01888292 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14032563 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 1941/5000 -- Batch 172/173 -- Loss: 0.03661232 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14624948 -- Accuracy: 65.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 1942/5000 -- Batch 172/173 -- Loss: 0.03323422 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14582569 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 1943/5000 -- Batch 172/173 -- Loss: 0.02315438 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14197948 -- Accuracy: 64.72039474\n",
      "\n",
      "Training:\n",
      "Epoch 1944/5000 -- Batch 172/173 -- Loss: 0.01182254 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15223542 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1945/5000 -- Batch 172/173 -- Loss: 0.01600946 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14916387 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 1946/5000 -- Batch 172/173 -- Loss: 0.02398779 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14668298 -- Accuracy: 65.21381579\n",
      "\n",
      "Training:\n",
      "Epoch 1947/5000 -- Batch 172/173 -- Loss: 0.03454151 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14673548 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1948/5000 -- Batch 172/173 -- Loss: 0.02308539 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15523815 -- Accuracy: 65.04934211\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1949/5000 -- Batch 172/173 -- Loss: 0.02778366 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15435985 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1950/5000 -- Batch 172/173 -- Loss: 0.01334210 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15076863 -- Accuracy: 65.21381579\n",
      "\n",
      "Training:\n",
      "Epoch 1951/5000 -- Batch 172/173 -- Loss: 0.02885293 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15689953 -- Accuracy: 65.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 1952/5000 -- Batch 172/173 -- Loss: 0.03316765 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15355535 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 1953/5000 -- Batch 172/173 -- Loss: 0.00841577 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15220125 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 1954/5000 -- Batch 172/173 -- Loss: 0.01470512 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15175895 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 1955/5000 -- Batch 172/173 -- Loss: 0.02861539 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15398928 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 1956/5000 -- Batch 172/173 -- Loss: 0.02607356 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14678236 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 1957/5000 -- Batch 172/173 -- Loss: 0.04634260 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14794430 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1958/5000 -- Batch 172/173 -- Loss: 0.04070485 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15197722 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 1959/5000 -- Batch 172/173 -- Loss: 0.02310325 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15921251 -- Accuracy: 65.54276316\n",
      "\n",
      "Training:\n",
      "Epoch 1960/5000 -- Batch 172/173 -- Loss: 0.03698748 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15716110 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1961/5000 -- Batch 172/173 -- Loss: 0.03410565 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15803662 -- Accuracy: 64.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 1962/5000 -- Batch 172/173 -- Loss: 0.03244350 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15761866 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 1963/5000 -- Batch 172/173 -- Loss: 0.03636130 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14127204 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 1964/5000 -- Batch 172/173 -- Loss: 0.02091585 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14734737 -- Accuracy: 65.70723684\n",
      "\n",
      "Training:\n",
      "Epoch 1965/5000 -- Batch 172/173 -- Loss: 0.03617604 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14824749 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 1966/5000 -- Batch 172/173 -- Loss: 0.02831139 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15249062 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1967/5000 -- Batch 172/173 -- Loss: 0.02214450 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15100807 -- Accuracy: 65.21381579\n",
      "\n",
      "Training:\n",
      "Epoch 1968/5000 -- Batch 172/173 -- Loss: 0.01978592 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15363979 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1969/5000 -- Batch 172/173 -- Loss: 0.02273156 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14796618 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 1970/5000 -- Batch 172/173 -- Loss: 0.00851828 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15292841 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1971/5000 -- Batch 172/173 -- Loss: 0.02252721 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15052408 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 1972/5000 -- Batch 172/173 -- Loss: 0.00780090 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14676079 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 1973/5000 -- Batch 172/173 -- Loss: 0.00831389 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14519061 -- Accuracy: 64.96710526\n",
      "\n",
      "Training:\n",
      "Epoch 1974/5000 -- Batch 172/173 -- Loss: 0.01887910 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14707884 -- Accuracy: 65.54276316\n",
      "\n",
      "Training:\n",
      "Epoch 1975/5000 -- Batch 172/173 -- Loss: 0.03274509 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15363740 -- Accuracy: 65.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 1976/5000 -- Batch 172/173 -- Loss: 0.03529231 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14568131 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 1977/5000 -- Batch 172/173 -- Loss: 0.05254842 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14793750 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1978/5000 -- Batch 172/173 -- Loss: 0.03315768 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14670283 -- Accuracy: 64.88486842\n",
      "\n",
      "Training:\n",
      "Epoch 1979/5000 -- Batch 172/173 -- Loss: 0.01524425 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14251181 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 1980/5000 -- Batch 172/173 -- Loss: 0.00804234 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14242944 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 1981/5000 -- Batch 172/173 -- Loss: 0.02711433 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14788628 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1982/5000 -- Batch 172/173 -- Loss: 0.02758119 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14353027 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 1983/5000 -- Batch 172/173 -- Loss: 0.03071734 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15100930 -- Accuracy: 65.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 1984/5000 -- Batch 172/173 -- Loss: 0.01766568 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14167620 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 1985/5000 -- Batch 172/173 -- Loss: 0.02990964 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14528454 -- Accuracy: 65.54276316\n",
      "\n",
      "Training:\n",
      "Epoch 1986/5000 -- Batch 172/173 -- Loss: 0.03161085 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15081349 -- Accuracy: 64.88486842\n",
      "\n",
      "Training:\n",
      "Epoch 1987/5000 -- Batch 172/173 -- Loss: 0.03171971 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15126462 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 1988/5000 -- Batch 172/173 -- Loss: 0.01690397 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14868869 -- Accuracy: 65.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 1989/5000 -- Batch 172/173 -- Loss: 0.03672267 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14676709 -- Accuracy: 64.88486842\n",
      "\n",
      "Training:\n",
      "Epoch 1990/5000 -- Batch 172/173 -- Loss: 0.02976330 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14994618 -- Accuracy: 64.80263158\n",
      "\n",
      "Training:\n",
      "Epoch 1991/5000 -- Batch 172/173 -- Loss: 0.02440424 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14521962 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 1992/5000 -- Batch 172/173 -- Loss: 0.02644446 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15019420 -- Accuracy: 65.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 1993/5000 -- Batch 172/173 -- Loss: 0.01963221 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14813979 -- Accuracy: 65.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 1994/5000 -- Batch 172/173 -- Loss: 0.03350474 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14911910 -- Accuracy: 65.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 1995/5000 -- Batch 172/173 -- Loss: 0.01289033 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14808153 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 1996/5000 -- Batch 172/173 -- Loss: 0.03247306 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14590928 -- Accuracy: 65.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 1997/5000 -- Batch 172/173 -- Loss: 0.02715742 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14636754 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1998/5000 -- Batch 172/173 -- Loss: 0.03234724 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14663515 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 1999/5000 -- Batch 172/173 -- Loss: 0.05198362 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14636295 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2000/5000 -- Batch 172/173 -- Loss: 0.04132063 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14888453 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 2001/5000 -- Batch 172/173 -- Loss: 0.04404449 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14923389 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2002/5000 -- Batch 172/173 -- Loss: 0.04227491 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15249178 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2003/5000 -- Batch 172/173 -- Loss: 0.02692726 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14612740 -- Accuracy: 65.70723684\n",
      "\n",
      "Training:\n",
      "Epoch 2004/5000 -- Batch 172/173 -- Loss: 0.03069183 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14432406 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2005/5000 -- Batch 172/173 -- Loss: 0.01431522 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15100415 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2006/5000 -- Batch 172/173 -- Loss: 0.03627641 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15195773 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2007/5000 -- Batch 172/173 -- Loss: 0.01126396 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13983624 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 2008/5000 -- Batch 172/173 -- Loss: 0.03177999 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14393215 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 2009/5000 -- Batch 172/173 -- Loss: 0.02686329 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15269998 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2010/5000 -- Batch 172/173 -- Loss: 0.01593473 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14379503 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 2011/5000 -- Batch 172/173 -- Loss: 0.02521819 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14454400 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 2012/5000 -- Batch 172/173 -- Loss: 0.01194812 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14999985 -- Accuracy: 65.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 2013/5000 -- Batch 172/173 -- Loss: 0.04808892 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14691084 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2014/5000 -- Batch 172/173 -- Loss: 0.01965384 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14959175 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 2015/5000 -- Batch 172/173 -- Loss: 0.02351814 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14910616 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 2016/5000 -- Batch 172/173 -- Loss: 0.04359408 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15002698 -- Accuracy: 65.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 2017/5000 -- Batch 172/173 -- Loss: 0.01993610 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15055977 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2018/5000 -- Batch 172/173 -- Loss: 0.02035438 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14652647 -- Accuracy: 65.21381579\n",
      "\n",
      "Training:\n",
      "Epoch 2019/5000 -- Batch 172/173 -- Loss: 0.01172244 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15082952 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 2020/5000 -- Batch 172/173 -- Loss: 0.03517088 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15555971 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 2021/5000 -- Batch 172/173 -- Loss: 0.02737675 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14654457 -- Accuracy: 65.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 2022/5000 -- Batch 172/173 -- Loss: 0.01063937 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14747583 -- Accuracy: 65.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 2023/5000 -- Batch 172/173 -- Loss: 0.02507038 -- Train accuracy: 84.6640\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14770825 -- Accuracy: 65.13157895\n",
      "\n",
      "Training:\n",
      "Epoch 2024/5000 -- Batch 172/173 -- Loss: 0.02373276 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13907265 -- Accuracy: 65.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 2025/5000 -- Batch 172/173 -- Loss: 0.04402633 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15127646 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2026/5000 -- Batch 172/173 -- Loss: 0.03260285 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14745672 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2027/5000 -- Batch 172/173 -- Loss: 0.02611806 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14715173 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2028/5000 -- Batch 172/173 -- Loss: 0.03140969 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14391693 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2029/5000 -- Batch 172/173 -- Loss: 0.01351879 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14720571 -- Accuracy: 65.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 2030/5000 -- Batch 172/173 -- Loss: 0.02673537 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14007218 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 2031/5000 -- Batch 172/173 -- Loss: 0.00849173 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14548430 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 2032/5000 -- Batch 172/173 -- Loss: 0.01689282 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15047855 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 2033/5000 -- Batch 172/173 -- Loss: 0.02890429 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15555420 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2034/5000 -- Batch 172/173 -- Loss: 0.03419173 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15055496 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 2035/5000 -- Batch 172/173 -- Loss: 0.02400705 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14611907 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2036/5000 -- Batch 172/173 -- Loss: 0.00945993 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14646959 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 2037/5000 -- Batch 172/173 -- Loss: 0.01076856 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14433347 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2038/5000 -- Batch 172/173 -- Loss: 0.01184484 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15099125 -- Accuracy: 65.04934211\n",
      "\n",
      "Training:\n",
      "Epoch 2039/5000 -- Batch 172/173 -- Loss: 0.00765956 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14993778 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2040/5000 -- Batch 172/173 -- Loss: 0.06895442 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15178250 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2041/5000 -- Batch 172/173 -- Loss: 0.03510693 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14811906 -- Accuracy: 65.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 2042/5000 -- Batch 172/173 -- Loss: 0.00819268 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15496908 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2043/5000 -- Batch 172/173 -- Loss: 0.01895045 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14776906 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2044/5000 -- Batch 172/173 -- Loss: 0.03371179 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15229400 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 2045/5000 -- Batch 172/173 -- Loss: 0.03235698 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15165100 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2046/5000 -- Batch 172/173 -- Loss: 0.02201310 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15046926 -- Accuracy: 65.21381579\n",
      "\n",
      "Training:\n",
      "Epoch 2047/5000 -- Batch 172/173 -- Loss: 0.03916012 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14933770 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2048/5000 -- Batch 172/173 -- Loss: 0.03539696 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14989211 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2049/5000 -- Batch 172/173 -- Loss: 0.03284841 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14901533 -- Accuracy: 65.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 2050/5000 -- Batch 172/173 -- Loss: 0.03997533 -- Train accuracy: 84.7272\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14596549 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2051/5000 -- Batch 172/173 -- Loss: 0.01400896 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15333182 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2052/5000 -- Batch 172/173 -- Loss: 0.02801400 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15334492 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2053/5000 -- Batch 172/173 -- Loss: 0.05391791 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15240354 -- Accuracy: 65.46052632\n",
      "\n",
      "Training:\n",
      "Epoch 2054/5000 -- Batch 172/173 -- Loss: 0.00812118 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15038569 -- Accuracy: 65.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 2055/5000 -- Batch 172/173 -- Loss: 0.01650726 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15424785 -- Accuracy: 65.70723684\n",
      "\n",
      "Training:\n",
      "Epoch 2056/5000 -- Batch 172/173 -- Loss: 0.02509871 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14198388 -- Accuracy: 65.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 2057/5000 -- Batch 172/173 -- Loss: 0.01672681 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14401777 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2058/5000 -- Batch 172/173 -- Loss: 0.01587061 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14564654 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2059/5000 -- Batch 172/173 -- Loss: 0.01458715 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14555272 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2060/5000 -- Batch 172/173 -- Loss: 0.01627588 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14413810 -- Accuracy: 65.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 2061/5000 -- Batch 172/173 -- Loss: 0.05773027 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14307367 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2062/5000 -- Batch 172/173 -- Loss: 0.00974320 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15333040 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2063/5000 -- Batch 172/173 -- Loss: 0.01726658 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14741310 -- Accuracy: 65.70723684\n",
      "\n",
      "Training:\n",
      "Epoch 2064/5000 -- Batch 172/173 -- Loss: 0.01516649 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15108184 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2065/5000 -- Batch 172/173 -- Loss: 0.02483541 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15341242 -- Accuracy: 65.70723684\n",
      "\n",
      "Training:\n",
      "Epoch 2066/5000 -- Batch 172/173 -- Loss: 0.02686746 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15414909 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2067/5000 -- Batch 172/173 -- Loss: 0.05545460 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14941733 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2068/5000 -- Batch 172/173 -- Loss: 0.04929622 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14875049 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 2069/5000 -- Batch 172/173 -- Loss: 0.03767330 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14942461 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2070/5000 -- Batch 172/173 -- Loss: 0.01204123 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15590326 -- Accuracy: 65.54276316\n",
      "\n",
      "Training:\n",
      "Epoch 2071/5000 -- Batch 172/173 -- Loss: 0.00957099 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14591561 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 2072/5000 -- Batch 172/173 -- Loss: 0.01609168 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14986743 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 2073/5000 -- Batch 172/173 -- Loss: 0.01288200 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14704126 -- Accuracy: 65.70723684\n",
      "\n",
      "Training:\n",
      "Epoch 2074/5000 -- Batch 172/173 -- Loss: 0.03281873 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15405697 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2075/5000 -- Batch 172/173 -- Loss: 0.05220575 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14433263 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2076/5000 -- Batch 172/173 -- Loss: 0.02749436 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14229987 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2077/5000 -- Batch 172/173 -- Loss: 0.04663637 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13452879 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2078/5000 -- Batch 172/173 -- Loss: 0.00868282 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14962138 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2079/5000 -- Batch 172/173 -- Loss: 0.02424836 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14252570 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2080/5000 -- Batch 172/173 -- Loss: 0.01679884 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14081895 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2081/5000 -- Batch 172/173 -- Loss: 0.04811977 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15044151 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2082/5000 -- Batch 172/173 -- Loss: 0.01517525 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15077717 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2083/5000 -- Batch 172/173 -- Loss: 0.01082626 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15380855 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2084/5000 -- Batch 172/173 -- Loss: 0.02196960 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15157188 -- Accuracy: 65.70723684\n",
      "\n",
      "Training:\n",
      "Epoch 2085/5000 -- Batch 172/173 -- Loss: 0.04923255 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14843720 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2086/5000 -- Batch 172/173 -- Loss: 0.01407752 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14646262 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2087/5000 -- Batch 172/173 -- Loss: 0.02626381 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14630711 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2088/5000 -- Batch 172/173 -- Loss: 0.01208048 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14816924 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2089/5000 -- Batch 172/173 -- Loss: 0.01357036 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15861551 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2090/5000 -- Batch 172/173 -- Loss: 0.01350484 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14525683 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2091/5000 -- Batch 172/173 -- Loss: 0.03135942 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15417611 -- Accuracy: 65.70723684\n",
      "\n",
      "Training:\n",
      "Epoch 2092/5000 -- Batch 172/173 -- Loss: 0.06062895 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14651003 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2093/5000 -- Batch 172/173 -- Loss: 0.03009155 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14593163 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2094/5000 -- Batch 172/173 -- Loss: 0.01636209 -- Train accuracy: 84.4382\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14170516 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2095/5000 -- Batch 172/173 -- Loss: 0.03657215 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15043711 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2096/5000 -- Batch 172/173 -- Loss: 0.02569150 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15015233 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2097/5000 -- Batch 172/173 -- Loss: 0.00909485 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15378036 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2098/5000 -- Batch 172/173 -- Loss: 0.03505389 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14225308 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2099/5000 -- Batch 172/173 -- Loss: 0.00348157 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15712950 -- Accuracy: 65.54276316\n",
      "\n",
      "Training:\n",
      "Epoch 2100/5000 -- Batch 172/173 -- Loss: 0.01578927 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14713695 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2101/5000 -- Batch 172/173 -- Loss: 0.02791210 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14762755 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2102/5000 -- Batch 172/173 -- Loss: 0.01508308 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14442987 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2103/5000 -- Batch 172/173 -- Loss: 0.00745284 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14929484 -- Accuracy: 65.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 2104/5000 -- Batch 172/173 -- Loss: 0.02733897 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15027199 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2105/5000 -- Batch 172/173 -- Loss: 0.01564018 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14109748 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2106/5000 -- Batch 172/173 -- Loss: 0.01941866 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16087449 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2107/5000 -- Batch 172/173 -- Loss: 0.02820231 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15018603 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2108/5000 -- Batch 172/173 -- Loss: 0.02223955 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15493218 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2109/5000 -- Batch 172/173 -- Loss: 0.02477474 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14600979 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2110/5000 -- Batch 172/173 -- Loss: 0.03218423 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15013500 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2111/5000 -- Batch 172/173 -- Loss: 0.05885775 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13293781 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2112/5000 -- Batch 172/173 -- Loss: 0.01356184 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14077660 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2113/5000 -- Batch 172/173 -- Loss: 0.03880965 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15518594 -- Accuracy: 65.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 2114/5000 -- Batch 172/173 -- Loss: 0.02058639 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14788353 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2115/5000 -- Batch 172/173 -- Loss: 0.02862102 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15532619 -- Accuracy: 65.37828947\n",
      "\n",
      "Training:\n",
      "Epoch 2116/5000 -- Batch 172/173 -- Loss: 0.01719640 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14857811 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2117/5000 -- Batch 172/173 -- Loss: 0.04481905 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15856560 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2118/5000 -- Batch 172/173 -- Loss: 0.04324457 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15412253 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2119/5000 -- Batch 172/173 -- Loss: 0.00961020 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15597296 -- Accuracy: 65.87171053\n",
      "\n",
      "Training:\n",
      "Epoch 2120/5000 -- Batch 172/173 -- Loss: 0.02607294 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15687605 -- Accuracy: 65.78947368\n",
      "\n",
      "Training:\n",
      "Epoch 2121/5000 -- Batch 172/173 -- Loss: 0.00375670 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15030539 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2122/5000 -- Batch 172/173 -- Loss: 0.01743867 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15508208 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2123/5000 -- Batch 172/173 -- Loss: 0.02012850 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15457886 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2124/5000 -- Batch 172/173 -- Loss: 0.02866442 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16046657 -- Accuracy: 65.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 2125/5000 -- Batch 172/173 -- Loss: 0.02692855 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15706429 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2126/5000 -- Batch 172/173 -- Loss: 0.01111941 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14780105 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2127/5000 -- Batch 172/173 -- Loss: 0.04695833 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14648227 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2128/5000 -- Batch 172/173 -- Loss: 0.01592145 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15573991 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2129/5000 -- Batch 172/173 -- Loss: 0.01513877 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.16167366 -- Accuracy: 65.70723684\n",
      "\n",
      "Training:\n",
      "Epoch 2130/5000 -- Batch 172/173 -- Loss: 0.03539886 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15775749 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2131/5000 -- Batch 172/173 -- Loss: 0.01234903 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13794638 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2132/5000 -- Batch 172/173 -- Loss: 0.02278016 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14719501 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2133/5000 -- Batch 172/173 -- Loss: 0.02651496 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13931961 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2134/5000 -- Batch 172/173 -- Loss: 0.02703995 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14187678 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2135/5000 -- Batch 172/173 -- Loss: 0.02658544 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14594642 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2136/5000 -- Batch 172/173 -- Loss: 0.03149413 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15063602 -- Accuracy: 66.03618421\n",
      "\n",
      "Training:\n",
      "Epoch 2137/5000 -- Batch 172/173 -- Loss: 0.02879540 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14463688 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2138/5000 -- Batch 172/173 -- Loss: 0.02735679 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15806897 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2139/5000 -- Batch 172/173 -- Loss: 0.03675161 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15009049 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2140/5000 -- Batch 172/173 -- Loss: 0.03101251 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14524890 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2141/5000 -- Batch 172/173 -- Loss: 0.01566468 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15547236 -- Accuracy: 65.62500000\n",
      "\n",
      "Training:\n",
      "Epoch 2142/5000 -- Batch 172/173 -- Loss: 0.01150316 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14814660 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2143/5000 -- Batch 172/173 -- Loss: 0.04101758 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15082543 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2144/5000 -- Batch 172/173 -- Loss: 0.00905820 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15415041 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2145/5000 -- Batch 172/173 -- Loss: 0.04352776 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14775792 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2146/5000 -- Batch 172/173 -- Loss: 0.02779631 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14587051 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2147/5000 -- Batch 172/173 -- Loss: 0.01449797 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14960985 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2148/5000 -- Batch 172/173 -- Loss: 0.02373611 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15537025 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2149/5000 -- Batch 172/173 -- Loss: 0.01577942 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15925185 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2150/5000 -- Batch 172/173 -- Loss: 0.02390936 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14665539 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2151/5000 -- Batch 172/173 -- Loss: 0.00547972 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15665699 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2152/5000 -- Batch 172/173 -- Loss: 0.01522201 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14981504 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2153/5000 -- Batch 172/173 -- Loss: 0.01765564 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15235944 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2154/5000 -- Batch 172/173 -- Loss: 0.00986276 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14868591 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2155/5000 -- Batch 172/173 -- Loss: 0.01010603 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12654117 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2156/5000 -- Batch 172/173 -- Loss: 0.02048595 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13154683 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2157/5000 -- Batch 172/173 -- Loss: 0.03327797 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13426009 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2158/5000 -- Batch 172/173 -- Loss: 0.04168666 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13714683 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2159/5000 -- Batch 172/173 -- Loss: 0.01238437 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13642115 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2160/5000 -- Batch 172/173 -- Loss: 0.02392725 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14104803 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2161/5000 -- Batch 172/173 -- Loss: 0.02164769 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13753904 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2162/5000 -- Batch 172/173 -- Loss: 0.02199710 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15190974 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2163/5000 -- Batch 172/173 -- Loss: 0.01496547 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15762318 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2164/5000 -- Batch 172/173 -- Loss: 0.02189238 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14948296 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2165/5000 -- Batch 172/173 -- Loss: 0.04866802 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14329937 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2166/5000 -- Batch 172/173 -- Loss: 0.02252737 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15601538 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2167/5000 -- Batch 172/173 -- Loss: 0.02656369 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13479261 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2168/5000 -- Batch 172/173 -- Loss: 0.02746473 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14905814 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2169/5000 -- Batch 172/173 -- Loss: 0.03881641 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14224880 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2170/5000 -- Batch 172/173 -- Loss: 0.03420978 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15087552 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2171/5000 -- Batch 172/173 -- Loss: 0.03299761 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15371240 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2172/5000 -- Batch 172/173 -- Loss: 0.02332440 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14910622 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2173/5000 -- Batch 172/173 -- Loss: 0.01381852 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14787760 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2174/5000 -- Batch 172/173 -- Loss: 0.01389968 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15544696 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2175/5000 -- Batch 172/173 -- Loss: 0.04204108 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15105392 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2176/5000 -- Batch 172/173 -- Loss: 0.02574328 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15374907 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2177/5000 -- Batch 172/173 -- Loss: 0.02470307 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14631800 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2178/5000 -- Batch 172/173 -- Loss: 0.03271908 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15078765 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2179/5000 -- Batch 172/173 -- Loss: 0.05201083 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15662924 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2180/5000 -- Batch 172/173 -- Loss: 0.02262350 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14475928 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2181/5000 -- Batch 172/173 -- Loss: 0.02665036 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14690441 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2182/5000 -- Batch 172/173 -- Loss: 0.02180780 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15211739 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2183/5000 -- Batch 172/173 -- Loss: 0.04148079 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12431440 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2184/5000 -- Batch 172/173 -- Loss: 0.00973513 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13530646 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2185/5000 -- Batch 172/173 -- Loss: 0.04138525 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12752619 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2186/5000 -- Batch 172/173 -- Loss: 0.05306271 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14037927 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2187/5000 -- Batch 172/173 -- Loss: 0.03074285 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13022494 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2188/5000 -- Batch 172/173 -- Loss: 0.02402669 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14479489 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2189/5000 -- Batch 172/173 -- Loss: 0.03412398 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14590042 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2190/5000 -- Batch 172/173 -- Loss: 0.01283149 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14943187 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2191/5000 -- Batch 172/173 -- Loss: 0.02119240 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14938065 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2192/5000 -- Batch 172/173 -- Loss: 0.04552370 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15217877 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2193/5000 -- Batch 172/173 -- Loss: 0.02471310 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14917740 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2194/5000 -- Batch 172/173 -- Loss: 0.04005025 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13682827 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2195/5000 -- Batch 172/173 -- Loss: 0.04242519 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14811933 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2196/5000 -- Batch 172/173 -- Loss: 0.01843225 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13520263 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2197/5000 -- Batch 172/173 -- Loss: 0.00801448 -- Train accuracy: 84.9530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14322385 -- Accuracy: 66.11842105\n",
      "\n",
      "Training:\n",
      "Epoch 2198/5000 -- Batch 172/173 -- Loss: 0.04378579 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14251242 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2199/5000 -- Batch 172/173 -- Loss: 0.05851670 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14903238 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2200/5000 -- Batch 172/173 -- Loss: 0.02539273 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14367340 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2201/5000 -- Batch 172/173 -- Loss: 0.00873928 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15774467 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2202/5000 -- Batch 172/173 -- Loss: 0.02015047 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14729422 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2203/5000 -- Batch 172/173 -- Loss: 0.04761238 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14912186 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2204/5000 -- Batch 172/173 -- Loss: 0.05398265 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14484848 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2205/5000 -- Batch 172/173 -- Loss: 0.01473175 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14909890 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2206/5000 -- Batch 172/173 -- Loss: 0.02679462 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14579153 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2207/5000 -- Batch 172/173 -- Loss: 0.02034776 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14830433 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2208/5000 -- Batch 172/173 -- Loss: 0.02314884 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14252853 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2209/5000 -- Batch 172/173 -- Loss: 0.02696599 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14301423 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2210/5000 -- Batch 172/173 -- Loss: 0.03194215 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14360239 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2211/5000 -- Batch 172/173 -- Loss: 0.02949898 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14819186 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2212/5000 -- Batch 172/173 -- Loss: 0.05393808 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14540040 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2213/5000 -- Batch 172/173 -- Loss: 0.01651210 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13181923 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2214/5000 -- Batch 172/173 -- Loss: 0.04245440 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14971220 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2215/5000 -- Batch 172/173 -- Loss: 0.03643863 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14763414 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2216/5000 -- Batch 172/173 -- Loss: 0.04149380 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14977407 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2217/5000 -- Batch 172/173 -- Loss: 0.02396818 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14382435 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2218/5000 -- Batch 172/173 -- Loss: 0.00901101 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15414851 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2219/5000 -- Batch 172/173 -- Loss: 0.02147468 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14944199 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2220/5000 -- Batch 172/173 -- Loss: 0.02591362 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11572983 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2221/5000 -- Batch 172/173 -- Loss: 0.02340385 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12101599 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2222/5000 -- Batch 172/173 -- Loss: 0.04905356 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11809076 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2223/5000 -- Batch 172/173 -- Loss: 0.03479232 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12294067 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2224/5000 -- Batch 172/173 -- Loss: 0.05983395 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12630185 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2225/5000 -- Batch 172/173 -- Loss: 0.02430588 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12097004 -- Accuracy: 66.28289474\n",
      "\n",
      "Training:\n",
      "Epoch 2226/5000 -- Batch 172/173 -- Loss: 0.03264511 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12498948 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2227/5000 -- Batch 172/173 -- Loss: 0.01399851 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12689498 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2228/5000 -- Batch 172/173 -- Loss: 0.03854220 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14863647 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2229/5000 -- Batch 172/173 -- Loss: 0.04890974 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13363563 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2230/5000 -- Batch 172/173 -- Loss: 0.03329100 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12985079 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2231/5000 -- Batch 172/173 -- Loss: 0.03100096 -- Train accuracy: 84.9530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14674292 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2232/5000 -- Batch 172/173 -- Loss: 0.02242592 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14023308 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2233/5000 -- Batch 172/173 -- Loss: 0.04012530 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13026137 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2234/5000 -- Batch 172/173 -- Loss: 0.02099215 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15027024 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2235/5000 -- Batch 172/173 -- Loss: 0.02752260 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13950740 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2236/5000 -- Batch 172/173 -- Loss: 0.04543900 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14094818 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2237/5000 -- Batch 172/173 -- Loss: 0.02826068 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14872485 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2238/5000 -- Batch 172/173 -- Loss: 0.05605144 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13238234 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2239/5000 -- Batch 172/173 -- Loss: 0.02039416 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13846480 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2240/5000 -- Batch 172/173 -- Loss: 0.04107617 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14360140 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2241/5000 -- Batch 172/173 -- Loss: 0.01489093 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14679415 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2242/5000 -- Batch 172/173 -- Loss: 0.02591163 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14660012 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2243/5000 -- Batch 172/173 -- Loss: 0.02167146 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13229691 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2244/5000 -- Batch 172/173 -- Loss: 0.04079882 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13230457 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2245/5000 -- Batch 172/173 -- Loss: 0.02573314 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13027862 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2246/5000 -- Batch 172/173 -- Loss: 0.03732355 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13401725 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2247/5000 -- Batch 172/173 -- Loss: 0.04047260 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13734295 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2248/5000 -- Batch 172/173 -- Loss: 0.01208996 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13673742 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2249/5000 -- Batch 172/173 -- Loss: 0.01607382 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14237171 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2250/5000 -- Batch 172/173 -- Loss: 0.04510814 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13816255 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2251/5000 -- Batch 172/173 -- Loss: 0.01669731 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15089175 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2252/5000 -- Batch 172/173 -- Loss: 0.02600633 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13059545 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2253/5000 -- Batch 172/173 -- Loss: 0.02497609 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14875051 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2254/5000 -- Batch 172/173 -- Loss: 0.03035902 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14825333 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2255/5000 -- Batch 172/173 -- Loss: 0.01827147 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14465190 -- Accuracy: 66.20065789\n",
      "\n",
      "Training:\n",
      "Epoch 2256/5000 -- Batch 172/173 -- Loss: 0.02215687 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14108221 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2257/5000 -- Batch 172/173 -- Loss: 0.02569754 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14850972 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2258/5000 -- Batch 172/173 -- Loss: 0.04958262 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14639124 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2259/5000 -- Batch 172/173 -- Loss: 0.03023550 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14191036 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2260/5000 -- Batch 172/173 -- Loss: 0.03517447 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14238211 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2261/5000 -- Batch 172/173 -- Loss: 0.03145655 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14137363 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2262/5000 -- Batch 172/173 -- Loss: 0.00578552 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14152443 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2263/5000 -- Batch 172/173 -- Loss: 0.03851872 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14495176 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2264/5000 -- Batch 172/173 -- Loss: 0.01919701 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14179731 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2265/5000 -- Batch 172/173 -- Loss: 0.04631674 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13373380 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2266/5000 -- Batch 172/173 -- Loss: 0.05004952 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14167967 -- Accuracy: 66.36513158\n",
      "\n",
      "Training:\n",
      "Epoch 2267/5000 -- Batch 172/173 -- Loss: 0.03180770 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14540516 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2268/5000 -- Batch 172/173 -- Loss: 0.02036779 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12956745 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2269/5000 -- Batch 172/173 -- Loss: 0.02376697 -- Train accuracy: 84.4834\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15259775 -- Accuracy: 65.29605263\n",
      "\n",
      "Training:\n",
      "Epoch 2270/5000 -- Batch 172/173 -- Loss: 0.02280912 -- Train accuracy: 84.5014\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12568796 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2271/5000 -- Batch 172/173 -- Loss: 0.02400383 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13656575 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2272/5000 -- Batch 172/173 -- Loss: 0.03016058 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13643771 -- Accuracy: 65.95394737\n",
      "\n",
      "Training:\n",
      "Epoch 2273/5000 -- Batch 172/173 -- Loss: 0.04543721 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13511148 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2274/5000 -- Batch 172/173 -- Loss: 0.01701185 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13689059 -- Accuracy: 66.44736842\n",
      "\n",
      "Training:\n",
      "Epoch 2275/5000 -- Batch 172/173 -- Loss: 0.04807830 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14189858 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2276/5000 -- Batch 172/173 -- Loss: 0.02148338 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13529059 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2277/5000 -- Batch 172/173 -- Loss: 0.05092279 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13787872 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2278/5000 -- Batch 172/173 -- Loss: 0.04979572 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14639227 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2279/5000 -- Batch 172/173 -- Loss: 0.08420353 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14123888 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2280/5000 -- Batch 172/173 -- Loss: 0.01438292 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15702813 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2281/5000 -- Batch 172/173 -- Loss: 0.04581394 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15027923 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2282/5000 -- Batch 172/173 -- Loss: 0.03238897 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15615078 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2283/5000 -- Batch 172/173 -- Loss: 0.05322115 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14802999 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2284/5000 -- Batch 172/173 -- Loss: 0.01354493 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13454572 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2285/5000 -- Batch 172/173 -- Loss: 0.05179126 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15095378 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2286/5000 -- Batch 172/173 -- Loss: 0.01363476 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15241321 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2287/5000 -- Batch 172/173 -- Loss: 0.04787914 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14360347 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2288/5000 -- Batch 172/173 -- Loss: 0.02177666 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14226871 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2289/5000 -- Batch 172/173 -- Loss: 0.04394123 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13909700 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2290/5000 -- Batch 172/173 -- Loss: 0.01302971 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14255892 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2291/5000 -- Batch 172/173 -- Loss: 0.02727848 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13939206 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2292/5000 -- Batch 172/173 -- Loss: 0.03105957 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12114292 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2293/5000 -- Batch 172/173 -- Loss: 0.01702854 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13080634 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2294/5000 -- Batch 172/173 -- Loss: 0.03164722 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12619065 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2295/5000 -- Batch 172/173 -- Loss: 0.01134490 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13182214 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2296/5000 -- Batch 172/173 -- Loss: 0.05177889 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13286548 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2297/5000 -- Batch 172/173 -- Loss: 0.04557650 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13471723 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2298/5000 -- Batch 172/173 -- Loss: 0.01639477 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12751117 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2299/5000 -- Batch 172/173 -- Loss: 0.02489784 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13282231 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2300/5000 -- Batch 172/173 -- Loss: 0.01333028 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13238950 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2301/5000 -- Batch 172/173 -- Loss: 0.00412753 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13239760 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2302/5000 -- Batch 172/173 -- Loss: 0.02414631 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13755524 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2303/5000 -- Batch 172/173 -- Loss: 0.00595018 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14394959 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2304/5000 -- Batch 172/173 -- Loss: 0.01909339 -- Train accuracy: 84.7814\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13507751 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2305/5000 -- Batch 172/173 -- Loss: 0.01555095 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15802409 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2306/5000 -- Batch 172/173 -- Loss: 0.03451153 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15234903 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2307/5000 -- Batch 172/173 -- Loss: 0.05941188 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13377111 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2308/5000 -- Batch 172/173 -- Loss: 0.02726581 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13539845 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2309/5000 -- Batch 172/173 -- Loss: 0.06511684 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13517803 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2310/5000 -- Batch 172/173 -- Loss: 0.01992487 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15502842 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2311/5000 -- Batch 172/173 -- Loss: 0.02597999 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14686595 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2312/5000 -- Batch 172/173 -- Loss: 0.01388531 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13790090 -- Accuracy: 66.69407895\n",
      "\n",
      "Training:\n",
      "Epoch 2313/5000 -- Batch 172/173 -- Loss: 0.04826590 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14731621 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2314/5000 -- Batch 172/173 -- Loss: 0.03429233 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14810354 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2315/5000 -- Batch 172/173 -- Loss: 0.02224901 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14384025 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2316/5000 -- Batch 172/173 -- Loss: 0.02597811 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13509711 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2317/5000 -- Batch 172/173 -- Loss: 0.02393164 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14620339 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2318/5000 -- Batch 172/173 -- Loss: 0.01189832 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14295375 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2319/5000 -- Batch 172/173 -- Loss: 0.01574380 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13896393 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2320/5000 -- Batch 172/173 -- Loss: 0.02342807 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13567466 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2321/5000 -- Batch 172/173 -- Loss: 0.01192645 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13533736 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2322/5000 -- Batch 172/173 -- Loss: 0.01906857 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14002443 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2323/5000 -- Batch 172/173 -- Loss: 0.04471035 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14422253 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2324/5000 -- Batch 172/173 -- Loss: 0.08780265 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14757249 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2325/5000 -- Batch 172/173 -- Loss: 0.03558014 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13789071 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2326/5000 -- Batch 172/173 -- Loss: 0.02313812 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14577202 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2327/5000 -- Batch 172/173 -- Loss: 0.02907458 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14733520 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2328/5000 -- Batch 172/173 -- Loss: 0.01540503 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13770084 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2329/5000 -- Batch 172/173 -- Loss: 0.11520666 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13522190 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2330/5000 -- Batch 172/173 -- Loss: 0.03005732 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13709505 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2331/5000 -- Batch 172/173 -- Loss: 0.03361429 -- Train accuracy: 84.3298\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11461034 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2332/5000 -- Batch 172/173 -- Loss: 0.01805782 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11524258 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2333/5000 -- Batch 172/173 -- Loss: 0.01763108 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13897425 -- Accuracy: 66.52960526\n",
      "\n",
      "Training:\n",
      "Epoch 2334/5000 -- Batch 172/173 -- Loss: 0.02424823 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12302492 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2335/5000 -- Batch 172/173 -- Loss: 0.02852423 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11807747 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2336/5000 -- Batch 172/173 -- Loss: 0.03256833 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11768729 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2337/5000 -- Batch 172/173 -- Loss: 0.02091463 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12206141 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2338/5000 -- Batch 172/173 -- Loss: 0.00356902 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13824135 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2339/5000 -- Batch 172/173 -- Loss: 0.00839745 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13330709 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2340/5000 -- Batch 172/173 -- Loss: 0.02408435 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13719044 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2341/5000 -- Batch 172/173 -- Loss: 0.01013955 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13758182 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2342/5000 -- Batch 172/173 -- Loss: 0.02002099 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13723420 -- Accuracy: 66.61184211\n",
      "\n",
      "Training:\n",
      "Epoch 2343/5000 -- Batch 172/173 -- Loss: 0.03228962 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13037253 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2344/5000 -- Batch 172/173 -- Loss: 0.03373464 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12433322 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2345/5000 -- Batch 172/173 -- Loss: 0.02567694 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13041660 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2346/5000 -- Batch 172/173 -- Loss: 0.02401406 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13341206 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2347/5000 -- Batch 172/173 -- Loss: 0.04487297 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13822491 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2348/5000 -- Batch 172/173 -- Loss: 0.03862117 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13509832 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2349/5000 -- Batch 172/173 -- Loss: 0.01350199 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13606328 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2350/5000 -- Batch 172/173 -- Loss: 0.02420325 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12983045 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2351/5000 -- Batch 172/173 -- Loss: 0.04891171 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13292010 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2352/5000 -- Batch 172/173 -- Loss: 0.02508755 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14055699 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2353/5000 -- Batch 172/173 -- Loss: 0.02882309 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14469240 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2354/5000 -- Batch 172/173 -- Loss: 0.03149776 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13504252 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2355/5000 -- Batch 172/173 -- Loss: 0.04029543 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.15054307 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2356/5000 -- Batch 172/173 -- Loss: 0.02650891 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12172850 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2357/5000 -- Batch 172/173 -- Loss: 0.01091706 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12577033 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2358/5000 -- Batch 172/173 -- Loss: 0.03802545 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11960498 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2359/5000 -- Batch 172/173 -- Loss: 0.02564030 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13807012 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2360/5000 -- Batch 172/173 -- Loss: 0.03093125 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12453715 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2361/5000 -- Batch 172/173 -- Loss: 0.01213601 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13193292 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2362/5000 -- Batch 172/173 -- Loss: 0.01300606 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14363274 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2363/5000 -- Batch 172/173 -- Loss: 0.01705206 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13016881 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2364/5000 -- Batch 172/173 -- Loss: 0.01657124 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12383563 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2365/5000 -- Batch 172/173 -- Loss: 0.03023403 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12342251 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2366/5000 -- Batch 172/173 -- Loss: 0.02964117 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13335183 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2367/5000 -- Batch 172/173 -- Loss: 0.01415224 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13395164 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2368/5000 -- Batch 172/173 -- Loss: 0.01109081 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13477692 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2369/5000 -- Batch 172/173 -- Loss: 0.03238164 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13476193 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2370/5000 -- Batch 172/173 -- Loss: 0.01843912 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14136540 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2371/5000 -- Batch 172/173 -- Loss: 0.04276707 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14759383 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2372/5000 -- Batch 172/173 -- Loss: 0.03954998 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14957104 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2373/5000 -- Batch 172/173 -- Loss: 0.01942547 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14443725 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2374/5000 -- Batch 172/173 -- Loss: 0.02536111 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13989099 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2375/5000 -- Batch 172/173 -- Loss: 0.01994400 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14674532 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2376/5000 -- Batch 172/173 -- Loss: 0.01975951 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13793901 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2377/5000 -- Batch 172/173 -- Loss: 0.01270269 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14638529 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2378/5000 -- Batch 172/173 -- Loss: 0.01331497 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14712482 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2379/5000 -- Batch 172/173 -- Loss: 0.02295807 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14207147 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2380/5000 -- Batch 172/173 -- Loss: 0.03242027 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14355210 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2381/5000 -- Batch 172/173 -- Loss: 0.03244949 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14033039 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2382/5000 -- Batch 172/173 -- Loss: 0.01658221 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14427881 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2383/5000 -- Batch 172/173 -- Loss: 0.01374507 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14763794 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2384/5000 -- Batch 172/173 -- Loss: 0.01976714 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13734240 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2385/5000 -- Batch 172/173 -- Loss: 0.01908681 -- Train accuracy: 84.9621\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13551756 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2386/5000 -- Batch 172/173 -- Loss: 0.02222970 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13905012 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2387/5000 -- Batch 172/173 -- Loss: 0.02147862 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14889950 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2388/5000 -- Batch 172/173 -- Loss: 0.01071417 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14951613 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2389/5000 -- Batch 172/173 -- Loss: 0.03714206 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14323914 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2390/5000 -- Batch 172/173 -- Loss: 0.02023135 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13246432 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2391/5000 -- Batch 172/173 -- Loss: 0.03074675 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14868007 -- Accuracy: 66.77631579\n",
      "\n",
      "Training:\n",
      "Epoch 2392/5000 -- Batch 172/173 -- Loss: 0.01933995 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14190949 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2393/5000 -- Batch 172/173 -- Loss: 0.01486232 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13770718 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2394/5000 -- Batch 172/173 -- Loss: 0.02752007 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14504272 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2395/5000 -- Batch 172/173 -- Loss: 0.01354368 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13993468 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2396/5000 -- Batch 172/173 -- Loss: 0.03576414 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12996930 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2397/5000 -- Batch 172/173 -- Loss: 0.00725225 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14622800 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2398/5000 -- Batch 172/173 -- Loss: 0.03881382 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12697246 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2399/5000 -- Batch 172/173 -- Loss: 0.02617574 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13733865 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2400/5000 -- Batch 172/173 -- Loss: 0.04416206 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14393648 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2401/5000 -- Batch 172/173 -- Loss: 0.04561708 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13464503 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2402/5000 -- Batch 172/173 -- Loss: 0.01018626 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14835821 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2403/5000 -- Batch 172/173 -- Loss: 0.02565325 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14825373 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2404/5000 -- Batch 172/173 -- Loss: 0.01353090 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14810740 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2405/5000 -- Batch 172/173 -- Loss: 0.01006432 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13948336 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2406/5000 -- Batch 172/173 -- Loss: 0.01281459 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14560729 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2407/5000 -- Batch 172/173 -- Loss: 0.02179973 -- Train accuracy: 84.6460\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12105925 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2408/5000 -- Batch 172/173 -- Loss: 0.01768343 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12810885 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2409/5000 -- Batch 172/173 -- Loss: 0.02422317 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12532842 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2410/5000 -- Batch 172/173 -- Loss: 0.03905427 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12883214 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2411/5000 -- Batch 172/173 -- Loss: 0.01492467 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13154497 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2412/5000 -- Batch 172/173 -- Loss: 0.02751367 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12847418 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2413/5000 -- Batch 172/173 -- Loss: 0.01869376 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12678327 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2414/5000 -- Batch 172/173 -- Loss: 0.02853257 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13088769 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2415/5000 -- Batch 172/173 -- Loss: 0.02809305 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12601578 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2416/5000 -- Batch 172/173 -- Loss: 0.01810930 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12984500 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2417/5000 -- Batch 172/173 -- Loss: 0.01325140 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13581501 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2418/5000 -- Batch 172/173 -- Loss: 0.02964882 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13499112 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2419/5000 -- Batch 172/173 -- Loss: 0.03587633 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13477933 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2420/5000 -- Batch 172/173 -- Loss: 0.03261885 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13992570 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2421/5000 -- Batch 172/173 -- Loss: 0.03110192 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13173222 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2422/5000 -- Batch 172/173 -- Loss: 0.05672748 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13404030 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2423/5000 -- Batch 172/173 -- Loss: 0.03218975 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12504133 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2424/5000 -- Batch 172/173 -- Loss: 0.03566504 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13491628 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2425/5000 -- Batch 172/173 -- Loss: 0.05556463 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13787620 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2426/5000 -- Batch 172/173 -- Loss: 0.05371156 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13444378 -- Accuracy: 66.94078947\n",
      "\n",
      "Training:\n",
      "Epoch 2427/5000 -- Batch 172/173 -- Loss: 0.05015054 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12949622 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2428/5000 -- Batch 172/173 -- Loss: 0.01173410 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13399256 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2429/5000 -- Batch 172/173 -- Loss: 0.02847592 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13957914 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2430/5000 -- Batch 172/173 -- Loss: 0.03762775 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13937849 -- Accuracy: 67.10526316\n",
      "\n",
      "Training:\n",
      "Epoch 2431/5000 -- Batch 172/173 -- Loss: 0.05509588 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14070464 -- Accuracy: 66.85855263\n",
      "\n",
      "Training:\n",
      "Epoch 2432/5000 -- Batch 172/173 -- Loss: 0.03538508 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13800144 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2433/5000 -- Batch 172/173 -- Loss: 0.03614474 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13616376 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2434/5000 -- Batch 172/173 -- Loss: 0.05474874 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14423768 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2435/5000 -- Batch 172/173 -- Loss: 0.03382050 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14504511 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2436/5000 -- Batch 172/173 -- Loss: 0.03576128 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12719412 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2437/5000 -- Batch 172/173 -- Loss: 0.02449617 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14391256 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2438/5000 -- Batch 172/173 -- Loss: 0.02748598 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14168591 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2439/5000 -- Batch 172/173 -- Loss: 0.03493364 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14651743 -- Accuracy: 67.18750000\n",
      "\n",
      "Training:\n",
      "Epoch 2440/5000 -- Batch 172/173 -- Loss: 0.03300598 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13656717 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2441/5000 -- Batch 172/173 -- Loss: 0.02317211 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13342033 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2442/5000 -- Batch 172/173 -- Loss: 0.01450412 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13765015 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2443/5000 -- Batch 172/173 -- Loss: 0.01390521 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13689528 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2444/5000 -- Batch 172/173 -- Loss: 0.02378031 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13640691 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2445/5000 -- Batch 172/173 -- Loss: 0.04781454 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13716660 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2446/5000 -- Batch 172/173 -- Loss: 0.02420346 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14229447 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2447/5000 -- Batch 172/173 -- Loss: 0.04000407 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13819315 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2448/5000 -- Batch 172/173 -- Loss: 0.00903585 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14699497 -- Accuracy: 67.02302632\n",
      "\n",
      "Training:\n",
      "Epoch 2449/5000 -- Batch 172/173 -- Loss: 0.01772826 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14219657 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2450/5000 -- Batch 172/173 -- Loss: 0.04059631 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13604253 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2451/5000 -- Batch 172/173 -- Loss: 0.02980338 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12324764 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2452/5000 -- Batch 172/173 -- Loss: 0.01889215 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12785533 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2453/5000 -- Batch 172/173 -- Loss: 0.02115000 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12451361 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2454/5000 -- Batch 172/173 -- Loss: 0.03380402 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13290056 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2455/5000 -- Batch 172/173 -- Loss: 0.00999313 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12835637 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n",
      "Epoch 2456/5000 -- Batch 172/173 -- Loss: 0.02160599 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13311328 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2457/5000 -- Batch 172/173 -- Loss: 0.02338439 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13266054 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2458/5000 -- Batch 172/173 -- Loss: 0.01431880 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13135278 -- Accuracy: 67.26973684\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2459/5000 -- Batch 172/173 -- Loss: 0.01210456 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13466269 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2460/5000 -- Batch 172/173 -- Loss: 0.03816526 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13499194 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2461/5000 -- Batch 172/173 -- Loss: 0.05915585 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13030749 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2462/5000 -- Batch 172/173 -- Loss: 0.01592444 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12614276 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2463/5000 -- Batch 172/173 -- Loss: 0.03532056 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13950724 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2464/5000 -- Batch 172/173 -- Loss: 0.04218366 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13161504 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2465/5000 -- Batch 172/173 -- Loss: 0.01516171 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14387269 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2466/5000 -- Batch 172/173 -- Loss: 0.01859453 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13330498 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2467/5000 -- Batch 172/173 -- Loss: 0.01556210 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13934128 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2468/5000 -- Batch 172/173 -- Loss: 0.01913766 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13564144 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2469/5000 -- Batch 172/173 -- Loss: 0.02416990 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13178659 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2470/5000 -- Batch 172/173 -- Loss: 0.02820917 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14069904 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2471/5000 -- Batch 172/173 -- Loss: 0.05202483 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12764849 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2472/5000 -- Batch 172/173 -- Loss: 0.03184194 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13513035 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2473/5000 -- Batch 172/173 -- Loss: 0.03374421 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13305219 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2474/5000 -- Batch 172/173 -- Loss: 0.03341311 -- Train accuracy: 84.7001\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11789563 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2475/5000 -- Batch 172/173 -- Loss: 0.00548736 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13301809 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2476/5000 -- Batch 172/173 -- Loss: 0.01944390 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13599041 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2477/5000 -- Batch 172/173 -- Loss: 0.03105053 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13308808 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2478/5000 -- Batch 172/173 -- Loss: 0.01627797 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13953741 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2479/5000 -- Batch 172/173 -- Loss: 0.02772920 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13494782 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2480/5000 -- Batch 172/173 -- Loss: 0.01048080 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13792103 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2481/5000 -- Batch 172/173 -- Loss: 0.03523283 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13273218 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2482/5000 -- Batch 172/173 -- Loss: 0.02906414 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13394483 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2483/5000 -- Batch 172/173 -- Loss: 0.02222859 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13855548 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2484/5000 -- Batch 172/173 -- Loss: 0.01801315 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13684596 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2485/5000 -- Batch 172/173 -- Loss: 0.05394438 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13710118 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2486/5000 -- Batch 172/173 -- Loss: 0.02584288 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13970657 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2487/5000 -- Batch 172/173 -- Loss: 0.01405917 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13928622 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2488/5000 -- Batch 172/173 -- Loss: 0.03828238 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13949106 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2489/5000 -- Batch 172/173 -- Loss: 0.00320415 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14215175 -- Accuracy: 67.43421053\n",
      "\n",
      "Training:\n",
      "Epoch 2490/5000 -- Batch 172/173 -- Loss: 0.01629425 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14094557 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2491/5000 -- Batch 172/173 -- Loss: 0.02589356 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13982668 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2492/5000 -- Batch 172/173 -- Loss: 0.02984995 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13829368 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2493/5000 -- Batch 172/173 -- Loss: 0.02983254 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14285729 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2494/5000 -- Batch 172/173 -- Loss: 0.03228286 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13382370 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2495/5000 -- Batch 172/173 -- Loss: 0.02909606 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14255086 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2496/5000 -- Batch 172/173 -- Loss: 0.04163824 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14179879 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2497/5000 -- Batch 172/173 -- Loss: 0.01557062 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14331542 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2498/5000 -- Batch 172/173 -- Loss: 0.02965472 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14128526 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2499/5000 -- Batch 172/173 -- Loss: 0.01876046 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14204843 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2500/5000 -- Batch 172/173 -- Loss: 0.01524937 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14195541 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2501/5000 -- Batch 172/173 -- Loss: 0.02748489 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13657094 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2502/5000 -- Batch 172/173 -- Loss: 0.03863490 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13255406 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2503/5000 -- Batch 172/173 -- Loss: 0.01978653 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13660007 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2504/5000 -- Batch 172/173 -- Loss: 0.02264760 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14481925 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2505/5000 -- Batch 172/173 -- Loss: 0.01227149 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14181596 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2506/5000 -- Batch 172/173 -- Loss: 0.02221436 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14409390 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2507/5000 -- Batch 172/173 -- Loss: 0.02696837 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12246589 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2508/5000 -- Batch 172/173 -- Loss: 0.02613693 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13436225 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2509/5000 -- Batch 172/173 -- Loss: 0.02492787 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13090653 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2510/5000 -- Batch 172/173 -- Loss: 0.01173639 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13295175 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2511/5000 -- Batch 172/173 -- Loss: 0.02665199 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13115235 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2512/5000 -- Batch 172/173 -- Loss: 0.01791903 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13752674 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2513/5000 -- Batch 172/173 -- Loss: 0.09449726 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12637574 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2514/5000 -- Batch 172/173 -- Loss: 0.03212671 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12540721 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2515/5000 -- Batch 172/173 -- Loss: 0.02188634 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12909376 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2516/5000 -- Batch 172/173 -- Loss: 0.02529190 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12768552 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2517/5000 -- Batch 172/173 -- Loss: 0.04129770 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12691400 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2518/5000 -- Batch 172/173 -- Loss: 0.01872122 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12857838 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2519/5000 -- Batch 172/173 -- Loss: 0.04100140 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12252457 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2520/5000 -- Batch 172/173 -- Loss: 0.05068364 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12025098 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2521/5000 -- Batch 172/173 -- Loss: 0.02978513 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13402716 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2522/5000 -- Batch 172/173 -- Loss: 0.01989263 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13392047 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2523/5000 -- Batch 172/173 -- Loss: 0.03282840 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12690805 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2524/5000 -- Batch 172/173 -- Loss: 0.04073941 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13552006 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2525/5000 -- Batch 172/173 -- Loss: 0.00747936 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14091560 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2526/5000 -- Batch 172/173 -- Loss: 0.01180022 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14178502 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2527/5000 -- Batch 172/173 -- Loss: 0.01633178 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12857182 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2528/5000 -- Batch 172/173 -- Loss: 0.01770707 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14093737 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2529/5000 -- Batch 172/173 -- Loss: 0.02359468 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14034935 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2530/5000 -- Batch 172/173 -- Loss: 0.03532168 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12037370 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2531/5000 -- Batch 172/173 -- Loss: 0.04684557 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13259878 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2532/5000 -- Batch 172/173 -- Loss: 0.01907143 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14038459 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2533/5000 -- Batch 172/173 -- Loss: 0.02316410 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12335423 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2534/5000 -- Batch 172/173 -- Loss: 0.03054926 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13786148 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2535/5000 -- Batch 172/173 -- Loss: 0.02965145 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13088897 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2536/5000 -- Batch 172/173 -- Loss: 0.02951428 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12774854 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2537/5000 -- Batch 172/173 -- Loss: 0.03293221 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11362130 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2538/5000 -- Batch 172/173 -- Loss: 0.04798160 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12135154 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2539/5000 -- Batch 172/173 -- Loss: 0.03729492 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12183126 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2540/5000 -- Batch 172/173 -- Loss: 0.02573360 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12443626 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2541/5000 -- Batch 172/173 -- Loss: 0.07432785 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12280692 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2542/5000 -- Batch 172/173 -- Loss: 0.02412310 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12716773 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2543/5000 -- Batch 172/173 -- Loss: 0.02454001 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11617938 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2544/5000 -- Batch 172/173 -- Loss: 0.10172018 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11810824 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2545/5000 -- Batch 172/173 -- Loss: 0.04201804 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11983455 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2546/5000 -- Batch 172/173 -- Loss: 0.00840372 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11927738 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2547/5000 -- Batch 172/173 -- Loss: 0.02959965 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11765237 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2548/5000 -- Batch 172/173 -- Loss: 0.01787023 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11708318 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2549/5000 -- Batch 172/173 -- Loss: 0.02701050 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12065555 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2550/5000 -- Batch 172/173 -- Loss: 0.00983387 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12252509 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2551/5000 -- Batch 172/173 -- Loss: 0.01590624 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11748383 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2552/5000 -- Batch 172/173 -- Loss: 0.02144589 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12281828 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2553/5000 -- Batch 172/173 -- Loss: 0.02919606 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13303816 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2554/5000 -- Batch 172/173 -- Loss: 0.02168629 -- Train accuracy: 84.5376\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13281758 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2555/5000 -- Batch 172/173 -- Loss: 0.02482067 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13103844 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2556/5000 -- Batch 172/173 -- Loss: 0.03214253 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13588178 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2557/5000 -- Batch 172/173 -- Loss: 0.02351017 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13847311 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2558/5000 -- Batch 172/173 -- Loss: 0.04129754 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12942137 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2559/5000 -- Batch 172/173 -- Loss: 0.01291300 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13599333 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2560/5000 -- Batch 172/173 -- Loss: 0.04074224 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13280129 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2561/5000 -- Batch 172/173 -- Loss: 0.01188188 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12588293 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2562/5000 -- Batch 172/173 -- Loss: 0.02748904 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11776182 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2563/5000 -- Batch 172/173 -- Loss: 0.02127779 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12539147 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2564/5000 -- Batch 172/173 -- Loss: 0.02992033 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11685064 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2565/5000 -- Batch 172/173 -- Loss: 0.02272740 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12457738 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2566/5000 -- Batch 172/173 -- Loss: 0.06571797 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13195112 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2567/5000 -- Batch 172/173 -- Loss: 0.01759449 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12200791 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2568/5000 -- Batch 172/173 -- Loss: 0.04105761 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12515705 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2569/5000 -- Batch 172/173 -- Loss: 0.02054075 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12475032 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2570/5000 -- Batch 172/173 -- Loss: 0.03712819 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12205763 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2571/5000 -- Batch 172/173 -- Loss: 0.02043824 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12214330 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2572/5000 -- Batch 172/173 -- Loss: 0.02868408 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12280011 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2573/5000 -- Batch 172/173 -- Loss: 0.06074887 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12374444 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2574/5000 -- Batch 172/173 -- Loss: 0.02366821 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12742048 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2575/5000 -- Batch 172/173 -- Loss: 0.07090458 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12695046 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2576/5000 -- Batch 172/173 -- Loss: 0.03531453 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12858051 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2577/5000 -- Batch 172/173 -- Loss: 0.03155463 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12748784 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2578/5000 -- Batch 172/173 -- Loss: 0.01137148 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12469432 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2579/5000 -- Batch 172/173 -- Loss: 0.01081249 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13477876 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2580/5000 -- Batch 172/173 -- Loss: 0.02258151 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12531452 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2581/5000 -- Batch 172/173 -- Loss: 0.01433944 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12016363 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2582/5000 -- Batch 172/173 -- Loss: 0.01619173 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12764770 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2583/5000 -- Batch 172/173 -- Loss: 0.02840088 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12794815 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2584/5000 -- Batch 172/173 -- Loss: 0.01469797 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12795257 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2585/5000 -- Batch 172/173 -- Loss: 0.02116952 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13440658 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2586/5000 -- Batch 172/173 -- Loss: 0.01868827 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12906961 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2587/5000 -- Batch 172/173 -- Loss: 0.01940434 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13397839 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2588/5000 -- Batch 172/173 -- Loss: 0.02540320 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12879784 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2589/5000 -- Batch 172/173 -- Loss: 0.02565926 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12459155 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2590/5000 -- Batch 172/173 -- Loss: 0.02165298 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12713152 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2591/5000 -- Batch 172/173 -- Loss: 0.05517596 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12786848 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2592/5000 -- Batch 172/173 -- Loss: 0.06711311 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12597168 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2593/5000 -- Batch 172/173 -- Loss: 0.00934530 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12523485 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2594/5000 -- Batch 172/173 -- Loss: 0.02117635 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13303127 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2595/5000 -- Batch 172/173 -- Loss: 0.02331666 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13458571 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2596/5000 -- Batch 172/173 -- Loss: 0.03357846 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12434528 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2597/5000 -- Batch 172/173 -- Loss: 0.03950271 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13501903 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2598/5000 -- Batch 172/173 -- Loss: 0.02366466 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13158801 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2599/5000 -- Batch 172/173 -- Loss: 0.02444563 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13912484 -- Accuracy: 67.35197368\n",
      "\n",
      "Training:\n",
      "Epoch 2600/5000 -- Batch 172/173 -- Loss: 0.02944227 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13502842 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2601/5000 -- Batch 172/173 -- Loss: 0.03603885 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13352170 -- Accuracy: 68.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 2602/5000 -- Batch 172/173 -- Loss: 0.02135337 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13569421 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2603/5000 -- Batch 172/173 -- Loss: 0.05448802 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11583338 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2604/5000 -- Batch 172/173 -- Loss: 0.02831707 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11628694 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2605/5000 -- Batch 172/173 -- Loss: 0.01660379 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12562345 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2606/5000 -- Batch 172/173 -- Loss: 0.01580257 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12595102 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2607/5000 -- Batch 172/173 -- Loss: 0.02232645 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13252270 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2608/5000 -- Batch 172/173 -- Loss: 0.04456974 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12637032 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2609/5000 -- Batch 172/173 -- Loss: 0.04847339 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12942626 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2610/5000 -- Batch 172/173 -- Loss: 0.02506321 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13080128 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2611/5000 -- Batch 172/173 -- Loss: 0.02401102 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12837356 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2612/5000 -- Batch 172/173 -- Loss: 0.02730552 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13478836 -- Accuracy: 67.59868421\n",
      "\n",
      "Training:\n",
      "Epoch 2613/5000 -- Batch 172/173 -- Loss: 0.03572865 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13178300 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2614/5000 -- Batch 172/173 -- Loss: 0.04229716 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11558060 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2615/5000 -- Batch 172/173 -- Loss: 0.02946917 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13386771 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2616/5000 -- Batch 172/173 -- Loss: 0.03419772 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12433857 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2617/5000 -- Batch 172/173 -- Loss: 0.01446060 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12926341 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2618/5000 -- Batch 172/173 -- Loss: 0.02845302 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12917770 -- Accuracy: 68.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 2619/5000 -- Batch 172/173 -- Loss: 0.04947041 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13247275 -- Accuracy: 68.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 2620/5000 -- Batch 172/173 -- Loss: 0.03627895 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13111055 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2621/5000 -- Batch 172/173 -- Loss: 0.01411992 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13529736 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2622/5000 -- Batch 172/173 -- Loss: 0.02401231 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13121310 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2623/5000 -- Batch 172/173 -- Loss: 0.01799168 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12612612 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2624/5000 -- Batch 172/173 -- Loss: 0.02278586 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13882047 -- Accuracy: 67.76315789\n",
      "\n",
      "Training:\n",
      "Epoch 2625/5000 -- Batch 172/173 -- Loss: 0.01643433 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13507472 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2626/5000 -- Batch 172/173 -- Loss: 0.02042259 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12668177 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2627/5000 -- Batch 172/173 -- Loss: 0.02081139 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12993404 -- Accuracy: 68.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 2628/5000 -- Batch 172/173 -- Loss: 0.03976358 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13624699 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2629/5000 -- Batch 172/173 -- Loss: 0.01826397 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14243304 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2630/5000 -- Batch 172/173 -- Loss: 0.02644290 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13271646 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2631/5000 -- Batch 172/173 -- Loss: 0.02260146 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13327611 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2632/5000 -- Batch 172/173 -- Loss: 0.04292960 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12925484 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2633/5000 -- Batch 172/173 -- Loss: 0.00229518 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13622917 -- Accuracy: 67.68092105\n",
      "\n",
      "Training:\n",
      "Epoch 2634/5000 -- Batch 172/173 -- Loss: 0.01068089 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13976889 -- Accuracy: 67.51644737\n",
      "\n",
      "Training:\n",
      "Epoch 2635/5000 -- Batch 172/173 -- Loss: 0.02961439 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13881658 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2636/5000 -- Batch 172/173 -- Loss: 0.02337940 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13417831 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2637/5000 -- Batch 172/173 -- Loss: 0.02368816 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13405288 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2638/5000 -- Batch 172/173 -- Loss: 0.01027540 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13168887 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2639/5000 -- Batch 172/173 -- Loss: 0.02022753 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13100682 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2640/5000 -- Batch 172/173 -- Loss: 0.01595833 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13402737 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2641/5000 -- Batch 172/173 -- Loss: 0.01180032 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13294477 -- Accuracy: 68.09210526\n",
      "\n",
      "Training:\n",
      "Epoch 2642/5000 -- Batch 172/173 -- Loss: 0.02968508 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13963545 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2643/5000 -- Batch 172/173 -- Loss: 0.02200810 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13499861 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2644/5000 -- Batch 172/173 -- Loss: 0.00866402 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12964652 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2645/5000 -- Batch 172/173 -- Loss: 0.02012874 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13509575 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2646/5000 -- Batch 172/173 -- Loss: 0.03783182 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13582551 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2647/5000 -- Batch 172/173 -- Loss: 0.02363079 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14016224 -- Accuracy: 67.92763158\n",
      "\n",
      "Training:\n",
      "Epoch 2648/5000 -- Batch 172/173 -- Loss: 0.01825740 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14475246 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2649/5000 -- Batch 172/173 -- Loss: 0.01097257 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13108595 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2650/5000 -- Batch 172/173 -- Loss: 0.03328007 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13545467 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2651/5000 -- Batch 172/173 -- Loss: 0.01438875 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12899191 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2652/5000 -- Batch 172/173 -- Loss: 0.01599886 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13428647 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2653/5000 -- Batch 172/173 -- Loss: 0.03564911 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12279401 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2654/5000 -- Batch 172/173 -- Loss: 0.04192581 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11888502 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2655/5000 -- Batch 172/173 -- Loss: 0.02604581 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13022616 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2656/5000 -- Batch 172/173 -- Loss: 0.04223075 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12261521 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2657/5000 -- Batch 172/173 -- Loss: 0.00648032 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13118133 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2658/5000 -- Batch 172/173 -- Loss: 0.01295759 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13527232 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2659/5000 -- Batch 172/173 -- Loss: 0.07150896 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12975637 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2660/5000 -- Batch 172/173 -- Loss: 0.04089320 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12783239 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2661/5000 -- Batch 172/173 -- Loss: 0.03979394 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12361717 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2662/5000 -- Batch 172/173 -- Loss: 0.03000748 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12652177 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2663/5000 -- Batch 172/173 -- Loss: 0.04345190 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13158903 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2664/5000 -- Batch 172/173 -- Loss: 0.01379870 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13938227 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2665/5000 -- Batch 172/173 -- Loss: 0.02174959 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12697843 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2666/5000 -- Batch 172/173 -- Loss: 0.03028820 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13016563 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2667/5000 -- Batch 172/173 -- Loss: 0.01041876 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13401449 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2668/5000 -- Batch 172/173 -- Loss: 0.01656827 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12692786 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2669/5000 -- Batch 172/173 -- Loss: 0.04805451 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13015457 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2670/5000 -- Batch 172/173 -- Loss: 0.01941891 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13073635 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2671/5000 -- Batch 172/173 -- Loss: 0.04401423 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13637321 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2672/5000 -- Batch 172/173 -- Loss: 0.01299568 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13251903 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2673/5000 -- Batch 172/173 -- Loss: 0.01491609 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13953299 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2674/5000 -- Batch 172/173 -- Loss: 0.06445338 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13382552 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2675/5000 -- Batch 172/173 -- Loss: 0.04047634 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13316524 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2676/5000 -- Batch 172/173 -- Loss: 0.01366430 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12903201 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2677/5000 -- Batch 172/173 -- Loss: 0.02718785 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13194367 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2678/5000 -- Batch 172/173 -- Loss: 0.01809080 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13453477 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2679/5000 -- Batch 172/173 -- Loss: 0.02609541 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12671918 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2680/5000 -- Batch 172/173 -- Loss: 0.03754045 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12711477 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2681/5000 -- Batch 172/173 -- Loss: 0.02463787 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12819208 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2682/5000 -- Batch 172/173 -- Loss: 0.02840465 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13370285 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2683/5000 -- Batch 172/173 -- Loss: 0.04310478 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13296161 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2684/5000 -- Batch 172/173 -- Loss: 0.01779763 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13657364 -- Accuracy: 68.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 2685/5000 -- Batch 172/173 -- Loss: 0.02360642 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13288341 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2686/5000 -- Batch 172/173 -- Loss: 0.01660915 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13537786 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2687/5000 -- Batch 172/173 -- Loss: 0.01270379 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13231319 -- Accuracy: 68.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 2688/5000 -- Batch 172/173 -- Loss: 0.03326349 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13781708 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2689/5000 -- Batch 172/173 -- Loss: 0.00821979 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13141747 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2690/5000 -- Batch 172/173 -- Loss: 0.03213890 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12550540 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2691/5000 -- Batch 172/173 -- Loss: 0.01652365 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13133321 -- Accuracy: 68.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 2692/5000 -- Batch 172/173 -- Loss: 0.04210550 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13667442 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2693/5000 -- Batch 172/173 -- Loss: 0.01455253 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13848594 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2694/5000 -- Batch 172/173 -- Loss: 0.02335291 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13556942 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2695/5000 -- Batch 172/173 -- Loss: 0.04035208 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13282839 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2696/5000 -- Batch 172/173 -- Loss: 0.02025577 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13927218 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2697/5000 -- Batch 172/173 -- Loss: 0.01773196 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13633621 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2698/5000 -- Batch 172/173 -- Loss: 0.00759585 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12952311 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2699/5000 -- Batch 172/173 -- Loss: 0.04058309 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12993812 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2700/5000 -- Batch 172/173 -- Loss: 0.02130416 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13686444 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2701/5000 -- Batch 172/173 -- Loss: 0.03752747 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12736672 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2702/5000 -- Batch 172/173 -- Loss: 0.02001858 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13243800 -- Accuracy: 67.84539474\n",
      "\n",
      "Training:\n",
      "Epoch 2703/5000 -- Batch 172/173 -- Loss: 0.00629268 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13475294 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2704/5000 -- Batch 172/173 -- Loss: 0.02698717 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14050033 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2705/5000 -- Batch 172/173 -- Loss: 0.01981362 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13524592 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2706/5000 -- Batch 172/173 -- Loss: 0.08842326 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13260515 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2707/5000 -- Batch 172/173 -- Loss: 0.05474883 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12796440 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2708/5000 -- Batch 172/173 -- Loss: 0.01727314 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13417703 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2709/5000 -- Batch 172/173 -- Loss: 0.01774186 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12292469 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2710/5000 -- Batch 172/173 -- Loss: 0.02365410 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13576021 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2711/5000 -- Batch 172/173 -- Loss: 0.03225511 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13708312 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2712/5000 -- Batch 172/173 -- Loss: 0.03492121 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13687443 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2713/5000 -- Batch 172/173 -- Loss: 0.01498626 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12487083 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2714/5000 -- Batch 172/173 -- Loss: 0.01420583 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13217679 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2715/5000 -- Batch 172/173 -- Loss: 0.01362023 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13494319 -- Accuracy: 68.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 2716/5000 -- Batch 172/173 -- Loss: 0.05707284 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13651972 -- Accuracy: 68.17434211\n",
      "\n",
      "Training:\n",
      "Epoch 2717/5000 -- Batch 172/173 -- Loss: 0.03468954 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13814059 -- Accuracy: 68.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 2718/5000 -- Batch 172/173 -- Loss: 0.03690525 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13643021 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2719/5000 -- Batch 172/173 -- Loss: 0.01860339 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14068304 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2720/5000 -- Batch 172/173 -- Loss: 0.03362314 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13652757 -- Accuracy: 68.42105263\n",
      "\n",
      "Training:\n",
      "Epoch 2721/5000 -- Batch 172/173 -- Loss: 0.01512298 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13327638 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2722/5000 -- Batch 172/173 -- Loss: 0.03111330 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13548577 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2723/5000 -- Batch 172/173 -- Loss: 0.01878649 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13701408 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2724/5000 -- Batch 172/173 -- Loss: 0.02614788 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13569640 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2725/5000 -- Batch 172/173 -- Loss: 0.01358582 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13185371 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2726/5000 -- Batch 172/173 -- Loss: 0.01702961 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12968310 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2727/5000 -- Batch 172/173 -- Loss: 0.01374962 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12756363 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2728/5000 -- Batch 172/173 -- Loss: 0.01302029 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13276934 -- Accuracy: 68.25657895\n",
      "\n",
      "Training:\n",
      "Epoch 2729/5000 -- Batch 172/173 -- Loss: 0.02005639 -- Train accuracy: 84.8085\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13272013 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2730/5000 -- Batch 172/173 -- Loss: 0.03163875 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13014825 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2731/5000 -- Batch 172/173 -- Loss: 0.01729557 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13212531 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2732/5000 -- Batch 172/173 -- Loss: 0.00759119 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13324088 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2733/5000 -- Batch 172/173 -- Loss: 0.03369407 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13307326 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2734/5000 -- Batch 172/173 -- Loss: 0.01520905 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13164429 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2735/5000 -- Batch 172/173 -- Loss: 0.01012473 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11897468 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2736/5000 -- Batch 172/173 -- Loss: 0.02916968 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12628751 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2737/5000 -- Batch 172/173 -- Loss: 0.03141519 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13643323 -- Accuracy: 68.00986842\n",
      "\n",
      "Training:\n",
      "Epoch 2738/5000 -- Batch 172/173 -- Loss: 0.00963037 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12902907 -- Accuracy: 68.33881579\n",
      "\n",
      "Training:\n",
      "Epoch 2739/5000 -- Batch 172/173 -- Loss: 0.03935706 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13416174 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2740/5000 -- Batch 172/173 -- Loss: 0.00702899 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12974729 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2741/5000 -- Batch 172/173 -- Loss: 0.03612534 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13082570 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2742/5000 -- Batch 172/173 -- Loss: 0.02546515 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13896753 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2743/5000 -- Batch 172/173 -- Loss: 0.01610941 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13260398 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2744/5000 -- Batch 172/173 -- Loss: 0.04850422 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12872927 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2745/5000 -- Batch 172/173 -- Loss: 0.01638358 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12985223 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2746/5000 -- Batch 172/173 -- Loss: 0.01767659 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12728750 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2747/5000 -- Batch 172/173 -- Loss: 0.01207848 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13094947 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2748/5000 -- Batch 172/173 -- Loss: 0.09089087 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13559314 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2749/5000 -- Batch 172/173 -- Loss: 0.03494982 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13422310 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2750/5000 -- Batch 172/173 -- Loss: 0.02709769 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13296109 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2751/5000 -- Batch 172/173 -- Loss: 0.01546592 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12866974 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2752/5000 -- Batch 172/173 -- Loss: 0.02277954 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13441291 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2753/5000 -- Batch 172/173 -- Loss: 0.02527922 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12633569 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2754/5000 -- Batch 172/173 -- Loss: 0.02437453 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13064475 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2755/5000 -- Batch 172/173 -- Loss: 0.00628866 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13021282 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2756/5000 -- Batch 172/173 -- Loss: 0.03046271 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13365647 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2757/5000 -- Batch 172/173 -- Loss: 0.01693218 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12462629 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2758/5000 -- Batch 172/173 -- Loss: 0.02173989 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12493294 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2759/5000 -- Batch 172/173 -- Loss: 0.01394098 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12756623 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2760/5000 -- Batch 172/173 -- Loss: 0.02061824 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13004198 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2761/5000 -- Batch 172/173 -- Loss: 0.00985542 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12461622 -- Accuracy: 68.50328947\n",
      "\n",
      "Training:\n",
      "Epoch 2762/5000 -- Batch 172/173 -- Loss: 0.02953739 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13140252 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2763/5000 -- Batch 172/173 -- Loss: 0.03329432 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12782782 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2764/5000 -- Batch 172/173 -- Loss: 0.01461352 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13129430 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2765/5000 -- Batch 172/173 -- Loss: 0.06196216 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13440791 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2766/5000 -- Batch 172/173 -- Loss: 0.01666193 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12866591 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2767/5000 -- Batch 172/173 -- Loss: 0.02726296 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13257308 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2768/5000 -- Batch 172/173 -- Loss: 0.03352209 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12927864 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2769/5000 -- Batch 172/173 -- Loss: 0.04736183 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13063521 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2770/5000 -- Batch 172/173 -- Loss: 0.03812208 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12714540 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2771/5000 -- Batch 172/173 -- Loss: 0.01454632 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12532511 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2772/5000 -- Batch 172/173 -- Loss: 0.02950617 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13394110 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2773/5000 -- Batch 172/173 -- Loss: 0.02544970 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12254144 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2774/5000 -- Batch 172/173 -- Loss: 0.03475617 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13095097 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2775/5000 -- Batch 172/173 -- Loss: 0.01668913 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13221991 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2776/5000 -- Batch 172/173 -- Loss: 0.05003313 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12595083 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2777/5000 -- Batch 172/173 -- Loss: 0.02557549 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12430684 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2778/5000 -- Batch 172/173 -- Loss: 0.02133633 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13050957 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2779/5000 -- Batch 172/173 -- Loss: 0.01546607 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12638258 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2780/5000 -- Batch 172/173 -- Loss: 0.03130600 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13573919 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2781/5000 -- Batch 172/173 -- Loss: 0.08713873 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13104469 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2782/5000 -- Batch 172/173 -- Loss: 0.02534436 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13682641 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2783/5000 -- Batch 172/173 -- Loss: 0.03120462 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13310060 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2784/5000 -- Batch 172/173 -- Loss: 0.01933402 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12526341 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2785/5000 -- Batch 172/173 -- Loss: 0.01955953 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12350600 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2786/5000 -- Batch 172/173 -- Loss: 0.02683448 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13896930 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2787/5000 -- Batch 172/173 -- Loss: 0.02101323 -- Train accuracy: 84.6189\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11321463 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 2788/5000 -- Batch 172/173 -- Loss: 0.04434613 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11515646 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 2789/5000 -- Batch 172/173 -- Loss: 0.02848702 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10535728 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2790/5000 -- Batch 172/173 -- Loss: 0.01591498 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10456325 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2791/5000 -- Batch 172/173 -- Loss: 0.01403961 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10559540 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2792/5000 -- Batch 172/173 -- Loss: 0.03137513 -- Train accuracy: 84.7001\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10354250 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2793/5000 -- Batch 172/173 -- Loss: 0.07280247 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10045392 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2794/5000 -- Batch 172/173 -- Loss: 0.01450630 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10877925 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2795/5000 -- Batch 172/173 -- Loss: 0.03387660 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10600232 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2796/5000 -- Batch 172/173 -- Loss: 0.03918381 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10692620 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2797/5000 -- Batch 172/173 -- Loss: 0.04430138 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12249014 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2798/5000 -- Batch 172/173 -- Loss: 0.03014494 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13537822 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2799/5000 -- Batch 172/173 -- Loss: 0.02655861 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10873224 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2800/5000 -- Batch 172/173 -- Loss: 0.04950174 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10346414 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2801/5000 -- Batch 172/173 -- Loss: 0.02693979 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13065185 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2802/5000 -- Batch 172/173 -- Loss: 0.01659179 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13565017 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2803/5000 -- Batch 172/173 -- Loss: 0.03545590 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12869210 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2804/5000 -- Batch 172/173 -- Loss: 0.04088397 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11709600 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2805/5000 -- Batch 172/173 -- Loss: 0.01373078 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13704934 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2806/5000 -- Batch 172/173 -- Loss: 0.03422399 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13566710 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2807/5000 -- Batch 172/173 -- Loss: 0.03459714 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12696863 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2808/5000 -- Batch 172/173 -- Loss: 0.02578877 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13740695 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2809/5000 -- Batch 172/173 -- Loss: 0.01698802 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12565808 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2810/5000 -- Batch 172/173 -- Loss: 0.02304368 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14026166 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2811/5000 -- Batch 172/173 -- Loss: 0.02695721 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13004982 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2812/5000 -- Batch 172/173 -- Loss: 0.03020851 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13517816 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2813/5000 -- Batch 172/173 -- Loss: 0.01642596 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13785537 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2814/5000 -- Batch 172/173 -- Loss: 0.03452846 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13708755 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2815/5000 -- Batch 172/173 -- Loss: 0.02543979 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13564631 -- Accuracy: 68.66776316\n",
      "\n",
      "Training:\n",
      "Epoch 2816/5000 -- Batch 172/173 -- Loss: 0.01291241 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11487842 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2817/5000 -- Batch 172/173 -- Loss: 0.01416581 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13229628 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2818/5000 -- Batch 172/173 -- Loss: 0.03276540 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12435510 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2819/5000 -- Batch 172/173 -- Loss: 0.01214991 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13035710 -- Accuracy: 68.58552632\n",
      "\n",
      "Training:\n",
      "Epoch 2820/5000 -- Batch 172/173 -- Loss: 0.02638450 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12854606 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2821/5000 -- Batch 172/173 -- Loss: 0.02611328 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13640577 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2822/5000 -- Batch 172/173 -- Loss: 0.00808431 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13484452 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2823/5000 -- Batch 172/173 -- Loss: 0.02745393 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13726849 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2824/5000 -- Batch 172/173 -- Loss: 0.01907137 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13262123 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2825/5000 -- Batch 172/173 -- Loss: 0.02118382 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12706418 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2826/5000 -- Batch 172/173 -- Loss: 0.03885951 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12957511 -- Accuracy: 68.83223684\n",
      "\n",
      "Training:\n",
      "Epoch 2827/5000 -- Batch 172/173 -- Loss: 0.02914715 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10231411 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2828/5000 -- Batch 172/173 -- Loss: 0.02165675 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12563705 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2829/5000 -- Batch 172/173 -- Loss: 0.03373167 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12320149 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2830/5000 -- Batch 172/173 -- Loss: 0.01637952 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12974959 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2831/5000 -- Batch 172/173 -- Loss: 0.02074062 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12480504 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2832/5000 -- Batch 172/173 -- Loss: 0.02730260 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12992279 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2833/5000 -- Batch 172/173 -- Loss: 0.02478160 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13335741 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2834/5000 -- Batch 172/173 -- Loss: 0.01217399 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13187641 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2835/5000 -- Batch 172/173 -- Loss: 0.02020760 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12874671 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2836/5000 -- Batch 172/173 -- Loss: 0.05731190 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12918210 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2837/5000 -- Batch 172/173 -- Loss: 0.01624509 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12923627 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2838/5000 -- Batch 172/173 -- Loss: 0.00805354 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12699643 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2839/5000 -- Batch 172/173 -- Loss: 0.03853600 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12478686 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2840/5000 -- Batch 172/173 -- Loss: 0.04678302 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11749111 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2841/5000 -- Batch 172/173 -- Loss: 0.02629890 -- Train accuracy: 84.7453\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10839293 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2842/5000 -- Batch 172/173 -- Loss: 0.02525138 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12854244 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2843/5000 -- Batch 172/173 -- Loss: 0.04901407 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12980766 -- Accuracy: 68.75000000\n",
      "\n",
      "Training:\n",
      "Epoch 2844/5000 -- Batch 172/173 -- Loss: 0.01344129 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13671254 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2845/5000 -- Batch 172/173 -- Loss: 0.01786856 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13660593 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2846/5000 -- Batch 172/173 -- Loss: 0.02798065 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11694483 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2847/5000 -- Batch 172/173 -- Loss: 0.02748075 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12250407 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2848/5000 -- Batch 172/173 -- Loss: 0.02096754 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14265117 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2849/5000 -- Batch 172/173 -- Loss: 0.03567911 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13236299 -- Accuracy: 68.99671053\n",
      "\n",
      "Training:\n",
      "Epoch 2850/5000 -- Batch 172/173 -- Loss: 0.00762296 -- Train accuracy: 84.9621\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13287236 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2851/5000 -- Batch 172/173 -- Loss: 0.03938606 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13259182 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2852/5000 -- Batch 172/173 -- Loss: 0.03839921 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13076846 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2853/5000 -- Batch 172/173 -- Loss: 0.02168958 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13538714 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2854/5000 -- Batch 172/173 -- Loss: 0.01553733 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13765200 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2855/5000 -- Batch 172/173 -- Loss: 0.03665126 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13766027 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2856/5000 -- Batch 172/173 -- Loss: 0.03115550 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.14105470 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2857/5000 -- Batch 172/173 -- Loss: 0.01197688 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13663933 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2858/5000 -- Batch 172/173 -- Loss: 0.00619742 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12712970 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2859/5000 -- Batch 172/173 -- Loss: 0.02325868 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13728527 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2860/5000 -- Batch 172/173 -- Loss: 0.02182249 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13367226 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2861/5000 -- Batch 172/173 -- Loss: 0.01891408 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13543585 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2862/5000 -- Batch 172/173 -- Loss: 0.03578839 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13158471 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2863/5000 -- Batch 172/173 -- Loss: 0.00953222 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13555936 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2864/5000 -- Batch 172/173 -- Loss: 0.01796583 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13445479 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2865/5000 -- Batch 172/173 -- Loss: 0.01718666 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12761992 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2866/5000 -- Batch 172/173 -- Loss: 0.01989091 -- Train accuracy: 84.7182\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13200290 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2867/5000 -- Batch 172/173 -- Loss: 0.02010109 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13399245 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2868/5000 -- Batch 172/173 -- Loss: 0.02281597 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12519186 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2869/5000 -- Batch 172/173 -- Loss: 0.01144850 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13005611 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2870/5000 -- Batch 172/173 -- Loss: 0.03265763 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12785530 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2871/5000 -- Batch 172/173 -- Loss: 0.00328519 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13748786 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2872/5000 -- Batch 172/173 -- Loss: 0.02956328 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13713505 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2873/5000 -- Batch 172/173 -- Loss: 0.02847400 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13029039 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2874/5000 -- Batch 172/173 -- Loss: 0.01995132 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13206326 -- Accuracy: 68.91447368\n",
      "\n",
      "Training:\n",
      "Epoch 2875/5000 -- Batch 172/173 -- Loss: 0.02701042 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13551071 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2876/5000 -- Batch 172/173 -- Loss: 0.02010433 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13376248 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2877/5000 -- Batch 172/173 -- Loss: 0.03593708 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13644577 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2878/5000 -- Batch 172/173 -- Loss: 0.07677925 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13307447 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2879/5000 -- Batch 172/173 -- Loss: 0.02840039 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13939661 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2880/5000 -- Batch 172/173 -- Loss: 0.01189174 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13759921 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2881/5000 -- Batch 172/173 -- Loss: 0.01828638 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12448340 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2882/5000 -- Batch 172/173 -- Loss: 0.01349260 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12380271 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2883/5000 -- Batch 172/173 -- Loss: 0.00132154 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11734333 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2884/5000 -- Batch 172/173 -- Loss: 0.03586362 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12530942 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2885/5000 -- Batch 172/173 -- Loss: 0.02166051 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13180390 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2886/5000 -- Batch 172/173 -- Loss: 0.05445421 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13080339 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2887/5000 -- Batch 172/173 -- Loss: 0.03784694 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13313328 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2888/5000 -- Batch 172/173 -- Loss: 0.01033802 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12891736 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2889/5000 -- Batch 172/173 -- Loss: 0.01284300 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12656370 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2890/5000 -- Batch 172/173 -- Loss: 0.00736455 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13599127 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2891/5000 -- Batch 172/173 -- Loss: 0.01899808 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13925614 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2892/5000 -- Batch 172/173 -- Loss: 0.03741582 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12425312 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2893/5000 -- Batch 172/173 -- Loss: 0.03113119 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13509487 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2894/5000 -- Batch 172/173 -- Loss: 0.01419983 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12948891 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2895/5000 -- Batch 172/173 -- Loss: 0.03108308 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12776170 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2896/5000 -- Batch 172/173 -- Loss: 0.04588369 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13211834 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2897/5000 -- Batch 172/173 -- Loss: 0.08326009 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13558322 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2898/5000 -- Batch 172/173 -- Loss: 0.01092426 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13595843 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2899/5000 -- Batch 172/173 -- Loss: 0.01739583 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13250773 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2900/5000 -- Batch 172/173 -- Loss: 0.01126471 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13765018 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2901/5000 -- Batch 172/173 -- Loss: 0.01884549 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12776387 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2902/5000 -- Batch 172/173 -- Loss: 0.03110504 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13141804 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2903/5000 -- Batch 172/173 -- Loss: 0.03149625 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13269498 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2904/5000 -- Batch 172/173 -- Loss: 0.02151661 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13292363 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 2905/5000 -- Batch 172/173 -- Loss: 0.02080662 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12978731 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2906/5000 -- Batch 172/173 -- Loss: 0.02372442 -- Train accuracy: 84.9530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13039082 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2907/5000 -- Batch 172/173 -- Loss: 0.02737771 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13264862 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2908/5000 -- Batch 172/173 -- Loss: 0.02871609 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12678073 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2909/5000 -- Batch 172/173 -- Loss: 0.02173998 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12940260 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2910/5000 -- Batch 172/173 -- Loss: 0.03351106 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12886243 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2911/5000 -- Batch 172/173 -- Loss: 0.01446792 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13138656 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2912/5000 -- Batch 172/173 -- Loss: 0.02502068 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13369771 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2913/5000 -- Batch 172/173 -- Loss: 0.01886060 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12531849 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2914/5000 -- Batch 172/173 -- Loss: 0.05513902 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13015771 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2915/5000 -- Batch 172/173 -- Loss: 0.07960678 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12534117 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2916/5000 -- Batch 172/173 -- Loss: 0.02494405 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12884393 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2917/5000 -- Batch 172/173 -- Loss: 0.03077030 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12466775 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2918/5000 -- Batch 172/173 -- Loss: 0.03638598 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12874565 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2919/5000 -- Batch 172/173 -- Loss: 0.03860102 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12413532 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2920/5000 -- Batch 172/173 -- Loss: 0.01830948 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12584485 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2921/5000 -- Batch 172/173 -- Loss: 0.03407160 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12956289 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2922/5000 -- Batch 172/173 -- Loss: 0.02959939 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13254769 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2923/5000 -- Batch 172/173 -- Loss: 0.03220862 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12871764 -- Accuracy: 69.07894737\n",
      "\n",
      "Training:\n",
      "Epoch 2924/5000 -- Batch 172/173 -- Loss: 0.02713491 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12797708 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2925/5000 -- Batch 172/173 -- Loss: 0.02555221 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13232838 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2926/5000 -- Batch 172/173 -- Loss: 0.01740091 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12727572 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 2927/5000 -- Batch 172/173 -- Loss: 0.01937009 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12843527 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2928/5000 -- Batch 172/173 -- Loss: 0.01314988 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13087852 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2929/5000 -- Batch 172/173 -- Loss: 0.01814255 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12987785 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2930/5000 -- Batch 172/173 -- Loss: 0.01441206 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12866890 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2931/5000 -- Batch 172/173 -- Loss: 0.03142438 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12870297 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2932/5000 -- Batch 172/173 -- Loss: 0.03654554 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13032862 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2933/5000 -- Batch 172/173 -- Loss: 0.02833032 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12905040 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 2934/5000 -- Batch 172/173 -- Loss: 0.04103334 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12976654 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2935/5000 -- Batch 172/173 -- Loss: 0.04840519 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12394674 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2936/5000 -- Batch 172/173 -- Loss: 0.02322986 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12892220 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2937/5000 -- Batch 172/173 -- Loss: 0.04047950 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12630305 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2938/5000 -- Batch 172/173 -- Loss: 0.03097438 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12479081 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2939/5000 -- Batch 172/173 -- Loss: 0.04310956 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12250084 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 2940/5000 -- Batch 172/173 -- Loss: 0.02783879 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12608523 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2941/5000 -- Batch 172/173 -- Loss: 0.06535541 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12805246 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2942/5000 -- Batch 172/173 -- Loss: 0.01994930 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12845539 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2943/5000 -- Batch 172/173 -- Loss: 0.02457279 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12623783 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2944/5000 -- Batch 172/173 -- Loss: 0.01375198 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13193569 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2945/5000 -- Batch 172/173 -- Loss: 0.00809281 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12747693 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2946/5000 -- Batch 172/173 -- Loss: 0.01419017 -- Train accuracy: 84.7363\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12246449 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 2947/5000 -- Batch 172/173 -- Loss: 0.01446052 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12594243 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2948/5000 -- Batch 172/173 -- Loss: 0.02780411 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12366474 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2949/5000 -- Batch 172/173 -- Loss: 0.01958675 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12346465 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2950/5000 -- Batch 172/173 -- Loss: 0.03443114 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12403679 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2951/5000 -- Batch 172/173 -- Loss: 0.00872674 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12510092 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2952/5000 -- Batch 172/173 -- Loss: 0.01496411 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12858894 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 2953/5000 -- Batch 172/173 -- Loss: 0.00285312 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12169791 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2954/5000 -- Batch 172/173 -- Loss: 0.03334527 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12926794 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2955/5000 -- Batch 172/173 -- Loss: 0.02251431 -- Train accuracy: 84.9801\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12842834 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2956/5000 -- Batch 172/173 -- Loss: 0.01777573 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12727558 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2957/5000 -- Batch 172/173 -- Loss: 0.02057664 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12229649 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2958/5000 -- Batch 172/173 -- Loss: 0.02406463 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12604157 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2959/5000 -- Batch 172/173 -- Loss: 0.01433490 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12284602 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2960/5000 -- Batch 172/173 -- Loss: 0.01084807 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12573280 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2961/5000 -- Batch 172/173 -- Loss: 0.01250783 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12230188 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 2962/5000 -- Batch 172/173 -- Loss: 0.02378641 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12725051 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2963/5000 -- Batch 172/173 -- Loss: 0.01785335 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13085153 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 2964/5000 -- Batch 172/173 -- Loss: 0.03353030 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12138728 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 2965/5000 -- Batch 172/173 -- Loss: 0.02798145 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12546938 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2966/5000 -- Batch 172/173 -- Loss: 0.04388980 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12441924 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2967/5000 -- Batch 172/173 -- Loss: 0.03415161 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12113651 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2968/5000 -- Batch 172/173 -- Loss: 0.02583856 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11916616 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2969/5000 -- Batch 172/173 -- Loss: 0.03353202 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12616972 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2970/5000 -- Batch 172/173 -- Loss: 0.02070588 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12483415 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 2971/5000 -- Batch 172/173 -- Loss: 0.04433136 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12623987 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2972/5000 -- Batch 172/173 -- Loss: 0.03180177 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12916128 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 2973/5000 -- Batch 172/173 -- Loss: 0.01339156 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12312082 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2974/5000 -- Batch 172/173 -- Loss: 0.03383337 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12499613 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 2975/5000 -- Batch 172/173 -- Loss: 0.02511974 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11802280 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2976/5000 -- Batch 172/173 -- Loss: 0.03369955 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12582679 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2977/5000 -- Batch 172/173 -- Loss: 0.01829870 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12406186 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2978/5000 -- Batch 172/173 -- Loss: 0.03508469 -- Train accuracy: 84.9530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13030416 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 2979/5000 -- Batch 172/173 -- Loss: 0.03415632 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12223221 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2980/5000 -- Batch 172/173 -- Loss: 0.00979725 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12304458 -- Accuracy: 69.16118421\n",
      "\n",
      "Training:\n",
      "Epoch 2981/5000 -- Batch 172/173 -- Loss: 0.02002415 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12493963 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 2982/5000 -- Batch 172/173 -- Loss: 0.01337590 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11908084 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2983/5000 -- Batch 172/173 -- Loss: 0.03798188 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12189642 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 2984/5000 -- Batch 172/173 -- Loss: 0.02541519 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12328809 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2985/5000 -- Batch 172/173 -- Loss: 0.04566070 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12836619 -- Accuracy: 69.24342105\n",
      "\n",
      "Training:\n",
      "Epoch 2986/5000 -- Batch 172/173 -- Loss: 0.01450706 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12008212 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2987/5000 -- Batch 172/173 -- Loss: 0.02376148 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12846058 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 2988/5000 -- Batch 172/173 -- Loss: 0.02456998 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12982553 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2989/5000 -- Batch 172/173 -- Loss: 0.04625739 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12919713 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2990/5000 -- Batch 172/173 -- Loss: 0.00990324 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12288966 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2991/5000 -- Batch 172/173 -- Loss: 0.03383386 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12985693 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 2992/5000 -- Batch 172/173 -- Loss: 0.02826078 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12801739 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2993/5000 -- Batch 172/173 -- Loss: 0.01520645 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12173156 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 2994/5000 -- Batch 172/173 -- Loss: 0.01815114 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11986834 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2995/5000 -- Batch 172/173 -- Loss: 0.01849572 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12704652 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 2996/5000 -- Batch 172/173 -- Loss: 0.00410224 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12711038 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 2997/5000 -- Batch 172/173 -- Loss: 0.00898217 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12623596 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 2998/5000 -- Batch 172/173 -- Loss: 0.01688275 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12325136 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 2999/5000 -- Batch 172/173 -- Loss: 0.03516000 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12723293 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3000/5000 -- Batch 172/173 -- Loss: 0.01869579 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12329410 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3001/5000 -- Batch 172/173 -- Loss: 0.08043756 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12542412 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 3002/5000 -- Batch 172/173 -- Loss: 0.02708102 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12436566 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 3003/5000 -- Batch 172/173 -- Loss: 0.02868508 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12801518 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3004/5000 -- Batch 172/173 -- Loss: 0.02201997 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12255051 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3005/5000 -- Batch 172/173 -- Loss: 0.01008186 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11863379 -- Accuracy: 69.40789474\n",
      "\n",
      "Training:\n",
      "Epoch 3006/5000 -- Batch 172/173 -- Loss: 0.05463753 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12721125 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3007/5000 -- Batch 172/173 -- Loss: 0.01743498 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12239556 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3008/5000 -- Batch 172/173 -- Loss: 0.05630563 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12267209 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3009/5000 -- Batch 172/173 -- Loss: 0.02019633 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12280899 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3010/5000 -- Batch 172/173 -- Loss: 0.01637300 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12110558 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 3011/5000 -- Batch 172/173 -- Loss: 0.02624688 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12481933 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3012/5000 -- Batch 172/173 -- Loss: 0.03437216 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12699163 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 3013/5000 -- Batch 172/173 -- Loss: 0.03204410 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12647543 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3014/5000 -- Batch 172/173 -- Loss: 0.03111259 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12056898 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 3015/5000 -- Batch 172/173 -- Loss: 0.00891574 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12565703 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3016/5000 -- Batch 172/173 -- Loss: 0.00739631 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12075911 -- Accuracy: 69.32565789\n",
      "\n",
      "Training:\n",
      "Epoch 3017/5000 -- Batch 172/173 -- Loss: 0.01934292 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12085324 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3018/5000 -- Batch 172/173 -- Loss: 0.02879108 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11914233 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 3019/5000 -- Batch 172/173 -- Loss: 0.02050276 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12433869 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3020/5000 -- Batch 172/173 -- Loss: 0.02624688 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12776546 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3021/5000 -- Batch 172/173 -- Loss: 0.04517746 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12012982 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3022/5000 -- Batch 172/173 -- Loss: 0.01641777 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12334640 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 3023/5000 -- Batch 172/173 -- Loss: 0.02161188 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12573601 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 3024/5000 -- Batch 172/173 -- Loss: 0.01701205 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12615490 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 3025/5000 -- Batch 172/173 -- Loss: 0.02930906 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12902110 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 3026/5000 -- Batch 172/173 -- Loss: 0.02214176 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12060698 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3027/5000 -- Batch 172/173 -- Loss: 0.01669399 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12389224 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 3028/5000 -- Batch 172/173 -- Loss: 0.04282634 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12244399 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3029/5000 -- Batch 172/173 -- Loss: 0.02314261 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12065448 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 3030/5000 -- Batch 172/173 -- Loss: 0.00389297 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12520478 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3031/5000 -- Batch 172/173 -- Loss: 0.02846583 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12287315 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3032/5000 -- Batch 172/173 -- Loss: 0.01352616 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12420870 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3033/5000 -- Batch 172/173 -- Loss: 0.03093401 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12411761 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3034/5000 -- Batch 172/173 -- Loss: 0.02133206 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12564989 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3035/5000 -- Batch 172/173 -- Loss: 0.04198927 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12126283 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 3036/5000 -- Batch 172/173 -- Loss: 0.04657803 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12111571 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 3037/5000 -- Batch 172/173 -- Loss: 0.01643281 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12368290 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3038/5000 -- Batch 172/173 -- Loss: 0.03566951 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12456683 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 3039/5000 -- Batch 172/173 -- Loss: 0.03615496 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12481827 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3040/5000 -- Batch 172/173 -- Loss: 0.01678670 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12691993 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3041/5000 -- Batch 172/173 -- Loss: 0.02862544 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12868757 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3042/5000 -- Batch 172/173 -- Loss: 0.04648969 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12444018 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3043/5000 -- Batch 172/173 -- Loss: 0.01570715 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12066604 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 3044/5000 -- Batch 172/173 -- Loss: 0.04994857 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12206409 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3045/5000 -- Batch 172/173 -- Loss: 0.03489634 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12052104 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 3046/5000 -- Batch 172/173 -- Loss: 0.03553522 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11897860 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3047/5000 -- Batch 172/173 -- Loss: 0.02073221 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12213962 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3048/5000 -- Batch 172/173 -- Loss: 0.01246783 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12133676 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3049/5000 -- Batch 172/173 -- Loss: 0.02527451 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12447567 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3050/5000 -- Batch 172/173 -- Loss: 0.03944585 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10901476 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3051/5000 -- Batch 172/173 -- Loss: 0.01995641 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10591323 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3052/5000 -- Batch 172/173 -- Loss: 0.01384583 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11045983 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3053/5000 -- Batch 172/173 -- Loss: 0.02261234 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12254849 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3054/5000 -- Batch 172/173 -- Loss: 0.03979351 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12092075 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3055/5000 -- Batch 172/173 -- Loss: 0.02659690 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12393038 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3056/5000 -- Batch 172/173 -- Loss: 0.02888441 -- Train accuracy: 84.9621\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12058118 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3057/5000 -- Batch 172/173 -- Loss: 0.01497107 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12167089 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3058/5000 -- Batch 172/173 -- Loss: 0.03068480 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12052087 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3059/5000 -- Batch 172/173 -- Loss: 0.03516197 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12042190 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3060/5000 -- Batch 172/173 -- Loss: 0.03937844 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12210479 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3061/5000 -- Batch 172/173 -- Loss: 0.00878112 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13161551 -- Accuracy: 69.49013158\n",
      "\n",
      "Training:\n",
      "Epoch 3062/5000 -- Batch 172/173 -- Loss: 0.02967207 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11981781 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3063/5000 -- Batch 172/173 -- Loss: 0.00744612 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11935412 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3064/5000 -- Batch 172/173 -- Loss: 0.04417692 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12115306 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 3065/5000 -- Batch 172/173 -- Loss: 0.01996761 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12053529 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3066/5000 -- Batch 172/173 -- Loss: 0.05060496 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12433983 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3067/5000 -- Batch 172/173 -- Loss: 0.02104733 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12906290 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 3068/5000 -- Batch 172/173 -- Loss: 0.03855598 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12145764 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3069/5000 -- Batch 172/173 -- Loss: 0.04827305 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12369750 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3070/5000 -- Batch 172/173 -- Loss: 0.02020424 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12284579 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3071/5000 -- Batch 172/173 -- Loss: 0.03775734 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12385290 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3072/5000 -- Batch 172/173 -- Loss: 0.03082229 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12678040 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 3073/5000 -- Batch 172/173 -- Loss: 0.01596990 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12648358 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3074/5000 -- Batch 172/173 -- Loss: 0.04185952 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12711230 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3075/5000 -- Batch 172/173 -- Loss: 0.01712380 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12285982 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3076/5000 -- Batch 172/173 -- Loss: 0.02636378 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12382952 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 3077/5000 -- Batch 172/173 -- Loss: 0.04037148 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12250718 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3078/5000 -- Batch 172/173 -- Loss: 0.02118363 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12702302 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3079/5000 -- Batch 172/173 -- Loss: 0.02290957 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11981941 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3080/5000 -- Batch 172/173 -- Loss: 0.02349258 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12263322 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3081/5000 -- Batch 172/173 -- Loss: 0.03901790 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12137203 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3082/5000 -- Batch 172/173 -- Loss: 0.01633946 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12308620 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3083/5000 -- Batch 172/173 -- Loss: 0.02498559 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12327314 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3084/5000 -- Batch 172/173 -- Loss: 0.02484312 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12084044 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3085/5000 -- Batch 172/173 -- Loss: 0.02417091 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12158201 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3086/5000 -- Batch 172/173 -- Loss: 0.03483083 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12619313 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3087/5000 -- Batch 172/173 -- Loss: 0.01293835 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12700040 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3088/5000 -- Batch 172/173 -- Loss: 0.04293652 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12596186 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3089/5000 -- Batch 172/173 -- Loss: 0.02177358 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12058418 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3090/5000 -- Batch 172/173 -- Loss: 0.01418710 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12102640 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3091/5000 -- Batch 172/173 -- Loss: 0.05902021 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12343177 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3092/5000 -- Batch 172/173 -- Loss: 0.01604314 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12220730 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 3093/5000 -- Batch 172/173 -- Loss: 0.02915255 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11402992 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3094/5000 -- Batch 172/173 -- Loss: 0.02097351 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11870790 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3095/5000 -- Batch 172/173 -- Loss: 0.01654685 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12044753 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3096/5000 -- Batch 172/173 -- Loss: 0.03464079 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12031193 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3097/5000 -- Batch 172/173 -- Loss: 0.02395494 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11830284 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3098/5000 -- Batch 172/173 -- Loss: 0.03820425 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12532176 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3099/5000 -- Batch 172/173 -- Loss: 0.00803512 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12008987 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3100/5000 -- Batch 172/173 -- Loss: 0.05737139 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12038101 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3101/5000 -- Batch 172/173 -- Loss: 0.03095224 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12159267 -- Accuracy: 69.65460526\n",
      "\n",
      "Training:\n",
      "Epoch 3102/5000 -- Batch 172/173 -- Loss: 0.03202775 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11576135 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3103/5000 -- Batch 172/173 -- Loss: 0.02774009 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12572641 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3104/5000 -- Batch 172/173 -- Loss: 0.01170578 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11307514 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3105/5000 -- Batch 172/173 -- Loss: 0.01224141 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11686668 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3106/5000 -- Batch 172/173 -- Loss: 0.01178408 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11830312 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3107/5000 -- Batch 172/173 -- Loss: 0.02013085 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12105449 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3108/5000 -- Batch 172/173 -- Loss: 0.05332077 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12096976 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3109/5000 -- Batch 172/173 -- Loss: 0.07784639 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11544674 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3110/5000 -- Batch 172/173 -- Loss: 0.02715171 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11759331 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3111/5000 -- Batch 172/173 -- Loss: 0.04046375 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11713058 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3112/5000 -- Batch 172/173 -- Loss: 0.03036315 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11925951 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3113/5000 -- Batch 172/173 -- Loss: 0.02218236 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12181270 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3114/5000 -- Batch 172/173 -- Loss: 0.02882800 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11667896 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3115/5000 -- Batch 172/173 -- Loss: 0.03693952 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11913456 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3116/5000 -- Batch 172/173 -- Loss: 0.01506182 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11402581 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3117/5000 -- Batch 172/173 -- Loss: 0.02005784 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11545727 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3118/5000 -- Batch 172/173 -- Loss: 0.01766484 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11793471 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3119/5000 -- Batch 172/173 -- Loss: 0.01872621 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11946702 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3120/5000 -- Batch 172/173 -- Loss: 0.01629242 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12052413 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3121/5000 -- Batch 172/173 -- Loss: 0.02289490 -- Train accuracy: 84.9621\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11759154 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3122/5000 -- Batch 172/173 -- Loss: 0.03131506 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11575633 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3123/5000 -- Batch 172/173 -- Loss: 0.02328446 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11973127 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3124/5000 -- Batch 172/173 -- Loss: 0.01069783 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11708782 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3125/5000 -- Batch 172/173 -- Loss: 0.01621468 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12405429 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3126/5000 -- Batch 172/173 -- Loss: 0.02085694 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12302755 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3127/5000 -- Batch 172/173 -- Loss: 0.01865400 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11841581 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3128/5000 -- Batch 172/173 -- Loss: 0.03212857 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11235666 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3129/5000 -- Batch 172/173 -- Loss: 0.04537494 -- Train accuracy: 84.4743\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11597299 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3130/5000 -- Batch 172/173 -- Loss: 0.00559318 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12593160 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3131/5000 -- Batch 172/173 -- Loss: 0.05051519 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12436727 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3132/5000 -- Batch 172/173 -- Loss: 0.05029375 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12418053 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3133/5000 -- Batch 172/173 -- Loss: 0.02092153 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11711234 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3134/5000 -- Batch 172/173 -- Loss: 0.01891091 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11581238 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3135/5000 -- Batch 172/173 -- Loss: 0.02400542 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11472014 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3136/5000 -- Batch 172/173 -- Loss: 0.02796889 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11799333 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3137/5000 -- Batch 172/173 -- Loss: 0.03945341 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12177104 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3138/5000 -- Batch 172/173 -- Loss: 0.02857714 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11621658 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3139/5000 -- Batch 172/173 -- Loss: 0.00584950 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11865010 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3140/5000 -- Batch 172/173 -- Loss: 0.03023200 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12586785 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3141/5000 -- Batch 172/173 -- Loss: 0.03350229 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11856144 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3142/5000 -- Batch 172/173 -- Loss: 0.03617771 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12765845 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3143/5000 -- Batch 172/173 -- Loss: 0.02744580 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11884226 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3144/5000 -- Batch 172/173 -- Loss: 0.01781342 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12727687 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3145/5000 -- Batch 172/173 -- Loss: 0.00807129 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11019942 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3146/5000 -- Batch 172/173 -- Loss: 0.04047700 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11477344 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3147/5000 -- Batch 172/173 -- Loss: 0.03179620 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12281399 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3148/5000 -- Batch 172/173 -- Loss: 0.04258735 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11990655 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3149/5000 -- Batch 172/173 -- Loss: 0.05280549 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12098064 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3150/5000 -- Batch 172/173 -- Loss: 0.02563971 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11628644 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3151/5000 -- Batch 172/173 -- Loss: 0.04222572 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12657968 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3152/5000 -- Batch 172/173 -- Loss: 0.02772636 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11492513 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3153/5000 -- Batch 172/173 -- Loss: 0.05336937 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11435988 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 3154/5000 -- Batch 172/173 -- Loss: 0.07648898 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12458270 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3155/5000 -- Batch 172/173 -- Loss: 0.04132730 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11872268 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3156/5000 -- Batch 172/173 -- Loss: 0.00708178 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12400647 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3157/5000 -- Batch 172/173 -- Loss: 0.00565908 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12492008 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3158/5000 -- Batch 172/173 -- Loss: 0.03391827 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11968012 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3159/5000 -- Batch 172/173 -- Loss: 0.01257061 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11903365 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3160/5000 -- Batch 172/173 -- Loss: 0.01904403 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11746900 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3161/5000 -- Batch 172/173 -- Loss: 0.03200660 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11782433 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3162/5000 -- Batch 172/173 -- Loss: 0.01851729 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11532259 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3163/5000 -- Batch 172/173 -- Loss: 0.03180540 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11831537 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3164/5000 -- Batch 172/173 -- Loss: 0.01606743 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12274868 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3165/5000 -- Batch 172/173 -- Loss: 0.03648203 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12064095 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3166/5000 -- Batch 172/173 -- Loss: 0.02095551 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11191210 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3167/5000 -- Batch 172/173 -- Loss: 0.02637945 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12658773 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3168/5000 -- Batch 172/173 -- Loss: 0.01552021 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12495468 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3169/5000 -- Batch 172/173 -- Loss: 0.01983699 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11777732 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3170/5000 -- Batch 172/173 -- Loss: 0.01272475 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12421681 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3171/5000 -- Batch 172/173 -- Loss: 0.01568921 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12431918 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3172/5000 -- Batch 172/173 -- Loss: 0.02409036 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12734004 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3173/5000 -- Batch 172/173 -- Loss: 0.01411017 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11832848 -- Accuracy: 69.57236842\n",
      "\n",
      "Training:\n",
      "Epoch 3174/5000 -- Batch 172/173 -- Loss: 0.01644718 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11643183 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3175/5000 -- Batch 172/173 -- Loss: 0.01550293 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11490157 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 3176/5000 -- Batch 172/173 -- Loss: 0.01265856 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11427322 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3177/5000 -- Batch 172/173 -- Loss: 0.01886615 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11377001 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3178/5000 -- Batch 172/173 -- Loss: 0.02244705 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12036247 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3179/5000 -- Batch 172/173 -- Loss: 0.09992921 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11696018 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3180/5000 -- Batch 172/173 -- Loss: 0.05812522 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12510500 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3181/5000 -- Batch 172/173 -- Loss: 0.01752485 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11744698 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3182/5000 -- Batch 172/173 -- Loss: 0.01990255 -- Train accuracy: 84.7092\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11638829 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3183/5000 -- Batch 172/173 -- Loss: 0.02894919 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13122362 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3184/5000 -- Batch 172/173 -- Loss: 0.03034506 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11551617 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3185/5000 -- Batch 172/173 -- Loss: 0.03560209 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12045639 -- Accuracy: 69.73684211\n",
      "\n",
      "Training:\n",
      "Epoch 3186/5000 -- Batch 172/173 -- Loss: 0.02184249 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12040422 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3187/5000 -- Batch 172/173 -- Loss: 0.02126880 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11455829 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3188/5000 -- Batch 172/173 -- Loss: 0.02834766 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11983723 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3189/5000 -- Batch 172/173 -- Loss: 0.02349522 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11565289 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3190/5000 -- Batch 172/173 -- Loss: 0.02290250 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11582054 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3191/5000 -- Batch 172/173 -- Loss: 0.02451338 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11873807 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3192/5000 -- Batch 172/173 -- Loss: 0.03373773 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11726768 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3193/5000 -- Batch 172/173 -- Loss: 0.03445905 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11748565 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3194/5000 -- Batch 172/173 -- Loss: 0.01756665 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12068071 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3195/5000 -- Batch 172/173 -- Loss: 0.02122667 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11820468 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3196/5000 -- Batch 172/173 -- Loss: 0.01138118 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11729112 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3197/5000 -- Batch 172/173 -- Loss: 0.02265241 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12057435 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3198/5000 -- Batch 172/173 -- Loss: 0.07118931 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11406621 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3199/5000 -- Batch 172/173 -- Loss: 0.01565470 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12555228 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3200/5000 -- Batch 172/173 -- Loss: 0.04173885 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11333023 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3201/5000 -- Batch 172/173 -- Loss: 0.01789056 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11047855 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3202/5000 -- Batch 172/173 -- Loss: 0.09099351 -- Train accuracy: 84.9530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11208988 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3203/5000 -- Batch 172/173 -- Loss: 0.01806274 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11445620 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3204/5000 -- Batch 172/173 -- Loss: 0.08312672 -- Train accuracy: 84.5195\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10868178 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3205/5000 -- Batch 172/173 -- Loss: 0.02873420 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11699045 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3206/5000 -- Batch 172/173 -- Loss: 0.02415702 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11131729 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3207/5000 -- Batch 172/173 -- Loss: 0.04967137 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10958728 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3208/5000 -- Batch 172/173 -- Loss: 0.07032476 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11464186 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3209/5000 -- Batch 172/173 -- Loss: 0.03608666 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11472748 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3210/5000 -- Batch 172/173 -- Loss: 0.02670200 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10814390 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3211/5000 -- Batch 172/173 -- Loss: 0.01492250 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11044689 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3212/5000 -- Batch 172/173 -- Loss: 0.02527550 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11368539 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3213/5000 -- Batch 172/173 -- Loss: 0.04039426 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11040264 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3214/5000 -- Batch 172/173 -- Loss: 0.03281179 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10944038 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3215/5000 -- Batch 172/173 -- Loss: 0.01924227 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11194413 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3216/5000 -- Batch 172/173 -- Loss: 0.00359189 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11473790 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3217/5000 -- Batch 172/173 -- Loss: 0.01014407 -- Train accuracy: 84.9530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11067341 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3218/5000 -- Batch 172/173 -- Loss: 0.03391386 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11744585 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3219/5000 -- Batch 172/173 -- Loss: 0.02092826 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11617958 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3220/5000 -- Batch 172/173 -- Loss: 0.02347029 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11658433 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3221/5000 -- Batch 172/173 -- Loss: 0.02342271 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11838965 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3222/5000 -- Batch 172/173 -- Loss: 0.01847203 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11582512 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3223/5000 -- Batch 172/173 -- Loss: 0.03424758 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11557381 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3224/5000 -- Batch 172/173 -- Loss: 0.13827118 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11896153 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3225/5000 -- Batch 172/173 -- Loss: 0.00887377 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11260778 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3226/5000 -- Batch 172/173 -- Loss: 0.01352890 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11865192 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3227/5000 -- Batch 172/173 -- Loss: 0.01407457 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11433809 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3228/5000 -- Batch 172/173 -- Loss: 0.02410771 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11674847 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3229/5000 -- Batch 172/173 -- Loss: 0.03069579 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11748524 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3230/5000 -- Batch 172/173 -- Loss: 0.03058422 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11992542 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3231/5000 -- Batch 172/173 -- Loss: 0.01719206 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11808718 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3232/5000 -- Batch 172/173 -- Loss: 0.07312217 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11717773 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3233/5000 -- Batch 172/173 -- Loss: 0.03195942 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11695289 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3234/5000 -- Batch 172/173 -- Loss: 0.02103531 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12188865 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3235/5000 -- Batch 172/173 -- Loss: 0.05058416 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11445794 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3236/5000 -- Batch 172/173 -- Loss: 0.02713624 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12093401 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3237/5000 -- Batch 172/173 -- Loss: 0.00654054 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11689621 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3238/5000 -- Batch 172/173 -- Loss: 0.03550313 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10881558 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3239/5000 -- Batch 172/173 -- Loss: 0.02346780 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11377647 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3240/5000 -- Batch 172/173 -- Loss: 0.04426014 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11239995 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3241/5000 -- Batch 172/173 -- Loss: 0.04886764 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11331781 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3242/5000 -- Batch 172/173 -- Loss: 0.00594762 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10817354 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3243/5000 -- Batch 172/173 -- Loss: 0.01712224 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10756468 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3244/5000 -- Batch 172/173 -- Loss: 0.00722129 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10900260 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3245/5000 -- Batch 172/173 -- Loss: 0.00547077 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11769462 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3246/5000 -- Batch 172/173 -- Loss: 0.00262699 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11129632 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3247/5000 -- Batch 172/173 -- Loss: 0.02489170 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11191628 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3248/5000 -- Batch 172/173 -- Loss: 0.00869366 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11630600 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3249/5000 -- Batch 172/173 -- Loss: 0.02480295 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11595483 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3250/5000 -- Batch 172/173 -- Loss: 0.03980161 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11095781 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3251/5000 -- Batch 172/173 -- Loss: 0.03911922 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11196945 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3252/5000 -- Batch 172/173 -- Loss: 0.03752088 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11913681 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3253/5000 -- Batch 172/173 -- Loss: 0.04141757 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11335322 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3254/5000 -- Batch 172/173 -- Loss: 0.02623538 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11313965 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3255/5000 -- Batch 172/173 -- Loss: 0.04276181 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11702684 -- Accuracy: 69.81907895\n",
      "\n",
      "Training:\n",
      "Epoch 3256/5000 -- Batch 172/173 -- Loss: 0.03138889 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12461668 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3257/5000 -- Batch 172/173 -- Loss: 0.02949369 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11474100 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3258/5000 -- Batch 172/173 -- Loss: 0.02537933 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11805254 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3259/5000 -- Batch 172/173 -- Loss: 0.00231015 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11789412 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3260/5000 -- Batch 172/173 -- Loss: 0.02982577 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11620742 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3261/5000 -- Batch 172/173 -- Loss: 0.01430291 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11499641 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3262/5000 -- Batch 172/173 -- Loss: 0.02510892 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11236306 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3263/5000 -- Batch 172/173 -- Loss: 0.02528910 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11712178 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3264/5000 -- Batch 172/173 -- Loss: 0.02602049 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11419295 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3265/5000 -- Batch 172/173 -- Loss: 0.01569455 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12013827 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3266/5000 -- Batch 172/173 -- Loss: 0.01541271 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12383274 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3267/5000 -- Batch 172/173 -- Loss: 0.02298040 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12270693 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3268/5000 -- Batch 172/173 -- Loss: 0.01599636 -- Train accuracy: 84.7272\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10635085 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3269/5000 -- Batch 172/173 -- Loss: 0.05205720 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10629468 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3270/5000 -- Batch 172/173 -- Loss: 0.02614000 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11883848 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3271/5000 -- Batch 172/173 -- Loss: 0.01212437 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10963776 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3272/5000 -- Batch 172/173 -- Loss: 0.03376286 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11610584 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3273/5000 -- Batch 172/173 -- Loss: 0.01008671 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12148545 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3274/5000 -- Batch 172/173 -- Loss: 0.03306177 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12495888 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3275/5000 -- Batch 172/173 -- Loss: 0.03761047 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12229840 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3276/5000 -- Batch 172/173 -- Loss: 0.03126768 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11799165 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3277/5000 -- Batch 172/173 -- Loss: 0.03339878 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12011103 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3278/5000 -- Batch 172/173 -- Loss: 0.02381763 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12153765 -- Accuracy: 70.06578947\n",
      "\n",
      "Training:\n",
      "Epoch 3279/5000 -- Batch 172/173 -- Loss: 0.05406286 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11583915 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3280/5000 -- Batch 172/173 -- Loss: 0.04044708 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12366572 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3281/5000 -- Batch 172/173 -- Loss: 0.04161231 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11923571 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3282/5000 -- Batch 172/173 -- Loss: 0.05725748 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12162421 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3283/5000 -- Batch 172/173 -- Loss: 0.01754346 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11814865 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3284/5000 -- Batch 172/173 -- Loss: 0.01489676 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12624789 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3285/5000 -- Batch 172/173 -- Loss: 0.02538796 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11808568 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3286/5000 -- Batch 172/173 -- Loss: 0.01522426 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12246883 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3287/5000 -- Batch 172/173 -- Loss: 0.05349538 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12091651 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3288/5000 -- Batch 172/173 -- Loss: 0.01265229 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11674504 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3289/5000 -- Batch 172/173 -- Loss: 0.00407536 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12585669 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3290/5000 -- Batch 172/173 -- Loss: 0.02296561 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12284537 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3291/5000 -- Batch 172/173 -- Loss: 0.01565025 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12045343 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3292/5000 -- Batch 172/173 -- Loss: 0.02314252 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11706423 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3293/5000 -- Batch 172/173 -- Loss: 0.00580562 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11900387 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3294/5000 -- Batch 172/173 -- Loss: 0.02377729 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11925009 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3295/5000 -- Batch 172/173 -- Loss: 0.02471782 -- Train accuracy: 84.9530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12018450 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3296/5000 -- Batch 172/173 -- Loss: 0.01557138 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12608496 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3297/5000 -- Batch 172/173 -- Loss: 0.02987247 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12502320 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3298/5000 -- Batch 172/173 -- Loss: 0.00568473 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12566269 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3299/5000 -- Batch 172/173 -- Loss: 0.03768581 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12245520 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3300/5000 -- Batch 172/173 -- Loss: 0.02266639 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12024769 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3301/5000 -- Batch 172/173 -- Loss: 0.03869388 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12513177 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3302/5000 -- Batch 172/173 -- Loss: 0.02056155 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12092844 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3303/5000 -- Batch 172/173 -- Loss: 0.02443376 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11952438 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3304/5000 -- Batch 172/173 -- Loss: 0.03096932 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12424522 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3305/5000 -- Batch 172/173 -- Loss: 0.04781900 -- Train accuracy: 84.6098\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11973359 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3306/5000 -- Batch 172/173 -- Loss: 0.02266450 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11056277 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3307/5000 -- Batch 172/173 -- Loss: 0.02362305 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10904427 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3308/5000 -- Batch 172/173 -- Loss: 0.02957781 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10589260 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3309/5000 -- Batch 172/173 -- Loss: 0.02308218 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11003800 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3310/5000 -- Batch 172/173 -- Loss: 0.01733864 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11103441 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3311/5000 -- Batch 172/173 -- Loss: 0.01057499 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11405829 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3312/5000 -- Batch 172/173 -- Loss: 0.02471496 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10889302 -- Accuracy: 69.98355263\n",
      "\n",
      "Training:\n",
      "Epoch 3313/5000 -- Batch 172/173 -- Loss: 0.01968900 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11453174 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3314/5000 -- Batch 172/173 -- Loss: 0.01192923 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11403583 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3315/5000 -- Batch 172/173 -- Loss: 0.01744009 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12039041 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3316/5000 -- Batch 172/173 -- Loss: 0.02487778 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11616154 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3317/5000 -- Batch 172/173 -- Loss: 0.04017571 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11734563 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3318/5000 -- Batch 172/173 -- Loss: 0.02328520 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11463372 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3319/5000 -- Batch 172/173 -- Loss: 0.02825456 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11885189 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3320/5000 -- Batch 172/173 -- Loss: 0.01415392 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12036709 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3321/5000 -- Batch 172/173 -- Loss: 0.02894983 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11734524 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3322/5000 -- Batch 172/173 -- Loss: 0.00363184 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12012011 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3323/5000 -- Batch 172/173 -- Loss: 0.02742452 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12098549 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3324/5000 -- Batch 172/173 -- Loss: 0.00489267 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11337979 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3325/5000 -- Batch 172/173 -- Loss: 0.03692706 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11561113 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3326/5000 -- Batch 172/173 -- Loss: 0.04545469 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11952021 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3327/5000 -- Batch 172/173 -- Loss: 0.02740905 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11463813 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3328/5000 -- Batch 172/173 -- Loss: 0.02872469 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11652261 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3329/5000 -- Batch 172/173 -- Loss: 0.02545464 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12521765 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3330/5000 -- Batch 172/173 -- Loss: 0.05643691 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12227931 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3331/5000 -- Batch 172/173 -- Loss: 0.03635688 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11457092 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3332/5000 -- Batch 172/173 -- Loss: 0.02955223 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11846015 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3333/5000 -- Batch 172/173 -- Loss: 0.01876616 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11825744 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3334/5000 -- Batch 172/173 -- Loss: 0.02560383 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12003223 -- Accuracy: 69.90131579\n",
      "\n",
      "Training:\n",
      "Epoch 3335/5000 -- Batch 172/173 -- Loss: 0.03244362 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11837257 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3336/5000 -- Batch 172/173 -- Loss: 0.02041209 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12233978 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3337/5000 -- Batch 172/173 -- Loss: 0.01309648 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11583848 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3338/5000 -- Batch 172/173 -- Loss: 0.04469164 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11457931 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3339/5000 -- Batch 172/173 -- Loss: 0.01956193 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11565873 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3340/5000 -- Batch 172/173 -- Loss: 0.02201187 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12025289 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3341/5000 -- Batch 172/173 -- Loss: 0.01114512 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11709569 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3342/5000 -- Batch 172/173 -- Loss: 0.01696508 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11530020 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3343/5000 -- Batch 172/173 -- Loss: 0.03535710 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11860758 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3344/5000 -- Batch 172/173 -- Loss: 0.03998707 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11692056 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3345/5000 -- Batch 172/173 -- Loss: 0.03486959 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11898195 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3346/5000 -- Batch 172/173 -- Loss: 0.03114452 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11834884 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3347/5000 -- Batch 172/173 -- Loss: 0.01636027 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12169199 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3348/5000 -- Batch 172/173 -- Loss: 0.02627824 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12031930 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3349/5000 -- Batch 172/173 -- Loss: 0.01635108 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11841511 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3350/5000 -- Batch 172/173 -- Loss: 0.04292906 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12036736 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3351/5000 -- Batch 172/173 -- Loss: 0.02947424 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11869384 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3352/5000 -- Batch 172/173 -- Loss: 0.02569545 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11876432 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3353/5000 -- Batch 172/173 -- Loss: 0.02957926 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10976469 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3354/5000 -- Batch 172/173 -- Loss: 0.00749192 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11893728 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3355/5000 -- Batch 172/173 -- Loss: 0.02319306 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12028354 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3356/5000 -- Batch 172/173 -- Loss: 0.01252706 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12097023 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3357/5000 -- Batch 172/173 -- Loss: 0.01140021 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11871069 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3358/5000 -- Batch 172/173 -- Loss: 0.01321451 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11994958 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3359/5000 -- Batch 172/173 -- Loss: 0.01165995 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11922695 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3360/5000 -- Batch 172/173 -- Loss: 0.02400560 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12383706 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3361/5000 -- Batch 172/173 -- Loss: 0.03404298 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11946048 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3362/5000 -- Batch 172/173 -- Loss: 0.03123239 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11975048 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3363/5000 -- Batch 172/173 -- Loss: 0.02336794 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11535627 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3364/5000 -- Batch 172/173 -- Loss: 0.04086939 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11992840 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3365/5000 -- Batch 172/173 -- Loss: 0.00670923 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11481592 -- Accuracy: 70.14802632\n",
      "\n",
      "Training:\n",
      "Epoch 3366/5000 -- Batch 172/173 -- Loss: 0.01635710 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11944782 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3367/5000 -- Batch 172/173 -- Loss: 0.03862460 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12507585 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3368/5000 -- Batch 172/173 -- Loss: 0.01152989 -- Train accuracy: 84.7634\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10470573 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3369/5000 -- Batch 172/173 -- Loss: 0.01460088 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11041163 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3370/5000 -- Batch 172/173 -- Loss: 0.01756224 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10767191 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3371/5000 -- Batch 172/173 -- Loss: 0.02810501 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11692252 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3372/5000 -- Batch 172/173 -- Loss: 0.01770422 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10976462 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3373/5000 -- Batch 172/173 -- Loss: 0.01084362 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12053405 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3374/5000 -- Batch 172/173 -- Loss: 0.02262605 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11639574 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3375/5000 -- Batch 172/173 -- Loss: 0.05066509 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12440360 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3376/5000 -- Batch 172/173 -- Loss: 0.01214154 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10730532 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3377/5000 -- Batch 172/173 -- Loss: 0.01135096 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10688539 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3378/5000 -- Batch 172/173 -- Loss: 0.02490920 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10861208 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3379/5000 -- Batch 172/173 -- Loss: 0.04991450 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11943205 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3380/5000 -- Batch 172/173 -- Loss: 0.02198289 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11494906 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3381/5000 -- Batch 172/173 -- Loss: 0.04425940 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11380105 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3382/5000 -- Batch 172/173 -- Loss: 0.01373783 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11382414 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3383/5000 -- Batch 172/173 -- Loss: 0.00735922 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11205957 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3384/5000 -- Batch 172/173 -- Loss: 0.01759299 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11676045 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3385/5000 -- Batch 172/173 -- Loss: 0.01867373 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11712927 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3386/5000 -- Batch 172/173 -- Loss: 0.01844511 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11591476 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3387/5000 -- Batch 172/173 -- Loss: 0.00973060 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11325417 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3388/5000 -- Batch 172/173 -- Loss: 0.03803267 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11326295 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3389/5000 -- Batch 172/173 -- Loss: 0.02248316 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12193882 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3390/5000 -- Batch 172/173 -- Loss: 0.01730483 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11552777 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3391/5000 -- Batch 172/173 -- Loss: 0.03584039 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11632463 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3392/5000 -- Batch 172/173 -- Loss: 0.02351415 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11214866 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3393/5000 -- Batch 172/173 -- Loss: 0.02384975 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11743119 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3394/5000 -- Batch 172/173 -- Loss: 0.02194630 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12212137 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3395/5000 -- Batch 172/173 -- Loss: 0.02363893 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12046609 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3396/5000 -- Batch 172/173 -- Loss: 0.13638613 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11609025 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3397/5000 -- Batch 172/173 -- Loss: 0.05689752 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11095536 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3398/5000 -- Batch 172/173 -- Loss: 0.03260951 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11750222 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3399/5000 -- Batch 172/173 -- Loss: 0.02573239 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11935595 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3400/5000 -- Batch 172/173 -- Loss: 0.01942240 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11567315 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3401/5000 -- Batch 172/173 -- Loss: 0.02606831 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11496323 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3402/5000 -- Batch 172/173 -- Loss: 0.02531040 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11685343 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3403/5000 -- Batch 172/173 -- Loss: 0.03602285 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11911997 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3404/5000 -- Batch 172/173 -- Loss: 0.01686142 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12061843 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3405/5000 -- Batch 172/173 -- Loss: 0.01667082 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12212129 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3406/5000 -- Batch 172/173 -- Loss: 0.01906013 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11484261 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3407/5000 -- Batch 172/173 -- Loss: 0.00708165 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11644253 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3408/5000 -- Batch 172/173 -- Loss: 0.01699830 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11426287 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3409/5000 -- Batch 172/173 -- Loss: 0.01870750 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12075174 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3410/5000 -- Batch 172/173 -- Loss: 0.09239540 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11592853 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3411/5000 -- Batch 172/173 -- Loss: 0.03264664 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11483840 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3412/5000 -- Batch 172/173 -- Loss: 0.05730864 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11832333 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3413/5000 -- Batch 172/173 -- Loss: 0.02132959 -- Train accuracy: 84.7905\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11505052 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3414/5000 -- Batch 172/173 -- Loss: 0.01211154 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11325924 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3415/5000 -- Batch 172/173 -- Loss: 0.02940201 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11709902 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3416/5000 -- Batch 172/173 -- Loss: 0.02790410 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11572550 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3417/5000 -- Batch 172/173 -- Loss: 0.04540146 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12106955 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3418/5000 -- Batch 172/173 -- Loss: 0.03002620 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12596218 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3419/5000 -- Batch 172/173 -- Loss: 0.02120234 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11552716 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3420/5000 -- Batch 172/173 -- Loss: 0.01395961 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12148833 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3421/5000 -- Batch 172/173 -- Loss: 0.02676421 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11879833 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3422/5000 -- Batch 172/173 -- Loss: 0.00948113 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11822262 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3423/5000 -- Batch 172/173 -- Loss: 0.00815465 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11832574 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3424/5000 -- Batch 172/173 -- Loss: 0.01682374 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11246828 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3425/5000 -- Batch 172/173 -- Loss: 0.03331775 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12130431 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3426/5000 -- Batch 172/173 -- Loss: 0.02310183 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11815159 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3427/5000 -- Batch 172/173 -- Loss: 0.02526416 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11920252 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3428/5000 -- Batch 172/173 -- Loss: 0.00896158 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11540622 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3429/5000 -- Batch 172/173 -- Loss: 0.05431857 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11867199 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3430/5000 -- Batch 172/173 -- Loss: 0.02804285 -- Train accuracy: 84.7995\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11360140 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3431/5000 -- Batch 172/173 -- Loss: 0.02667908 -- Train accuracy: 84.5827\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11935635 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3432/5000 -- Batch 172/173 -- Loss: 0.02509105 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11368956 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3433/5000 -- Batch 172/173 -- Loss: 0.03208607 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11679943 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3434/5000 -- Batch 172/173 -- Loss: 0.03932653 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11269845 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3435/5000 -- Batch 172/173 -- Loss: 0.05835928 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12152420 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3436/5000 -- Batch 172/173 -- Loss: 0.04623682 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10675850 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3437/5000 -- Batch 172/173 -- Loss: 0.02991307 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11849617 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3438/5000 -- Batch 172/173 -- Loss: 0.06426097 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11635997 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3439/5000 -- Batch 172/173 -- Loss: 0.03590959 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11960917 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3440/5000 -- Batch 172/173 -- Loss: 0.01629842 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10826725 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3441/5000 -- Batch 172/173 -- Loss: 0.02765453 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11857298 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3442/5000 -- Batch 172/173 -- Loss: 0.01496529 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12064908 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3443/5000 -- Batch 172/173 -- Loss: 0.02237701 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10930513 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3444/5000 -- Batch 172/173 -- Loss: 0.02963693 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12341141 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3445/5000 -- Batch 172/173 -- Loss: 0.02537442 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10618162 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3446/5000 -- Batch 172/173 -- Loss: 0.03504350 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12069691 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3447/5000 -- Batch 172/173 -- Loss: 0.02605097 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10860421 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3448/5000 -- Batch 172/173 -- Loss: 0.04334773 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10845720 -- Accuracy: 70.23026316\n",
      "\n",
      "Training:\n",
      "Epoch 3449/5000 -- Batch 172/173 -- Loss: 0.02276528 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10653691 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3450/5000 -- Batch 172/173 -- Loss: 0.02684786 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11096751 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3451/5000 -- Batch 172/173 -- Loss: 0.01890650 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11576584 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3452/5000 -- Batch 172/173 -- Loss: 0.02436469 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11173661 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3453/5000 -- Batch 172/173 -- Loss: 0.04569304 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10552552 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3454/5000 -- Batch 172/173 -- Loss: 0.03787883 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10751282 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3455/5000 -- Batch 172/173 -- Loss: 0.01158087 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11083786 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3456/5000 -- Batch 172/173 -- Loss: 0.02257728 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11000506 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3457/5000 -- Batch 172/173 -- Loss: 0.03043992 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10785674 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3458/5000 -- Batch 172/173 -- Loss: 0.01957488 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10741906 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3459/5000 -- Batch 172/173 -- Loss: 0.03095471 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11487813 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3460/5000 -- Batch 172/173 -- Loss: 0.01257267 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10864006 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3461/5000 -- Batch 172/173 -- Loss: 0.01120869 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10855998 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3462/5000 -- Batch 172/173 -- Loss: 0.02580348 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12583679 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3463/5000 -- Batch 172/173 -- Loss: 0.03132702 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10903724 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3464/5000 -- Batch 172/173 -- Loss: 0.03614823 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11337385 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3465/5000 -- Batch 172/173 -- Loss: 0.03711073 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11244278 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3466/5000 -- Batch 172/173 -- Loss: 0.01634930 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10689672 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3467/5000 -- Batch 172/173 -- Loss: 0.02180482 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12415331 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3468/5000 -- Batch 172/173 -- Loss: 0.07639353 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11023931 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3469/5000 -- Batch 172/173 -- Loss: 0.03391169 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11113082 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3470/5000 -- Batch 172/173 -- Loss: 0.03381342 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11382605 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3471/5000 -- Batch 172/173 -- Loss: 0.01064325 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11809111 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3472/5000 -- Batch 172/173 -- Loss: 0.02483881 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11061706 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3473/5000 -- Batch 172/173 -- Loss: 0.01373568 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10900977 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3474/5000 -- Batch 172/173 -- Loss: 0.02933951 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10829231 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3475/5000 -- Batch 172/173 -- Loss: 0.02535869 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11947400 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3476/5000 -- Batch 172/173 -- Loss: 0.04092340 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11601119 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3477/5000 -- Batch 172/173 -- Loss: 0.03570496 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10820210 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3478/5000 -- Batch 172/173 -- Loss: 0.04456434 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11570428 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3479/5000 -- Batch 172/173 -- Loss: 0.01345036 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10491577 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3480/5000 -- Batch 172/173 -- Loss: 0.01275403 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10957696 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3481/5000 -- Batch 172/173 -- Loss: 0.02410019 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11107263 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3482/5000 -- Batch 172/173 -- Loss: 0.04787980 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11743158 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3483/5000 -- Batch 172/173 -- Loss: 0.01864516 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10824828 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3484/5000 -- Batch 172/173 -- Loss: 0.02059128 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10591416 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3485/5000 -- Batch 172/173 -- Loss: 0.02685419 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10948736 -- Accuracy: 70.31250000\n",
      "\n",
      "Training:\n",
      "Epoch 3486/5000 -- Batch 172/173 -- Loss: 0.01942003 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12476545 -- Accuracy: 70.39473684\n",
      "\n",
      "Training:\n",
      "Epoch 3487/5000 -- Batch 172/173 -- Loss: 0.03577314 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12262061 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3488/5000 -- Batch 172/173 -- Loss: 0.05147902 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11864942 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3489/5000 -- Batch 172/173 -- Loss: 0.01193203 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11280759 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3490/5000 -- Batch 172/173 -- Loss: 0.02113643 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11625182 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3491/5000 -- Batch 172/173 -- Loss: 0.03241070 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11102001 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3492/5000 -- Batch 172/173 -- Loss: 0.02194974 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11988144 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3493/5000 -- Batch 172/173 -- Loss: 0.02344637 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11738772 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3494/5000 -- Batch 172/173 -- Loss: 0.04920653 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11597265 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3495/5000 -- Batch 172/173 -- Loss: 0.04031300 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11048589 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3496/5000 -- Batch 172/173 -- Loss: 0.02631906 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11315026 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3497/5000 -- Batch 172/173 -- Loss: 0.02409786 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11200484 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3498/5000 -- Batch 172/173 -- Loss: 0.04987754 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11682594 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3499/5000 -- Batch 172/173 -- Loss: 0.05476959 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11392897 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3500/5000 -- Batch 172/173 -- Loss: 0.02181591 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11320555 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3501/5000 -- Batch 172/173 -- Loss: 0.03957137 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11868966 -- Accuracy: 70.47697368\n",
      "\n",
      "Training:\n",
      "Epoch 3502/5000 -- Batch 172/173 -- Loss: 0.02928599 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11496213 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3503/5000 -- Batch 172/173 -- Loss: 0.03620774 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11924579 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3504/5000 -- Batch 172/173 -- Loss: 0.03950471 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11620582 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3505/5000 -- Batch 172/173 -- Loss: 0.02394544 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10966718 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3506/5000 -- Batch 172/173 -- Loss: 0.02601442 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11470849 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3507/5000 -- Batch 172/173 -- Loss: 0.02301349 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11544107 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3508/5000 -- Batch 172/173 -- Loss: 0.01446623 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11014726 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3509/5000 -- Batch 172/173 -- Loss: 0.03523047 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10866904 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3510/5000 -- Batch 172/173 -- Loss: 0.02727739 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11594959 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3511/5000 -- Batch 172/173 -- Loss: 0.03024040 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11694662 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3512/5000 -- Batch 172/173 -- Loss: 0.01278379 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10791987 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3513/5000 -- Batch 172/173 -- Loss: 0.05843961 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11135690 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3514/5000 -- Batch 172/173 -- Loss: 0.01075534 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11369497 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3515/5000 -- Batch 172/173 -- Loss: 0.03427697 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12026760 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3516/5000 -- Batch 172/173 -- Loss: 0.01523922 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11863535 -- Accuracy: 71.87500000\n",
      "\n",
      "Training:\n",
      "Epoch 3517/5000 -- Batch 172/173 -- Loss: 0.05873743 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11363690 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3518/5000 -- Batch 172/173 -- Loss: 0.01717227 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11705337 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3519/5000 -- Batch 172/173 -- Loss: 0.01461002 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11508876 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3520/5000 -- Batch 172/173 -- Loss: 0.02467202 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11370595 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3521/5000 -- Batch 172/173 -- Loss: 0.02205639 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11662781 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3522/5000 -- Batch 172/173 -- Loss: 0.03100289 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11471909 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3523/5000 -- Batch 172/173 -- Loss: 0.03415564 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11318117 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3524/5000 -- Batch 172/173 -- Loss: 0.00687178 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11352779 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3525/5000 -- Batch 172/173 -- Loss: 0.10563973 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11653576 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3526/5000 -- Batch 172/173 -- Loss: 0.02499552 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11952252 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3527/5000 -- Batch 172/173 -- Loss: 0.01787690 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11572781 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3528/5000 -- Batch 172/173 -- Loss: 0.03936226 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11429953 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3529/5000 -- Batch 172/173 -- Loss: 0.03225698 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11390965 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3530/5000 -- Batch 172/173 -- Loss: 0.03121094 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11831741 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3531/5000 -- Batch 172/173 -- Loss: 0.02205728 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11542354 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3532/5000 -- Batch 172/173 -- Loss: 0.02691597 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12165626 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3533/5000 -- Batch 172/173 -- Loss: 0.01544542 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11668366 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3534/5000 -- Batch 172/173 -- Loss: 0.03462288 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11937083 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3535/5000 -- Batch 172/173 -- Loss: 0.04681493 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11771589 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3536/5000 -- Batch 172/173 -- Loss: 0.01241178 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11907358 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3537/5000 -- Batch 172/173 -- Loss: 0.03672330 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12261335 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3538/5000 -- Batch 172/173 -- Loss: 0.01888034 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11718288 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3539/5000 -- Batch 172/173 -- Loss: 0.01795489 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11804923 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3540/5000 -- Batch 172/173 -- Loss: 0.02835575 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11619047 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3541/5000 -- Batch 172/173 -- Loss: 0.03523318 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11760475 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3542/5000 -- Batch 172/173 -- Loss: 0.03534110 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12000336 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3543/5000 -- Batch 172/173 -- Loss: 0.01585443 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11532649 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3544/5000 -- Batch 172/173 -- Loss: 0.03428488 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11955843 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3545/5000 -- Batch 172/173 -- Loss: 0.01756386 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12066055 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3546/5000 -- Batch 172/173 -- Loss: 0.02728920 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11938920 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3547/5000 -- Batch 172/173 -- Loss: 0.07467986 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11664679 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3548/5000 -- Batch 172/173 -- Loss: 0.02899483 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12672742 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3549/5000 -- Batch 172/173 -- Loss: 0.06951662 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12935013 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3550/5000 -- Batch 172/173 -- Loss: 0.00873332 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13270504 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3551/5000 -- Batch 172/173 -- Loss: 0.01457563 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12402678 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3552/5000 -- Batch 172/173 -- Loss: 0.04107294 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12345159 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3553/5000 -- Batch 172/173 -- Loss: 0.03017141 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12390618 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3554/5000 -- Batch 172/173 -- Loss: 0.02067023 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13367312 -- Accuracy: 71.87500000\n",
      "\n",
      "Training:\n",
      "Epoch 3555/5000 -- Batch 172/173 -- Loss: 0.02683372 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12141348 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3556/5000 -- Batch 172/173 -- Loss: 0.01748989 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12449097 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3557/5000 -- Batch 172/173 -- Loss: 0.02451594 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.13060981 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3558/5000 -- Batch 172/173 -- Loss: 0.05315354 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12426523 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3559/5000 -- Batch 172/173 -- Loss: 0.02797190 -- Train accuracy: 84.9621\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11980231 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3560/5000 -- Batch 172/173 -- Loss: 0.02168266 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11933362 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3561/5000 -- Batch 172/173 -- Loss: 0.02472832 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12497352 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3562/5000 -- Batch 172/173 -- Loss: 0.02259446 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11448848 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3563/5000 -- Batch 172/173 -- Loss: 0.03352200 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11943480 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3564/5000 -- Batch 172/173 -- Loss: 0.02366628 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12491871 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3565/5000 -- Batch 172/173 -- Loss: 0.03946415 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12287585 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3566/5000 -- Batch 172/173 -- Loss: 0.03473130 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11680429 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3567/5000 -- Batch 172/173 -- Loss: 0.03048546 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11583322 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3568/5000 -- Batch 172/173 -- Loss: 0.03534523 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11695856 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3569/5000 -- Batch 172/173 -- Loss: 0.02372019 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11678600 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3570/5000 -- Batch 172/173 -- Loss: 0.01506205 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11956193 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3571/5000 -- Batch 172/173 -- Loss: 0.02701623 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11998977 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3572/5000 -- Batch 172/173 -- Loss: 0.01401999 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11623891 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3573/5000 -- Batch 172/173 -- Loss: 0.02557619 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11806956 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3574/5000 -- Batch 172/173 -- Loss: 0.02351687 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11610170 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3575/5000 -- Batch 172/173 -- Loss: 0.02625383 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12039988 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3576/5000 -- Batch 172/173 -- Loss: 0.01923288 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12102267 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3577/5000 -- Batch 172/173 -- Loss: 0.02230563 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11631749 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3578/5000 -- Batch 172/173 -- Loss: 0.01322065 -- Train accuracy: 84.7724\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11921407 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3579/5000 -- Batch 172/173 -- Loss: 0.02192712 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11752536 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3580/5000 -- Batch 172/173 -- Loss: 0.02006751 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11330284 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3581/5000 -- Batch 172/173 -- Loss: 0.06344009 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12443042 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3582/5000 -- Batch 172/173 -- Loss: 0.01899596 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12009385 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3583/5000 -- Batch 172/173 -- Loss: 0.00633807 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11513156 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3584/5000 -- Batch 172/173 -- Loss: 0.06045542 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11607867 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3585/5000 -- Batch 172/173 -- Loss: 0.03013938 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12222599 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3586/5000 -- Batch 172/173 -- Loss: 0.02098223 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10537110 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3587/5000 -- Batch 172/173 -- Loss: 0.00563336 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11173293 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3588/5000 -- Batch 172/173 -- Loss: 0.03670616 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11536707 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3589/5000 -- Batch 172/173 -- Loss: 0.02278201 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11802102 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3590/5000 -- Batch 172/173 -- Loss: 0.03332366 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11479609 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3591/5000 -- Batch 172/173 -- Loss: 0.01439694 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10897918 -- Accuracy: 70.55921053\n",
      "\n",
      "Training:\n",
      "Epoch 3592/5000 -- Batch 172/173 -- Loss: 0.02949314 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11832041 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3593/5000 -- Batch 172/173 -- Loss: 0.10388303 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11741063 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3594/5000 -- Batch 172/173 -- Loss: 0.02369199 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12012904 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3595/5000 -- Batch 172/173 -- Loss: 0.04305293 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12640583 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3596/5000 -- Batch 172/173 -- Loss: 0.02993718 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12422875 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3597/5000 -- Batch 172/173 -- Loss: 0.01933784 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11770537 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3598/5000 -- Batch 172/173 -- Loss: 0.04002720 -- Train accuracy: 84.9440\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12043435 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3599/5000 -- Batch 172/173 -- Loss: 0.05615130 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11924798 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3600/5000 -- Batch 172/173 -- Loss: 0.02934522 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12318590 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3601/5000 -- Batch 172/173 -- Loss: 0.00919270 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11282348 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3602/5000 -- Batch 172/173 -- Loss: 0.02447122 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11172371 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3603/5000 -- Batch 172/173 -- Loss: 0.03499445 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12248986 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3604/5000 -- Batch 172/173 -- Loss: 0.05591815 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11643613 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3605/5000 -- Batch 172/173 -- Loss: 0.02408005 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12389022 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3606/5000 -- Batch 172/173 -- Loss: 0.01376881 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12103086 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3607/5000 -- Batch 172/173 -- Loss: 0.01560648 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11246720 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3608/5000 -- Batch 172/173 -- Loss: 0.01952343 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11291788 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3609/5000 -- Batch 172/173 -- Loss: 0.03379346 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11619169 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3610/5000 -- Batch 172/173 -- Loss: 0.02398370 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10681111 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3611/5000 -- Batch 172/173 -- Loss: 0.01684512 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11608393 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3612/5000 -- Batch 172/173 -- Loss: 0.03310917 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11479551 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3613/5000 -- Batch 172/173 -- Loss: 0.03372401 -- Train accuracy: 84.9530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11951425 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3614/5000 -- Batch 172/173 -- Loss: 0.01811458 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11495367 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3615/5000 -- Batch 172/173 -- Loss: 0.02223291 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11254975 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3616/5000 -- Batch 172/173 -- Loss: 0.08436083 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12003625 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3617/5000 -- Batch 172/173 -- Loss: 0.04991233 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11955747 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3618/5000 -- Batch 172/173 -- Loss: 0.00337146 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11792357 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3619/5000 -- Batch 172/173 -- Loss: 0.02185310 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11672772 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3620/5000 -- Batch 172/173 -- Loss: 0.05387754 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12056521 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3621/5000 -- Batch 172/173 -- Loss: 0.02935529 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11945554 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3622/5000 -- Batch 172/173 -- Loss: 0.01699680 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10857296 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3623/5000 -- Batch 172/173 -- Loss: 0.02529288 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10850674 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3624/5000 -- Batch 172/173 -- Loss: 0.02469667 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12044256 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3625/5000 -- Batch 172/173 -- Loss: 0.02070412 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12157769 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3626/5000 -- Batch 172/173 -- Loss: 0.04202297 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12336821 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3627/5000 -- Batch 172/173 -- Loss: 0.01584217 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11056945 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3628/5000 -- Batch 172/173 -- Loss: 0.02437619 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11294564 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3629/5000 -- Batch 172/173 -- Loss: 0.02694137 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11660705 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3630/5000 -- Batch 172/173 -- Loss: 0.01867400 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11569497 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3631/5000 -- Batch 172/173 -- Loss: 0.02481217 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11790545 -- Accuracy: 71.87500000\n",
      "\n",
      "Training:\n",
      "Epoch 3632/5000 -- Batch 172/173 -- Loss: 0.01274561 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11142210 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3633/5000 -- Batch 172/173 -- Loss: 0.04385146 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11286862 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3634/5000 -- Batch 172/173 -- Loss: 0.01764429 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11463964 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3635/5000 -- Batch 172/173 -- Loss: 0.08128136 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11965378 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3636/5000 -- Batch 172/173 -- Loss: 0.02170862 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12094885 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3637/5000 -- Batch 172/173 -- Loss: 0.01277772 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11783089 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3638/5000 -- Batch 172/173 -- Loss: 0.01696740 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11106676 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3639/5000 -- Batch 172/173 -- Loss: 0.03858137 -- Train accuracy: 84.7543\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11282858 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3640/5000 -- Batch 172/173 -- Loss: 0.01137410 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11901047 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3641/5000 -- Batch 172/173 -- Loss: 0.02812907 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10879006 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3642/5000 -- Batch 172/173 -- Loss: 0.04128470 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11108412 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3643/5000 -- Batch 172/173 -- Loss: 0.01567642 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10536035 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3644/5000 -- Batch 172/173 -- Loss: 0.00462428 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11615982 -- Accuracy: 70.64144737\n",
      "\n",
      "Training:\n",
      "Epoch 3645/5000 -- Batch 172/173 -- Loss: 0.02706368 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10715462 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3646/5000 -- Batch 172/173 -- Loss: 0.02230417 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10848624 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3647/5000 -- Batch 172/173 -- Loss: 0.03519099 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10553730 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3648/5000 -- Batch 172/173 -- Loss: 0.02297611 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11242115 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3649/5000 -- Batch 172/173 -- Loss: 0.01348376 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10834921 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3650/5000 -- Batch 172/173 -- Loss: 0.02921843 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10241814 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3651/5000 -- Batch 172/173 -- Loss: 0.02675345 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10421750 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3652/5000 -- Batch 172/173 -- Loss: 0.01765050 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10666285 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3653/5000 -- Batch 172/173 -- Loss: 0.01346650 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11196161 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3654/5000 -- Batch 172/173 -- Loss: 0.02543869 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11243792 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3655/5000 -- Batch 172/173 -- Loss: 0.02572028 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11376873 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3656/5000 -- Batch 172/173 -- Loss: 0.01092781 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10754111 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3657/5000 -- Batch 172/173 -- Loss: 0.03908984 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11427551 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3658/5000 -- Batch 172/173 -- Loss: 0.08618161 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11213044 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3659/5000 -- Batch 172/173 -- Loss: 0.02974165 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10921358 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3660/5000 -- Batch 172/173 -- Loss: 0.01483038 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10863713 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3661/5000 -- Batch 172/173 -- Loss: 0.04761147 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10776669 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3662/5000 -- Batch 172/173 -- Loss: 0.03237863 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10975619 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3663/5000 -- Batch 172/173 -- Loss: 0.02026949 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10533180 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3664/5000 -- Batch 172/173 -- Loss: 0.01349613 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10829866 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3665/5000 -- Batch 172/173 -- Loss: 0.02502669 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10927943 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3666/5000 -- Batch 172/173 -- Loss: 0.04861198 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10739879 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3667/5000 -- Batch 172/173 -- Loss: 0.01294185 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10718835 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3668/5000 -- Batch 172/173 -- Loss: 0.02067305 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11268980 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3669/5000 -- Batch 172/173 -- Loss: 0.02829491 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11156212 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3670/5000 -- Batch 172/173 -- Loss: 0.04029828 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10813730 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3671/5000 -- Batch 172/173 -- Loss: 0.01920030 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10695080 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3672/5000 -- Batch 172/173 -- Loss: 0.02410337 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11141662 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3673/5000 -- Batch 172/173 -- Loss: 0.03667707 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10745944 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3674/5000 -- Batch 172/173 -- Loss: 0.03571836 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11741228 -- Accuracy: 71.87500000\n",
      "\n",
      "Training:\n",
      "Epoch 3675/5000 -- Batch 172/173 -- Loss: 0.02031291 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11047091 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3676/5000 -- Batch 172/173 -- Loss: 0.02127304 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10762932 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3677/5000 -- Batch 172/173 -- Loss: 0.02525305 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11042405 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3678/5000 -- Batch 172/173 -- Loss: 0.02094384 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11756729 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3679/5000 -- Batch 172/173 -- Loss: 0.02043176 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10990277 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3680/5000 -- Batch 172/173 -- Loss: 0.01869904 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11248323 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3681/5000 -- Batch 172/173 -- Loss: 0.01893005 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10629714 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3682/5000 -- Batch 172/173 -- Loss: 0.02259472 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10818063 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3683/5000 -- Batch 172/173 -- Loss: 0.05908567 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10712935 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3684/5000 -- Batch 172/173 -- Loss: 0.00527387 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11301224 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3685/5000 -- Batch 172/173 -- Loss: 0.01456712 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10741477 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3686/5000 -- Batch 172/173 -- Loss: 0.03288171 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11006915 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3687/5000 -- Batch 172/173 -- Loss: 0.01400571 -- Train accuracy: 84.9530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11063295 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3688/5000 -- Batch 172/173 -- Loss: 0.02660865 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10603379 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3689/5000 -- Batch 172/173 -- Loss: 0.00729869 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11083276 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3690/5000 -- Batch 172/173 -- Loss: 0.00199602 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10473825 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3691/5000 -- Batch 172/173 -- Loss: 0.01958458 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10434891 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3692/5000 -- Batch 172/173 -- Loss: 0.02065146 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11308859 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3693/5000 -- Batch 172/173 -- Loss: 0.02002905 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10741831 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3694/5000 -- Batch 172/173 -- Loss: 0.02264641 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11179937 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3695/5000 -- Batch 172/173 -- Loss: 0.02565932 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10810410 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3696/5000 -- Batch 172/173 -- Loss: 0.02088409 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11332818 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3697/5000 -- Batch 172/173 -- Loss: 0.01733840 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11475095 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3698/5000 -- Batch 172/173 -- Loss: 0.02272885 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11203343 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3699/5000 -- Batch 172/173 -- Loss: 0.04684161 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11306562 -- Accuracy: 71.79276316\n",
      "\n",
      "Training:\n",
      "Epoch 3700/5000 -- Batch 172/173 -- Loss: 0.02230356 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11012039 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3701/5000 -- Batch 172/173 -- Loss: 0.04050777 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11291614 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3702/5000 -- Batch 172/173 -- Loss: 0.03340983 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10955825 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3703/5000 -- Batch 172/173 -- Loss: 0.02434850 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10334339 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3704/5000 -- Batch 172/173 -- Loss: 0.04091813 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11435994 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3705/5000 -- Batch 172/173 -- Loss: 0.02237795 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11465624 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3706/5000 -- Batch 172/173 -- Loss: 0.04856069 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11329671 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3707/5000 -- Batch 172/173 -- Loss: 0.03790744 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11146652 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3708/5000 -- Batch 172/173 -- Loss: 0.03066670 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10518852 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3709/5000 -- Batch 172/173 -- Loss: 0.01829790 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11158435 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3710/5000 -- Batch 172/173 -- Loss: 0.03705172 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11536505 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3711/5000 -- Batch 172/173 -- Loss: 0.03251165 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10799414 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3712/5000 -- Batch 172/173 -- Loss: 0.01739638 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10700943 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3713/5000 -- Batch 172/173 -- Loss: 0.01691177 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11090312 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3714/5000 -- Batch 172/173 -- Loss: 0.02750795 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11783575 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3715/5000 -- Batch 172/173 -- Loss: 0.02118384 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10610859 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3716/5000 -- Batch 172/173 -- Loss: 0.02525289 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12009124 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3717/5000 -- Batch 172/173 -- Loss: 0.03924031 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11448741 -- Accuracy: 71.79276316\n",
      "\n",
      "Training:\n",
      "Epoch 3718/5000 -- Batch 172/173 -- Loss: 0.02300302 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11187522 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3719/5000 -- Batch 172/173 -- Loss: 0.03026356 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10367753 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3720/5000 -- Batch 172/173 -- Loss: 0.03895546 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10644833 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3721/5000 -- Batch 172/173 -- Loss: 0.01088174 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11122460 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3722/5000 -- Batch 172/173 -- Loss: 0.01030153 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11383315 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3723/5000 -- Batch 172/173 -- Loss: 0.00389769 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10585947 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3724/5000 -- Batch 172/173 -- Loss: 0.02217670 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11302121 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3725/5000 -- Batch 172/173 -- Loss: 0.01615851 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11756503 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3726/5000 -- Batch 172/173 -- Loss: 0.04239308 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11667009 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3727/5000 -- Batch 172/173 -- Loss: 0.05516807 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11349085 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3728/5000 -- Batch 172/173 -- Loss: 0.02182468 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11231162 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3729/5000 -- Batch 172/173 -- Loss: 0.02989878 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11543507 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3730/5000 -- Batch 172/173 -- Loss: 0.02249374 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11758178 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3731/5000 -- Batch 172/173 -- Loss: 0.04162046 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11242087 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3732/5000 -- Batch 172/173 -- Loss: 0.01076603 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10395805 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3733/5000 -- Batch 172/173 -- Loss: 0.02310919 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10169907 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3734/5000 -- Batch 172/173 -- Loss: 0.01336446 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11442720 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3735/5000 -- Batch 172/173 -- Loss: 0.02611211 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11328480 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3736/5000 -- Batch 172/173 -- Loss: 0.00647721 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10247464 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3737/5000 -- Batch 172/173 -- Loss: 0.03762762 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11315007 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3738/5000 -- Batch 172/173 -- Loss: 0.02828680 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11455194 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3739/5000 -- Batch 172/173 -- Loss: 0.02954125 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11310188 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3740/5000 -- Batch 172/173 -- Loss: 0.03469167 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10414281 -- Accuracy: 70.72368421\n",
      "\n",
      "Training:\n",
      "Epoch 3741/5000 -- Batch 172/173 -- Loss: 0.02290073 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10191250 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3742/5000 -- Batch 172/173 -- Loss: 0.02420306 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10594289 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3743/5000 -- Batch 172/173 -- Loss: 0.04645292 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11489225 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3744/5000 -- Batch 172/173 -- Loss: 0.01876326 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10533209 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3745/5000 -- Batch 172/173 -- Loss: 0.05841938 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10593477 -- Accuracy: 70.80592105\n",
      "\n",
      "Training:\n",
      "Epoch 3746/5000 -- Batch 172/173 -- Loss: 0.03705753 -- Train accuracy: 84.8176\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11307525 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3747/5000 -- Batch 172/173 -- Loss: 0.01415911 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10960850 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3748/5000 -- Batch 172/173 -- Loss: 0.01008230 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11134024 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3749/5000 -- Batch 172/173 -- Loss: 0.02766684 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11279042 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3750/5000 -- Batch 172/173 -- Loss: 0.01899201 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11625392 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3751/5000 -- Batch 172/173 -- Loss: 0.01442236 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10513551 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3752/5000 -- Batch 172/173 -- Loss: 0.07199673 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11000782 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3753/5000 -- Batch 172/173 -- Loss: 0.03350219 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10498153 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3754/5000 -- Batch 172/173 -- Loss: 0.02332095 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11469813 -- Accuracy: 71.79276316\n",
      "\n",
      "Training:\n",
      "Epoch 3755/5000 -- Batch 172/173 -- Loss: 0.03237240 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10359180 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3756/5000 -- Batch 172/173 -- Loss: 0.02408691 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11390834 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3757/5000 -- Batch 172/173 -- Loss: 0.03368227 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10552669 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3758/5000 -- Batch 172/173 -- Loss: 0.01707963 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11027869 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3759/5000 -- Batch 172/173 -- Loss: 0.02749195 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11534792 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3760/5000 -- Batch 172/173 -- Loss: 0.02995332 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11166431 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3761/5000 -- Batch 172/173 -- Loss: 0.06241092 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11561129 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3762/5000 -- Batch 172/173 -- Loss: 0.03429641 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10590250 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3763/5000 -- Batch 172/173 -- Loss: 0.09547184 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11381620 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3764/5000 -- Batch 172/173 -- Loss: 0.01421339 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11432237 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3765/5000 -- Batch 172/173 -- Loss: 0.02690185 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10802873 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3766/5000 -- Batch 172/173 -- Loss: 0.00984606 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10809658 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3767/5000 -- Batch 172/173 -- Loss: 0.10305756 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10851061 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3768/5000 -- Batch 172/173 -- Loss: 0.02559381 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11397231 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3769/5000 -- Batch 172/173 -- Loss: 0.01530033 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10855583 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3770/5000 -- Batch 172/173 -- Loss: 0.01817123 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11802353 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3771/5000 -- Batch 172/173 -- Loss: 0.04997329 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11221890 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3772/5000 -- Batch 172/173 -- Loss: 0.02477992 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11733794 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3773/5000 -- Batch 172/173 -- Loss: 0.02767394 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11426584 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3774/5000 -- Batch 172/173 -- Loss: 0.01770433 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10594512 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3775/5000 -- Batch 172/173 -- Loss: 0.03606588 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11278725 -- Accuracy: 71.79276316\n",
      "\n",
      "Training:\n",
      "Epoch 3776/5000 -- Batch 172/173 -- Loss: 0.01177025 -- Train accuracy: 84.9530\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11695734 -- Accuracy: 71.95723684\n",
      "\n",
      "Training:\n",
      "Epoch 3777/5000 -- Batch 172/173 -- Loss: 0.03043289 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11297790 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3778/5000 -- Batch 172/173 -- Loss: 0.02023404 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12102939 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3779/5000 -- Batch 172/173 -- Loss: 0.03411889 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11353488 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3780/5000 -- Batch 172/173 -- Loss: 0.02568439 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11788604 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3781/5000 -- Batch 172/173 -- Loss: 0.02773325 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11888894 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3782/5000 -- Batch 172/173 -- Loss: 0.02457252 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11638868 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3783/5000 -- Batch 172/173 -- Loss: 0.06165462 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11313358 -- Accuracy: 71.87500000\n",
      "\n",
      "Training:\n",
      "Epoch 3784/5000 -- Batch 172/173 -- Loss: 0.03176670 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11356777 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3785/5000 -- Batch 172/173 -- Loss: 0.02336191 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11878048 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3786/5000 -- Batch 172/173 -- Loss: 0.02079419 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11178624 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3787/5000 -- Batch 172/173 -- Loss: 0.01836543 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10848068 -- Accuracy: 71.95723684\n",
      "\n",
      "Training:\n",
      "Epoch 3788/5000 -- Batch 172/173 -- Loss: 0.01329954 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11621345 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3789/5000 -- Batch 172/173 -- Loss: 0.01524704 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11851771 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3790/5000 -- Batch 172/173 -- Loss: 0.01340712 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11105082 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3791/5000 -- Batch 172/173 -- Loss: 0.09302527 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11036106 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3792/5000 -- Batch 172/173 -- Loss: 0.01569842 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10999798 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3793/5000 -- Batch 172/173 -- Loss: 0.03217427 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11789651 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3794/5000 -- Batch 172/173 -- Loss: 0.01659325 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10762677 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3795/5000 -- Batch 172/173 -- Loss: 0.01962354 -- Train accuracy: 84.9350\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11058752 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3796/5000 -- Batch 172/173 -- Loss: 0.02843936 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10765420 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3797/5000 -- Batch 172/173 -- Loss: 0.02346123 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.09882021 -- Accuracy: 70.88815789\n",
      "\n",
      "Training:\n",
      "Epoch 3798/5000 -- Batch 172/173 -- Loss: 0.03693588 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11903678 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3799/5000 -- Batch 172/173 -- Loss: 0.03299075 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10920163 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3800/5000 -- Batch 172/173 -- Loss: 0.03393640 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.12226851 -- Accuracy: 71.29934211\n",
      "\n",
      "Training:\n",
      "Epoch 3801/5000 -- Batch 172/173 -- Loss: 0.05699289 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10801877 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3802/5000 -- Batch 172/173 -- Loss: 0.02596272 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11365149 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3803/5000 -- Batch 172/173 -- Loss: 0.01942515 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10438173 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3804/5000 -- Batch 172/173 -- Loss: 0.00932752 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10990228 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3805/5000 -- Batch 172/173 -- Loss: 0.00392487 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10411825 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3806/5000 -- Batch 172/173 -- Loss: 0.04032352 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11331625 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3807/5000 -- Batch 172/173 -- Loss: 0.03470286 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10028599 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3808/5000 -- Batch 172/173 -- Loss: 0.03099680 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10448516 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3809/5000 -- Batch 172/173 -- Loss: 0.01195529 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10258621 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3810/5000 -- Batch 172/173 -- Loss: 0.03256290 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10852459 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3811/5000 -- Batch 172/173 -- Loss: 0.01448806 -- Train accuracy: 84.8356\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10426121 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3812/5000 -- Batch 172/173 -- Loss: 0.04140981 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.09910601 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3813/5000 -- Batch 172/173 -- Loss: 0.02478205 -- Train accuracy: 84.8627\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10667863 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3814/5000 -- Batch 172/173 -- Loss: 0.03671610 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10891361 -- Accuracy: 71.79276316\n",
      "\n",
      "Training:\n",
      "Epoch 3815/5000 -- Batch 172/173 -- Loss: 0.01403156 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.11023599 -- Accuracy: 71.13486842\n",
      "\n",
      "Training:\n",
      "Epoch 3816/5000 -- Batch 172/173 -- Loss: 0.03001254 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10774800 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3817/5000 -- Batch 172/173 -- Loss: 0.03156135 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10914213 -- Accuracy: 71.21710526\n",
      "\n",
      "Training:\n",
      "Epoch 3818/5000 -- Batch 172/173 -- Loss: 0.02133867 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10847074 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3819/5000 -- Batch 172/173 -- Loss: 0.04023718 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10915957 -- Accuracy: 71.79276316\n",
      "\n",
      "Training:\n",
      "Epoch 3820/5000 -- Batch 172/173 -- Loss: 0.02067176 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10705774 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3821/5000 -- Batch 172/173 -- Loss: 0.01022651 -- Train accuracy: 84.8266\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10282514 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3822/5000 -- Batch 172/173 -- Loss: 0.04114174 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10417931 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3823/5000 -- Batch 172/173 -- Loss: 0.03183337 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10446226 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3824/5000 -- Batch 172/173 -- Loss: 0.01772073 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10360323 -- Accuracy: 71.62828947\n",
      "\n",
      "Training:\n",
      "Epoch 3825/5000 -- Batch 172/173 -- Loss: 0.03080166 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10599611 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3826/5000 -- Batch 172/173 -- Loss: 0.02660772 -- Train accuracy: 84.9079\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10526801 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3827/5000 -- Batch 172/173 -- Loss: 0.02263835 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10547085 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3828/5000 -- Batch 172/173 -- Loss: 0.02266828 -- Train accuracy: 84.9169\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10849876 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3829/5000 -- Batch 172/173 -- Loss: 0.04657207 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10694521 -- Accuracy: 71.79276316\n",
      "\n",
      "Training:\n",
      "Epoch 3830/5000 -- Batch 172/173 -- Loss: 0.02882199 -- Train accuracy: 84.8537\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10561912 -- Accuracy: 71.79276316\n",
      "\n",
      "Training:\n",
      "Epoch 3831/5000 -- Batch 172/173 -- Loss: 0.04402098 -- Train accuracy: 84.8898\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10777668 -- Accuracy: 71.46381579\n",
      "\n",
      "Training:\n",
      "Epoch 3832/5000 -- Batch 172/173 -- Loss: 0.01889007 -- Train accuracy: 84.8447\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10629114 -- Accuracy: 71.54605263\n",
      "\n",
      "Training:\n",
      "Epoch 3833/5000 -- Batch 172/173 -- Loss: 0.01673641 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10371504 -- Accuracy: 71.95723684\n",
      "\n",
      "Training:\n",
      "Epoch 3834/5000 -- Batch 172/173 -- Loss: 0.02572970 -- Train accuracy: 84.9259\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10710541 -- Accuracy: 71.38157895\n",
      "\n",
      "Training:\n",
      "Epoch 3835/5000 -- Batch 172/173 -- Loss: 0.02512875 -- Train accuracy: 84.8808\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10993332 -- Accuracy: 71.05263158\n",
      "\n",
      "Training:\n",
      "Epoch 3836/5000 -- Batch 172/173 -- Loss: 0.02182391 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10787566 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3837/5000 -- Batch 172/173 -- Loss: 0.00745098 -- Train accuracy: 84.8988\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10345038 -- Accuracy: 70.97039474\n",
      "\n",
      "Training:\n",
      "Epoch 3838/5000 -- Batch 172/173 -- Loss: 0.01791775 -- Train accuracy: 84.8717\n",
      "Validation:\n",
      "Batch 18/19 -- Loss: 0.10520599 -- Accuracy: 71.71052632\n",
      "\n",
      "Training:\n",
      "Epoch 3839/5000 -- Batch 85/173 -- Loss: 0.02656539 -- Train accuracy: 85.3379\n",
      "Ending early.\n",
      "Wall time: 13h 14min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "try:\n",
    "    model.train()\n",
    "    for epoch_i in range(start_epoch, start_epoch+N_EPOCHS+1):\n",
    "        \n",
    "        # Training loop\n",
    "        # ------------------------------------------------\n",
    "        print(\"Training:\")\n",
    "        batch_train_losses = []\n",
    "        batch_train_accs = []\n",
    "        for batch_i, (X_, y_, head_x, head_y, tail_x, tail_y) in enumerate(train_loader):\n",
    "            X_, y_ = Utils.shuffle_batch(X_, y_)\n",
    "            X_fixed = Utils.convert_X_for_resnet(X_)\n",
    "#             X_fixed = X_\n",
    "    \n",
    "            X_fixed = X_fixed.to(device)\n",
    "            y_ = y_.to(device)\n",
    "            \n",
    "            # Convert to float data type\n",
    "            y_ = y_.type(torch.FloatTensor).view(-1,1)\n",
    "            y_ = np.deg2rad(y_)  # Convert to radians\n",
    "            y_ = y_.to(device)\n",
    "    \n",
    "            # Pass through model\n",
    "            # Logits as net's predictions\n",
    "            logits = model(X_fixed)\n",
    "\n",
    "#             # Compute loss\n",
    "#             # Convert negative angles to positive (add 360 to degrees or (2*np.pi) to radians)\n",
    "#             mask = (logits < 0) * (2*np.pi)\n",
    "#             logits = logits + mask\n",
    "            \n",
    "            \n",
    "            loss = criterion(logits, y_)\n",
    "            batch_train_losses.append(loss.item())\n",
    "\n",
    "            # Training step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Get training accs within tol% error\n",
    "            with torch.no_grad():\n",
    "                xxx = (y_ - tol/2) <= logits\n",
    "                yyy = logits <= (y_ + tol/2)\n",
    "                accuracy = (xxx.view(-1) & yyy.view(-1)).sum() / float(BATCH_SIZE) * 100\n",
    "            batch_train_accs.append(accuracy.item())\n",
    "            \n",
    "            print_str = f'\\rEpoch {epoch_i+1}/{start_epoch+N_EPOCHS} -- Batch {batch_i}/{len(train_loader)}'\n",
    "            print_str += f' -- Loss: {loss.item():0.8f} -- Train accuracy: {np.mean(batch_train_accs):0.4f}'\n",
    "            sys.stdout.write(print_str)\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        metrics['losses']['train'].append((epoch_i, np.mean(batch_train_losses)))\n",
    "        metrics['accs']['train'].append((epoch_i, np.mean(batch_train_accs)))\n",
    "        # ------------------------------------------------\n",
    "\n",
    "        # Test Acc\n",
    "        print(\"\\nValidation:\")\n",
    "        with torch.no_grad():\n",
    "            test_acc, test_loss = evaluate(val_loader, model, criterion, device, tol, BATCH_SIZE)\n",
    "        metrics['accs']['val'].append((epoch_i, test_acc))\n",
    "        metrics['losses']['val'].append((epoch_i, test_loss))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        if epoch_i % 250 == 0:\n",
    "            save_model(model, optimizer, metrics, epoch_i)\n",
    "    \n",
    "#         break\n",
    "except KeyboardInterrupt:\n",
    "    save_model(model, optimizer, metrics, epoch_i)\n",
    "    print(\"\\nEnding early.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training loss and accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.array(metrics['losses']['train'])[::,0]\n",
    "train_losses = np.array(metrics['losses']['train'])[::,1]\n",
    "test_losses = np.array(metrics['losses']['val'])[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, train_losses, label='Train');\n",
    "plt.plot(epochs[:len(test_losses)], test_losses, label='Val');\n",
    "plt.title(f'Loss curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.array(metrics['accs']['train'])[::,0]\n",
    "train_accs = np.array(metrics['accs']['train'])[::,1]\n",
    "test_accs = np.array(metrics['accs']['val'])[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, train_accs, label='Train');\n",
    "plt.plot(epochs[:len(test_losses)], test_accs, label='Val');\n",
    "plt.title(f'Accuracy curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute accuracy with tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  5, 10, 15, 20, 25, 30]),\n",
       " array([0.        , 0.08726646, 0.17453293, 0.26179939, 0.34906585,\n",
       "        0.43633231, 0.52359878]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolerance_array_deg = np.arange(0, 30+1, 5)\n",
    "tolerance_array_rad = np.deg2rad(tolerance_array_deg)\n",
    "\n",
    "tolerance_array_deg, tolerance_array_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tol: 0.0 or +- 0.0\n",
      "Batch 47/48 -- Loss: 8.01532656 -- Accuracy: 0.00000000\n",
      "\n",
      "Tol: 5.0 or +- 2.5\n",
      "Batch 47/48 -- Loss: 8.01532656 -- Accuracy: 0.00000000\n",
      "\n",
      "Tol: 10.0 or +- 5.0\n",
      "Batch 47/48 -- Loss: 8.01532656 -- Accuracy: 0.00000000\n",
      "\n",
      "Tol: 14.999999999999998 or +- 7.499999999999999\n",
      "Batch 47/48 -- Loss: 8.01532656 -- Accuracy: 0.00000000\n",
      "\n",
      "Tol: 20.0 or +- 10.0\n",
      "Batch 47/48 -- Loss: 8.01532656 -- Accuracy: 0.00000000\n",
      "\n",
      "Tol: 25.0 or +- 12.5\n",
      "Batch 47/48 -- Loss: 8.01532656 -- Accuracy: 0.00000000\n",
      "\n",
      "Tol: 29.999999999999996 or +- 14.999999999999998\n",
      "Batch 47/48 -- Loss: 8.01532656 -- Accuracy: 0.00000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accs_across_tolerances = []\n",
    "\n",
    "loader = test_loader\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for tol_i, tol in enumerate(tolerance_array_rad):\n",
    "        print(f'Tol: {np.rad2deg(tol)} or +- {np.rad2deg(tol)/2}')\n",
    "        test_acc, test_loss = evaluate(loader, model, criterion, device, tol, BATCH_SIZE)\n",
    "        print('\\n')\n",
    "        \n",
    "        accs_across_tolerances.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.plot(tolerance_array_deg, accs_across_tolerances, marker='o', linewidth=1)\n",
    "for acc_i, acc in enumerate(accs_across_tolerances):\n",
    "    ax.annotate(f'{acc:0.2f}', ((tolerance_array_deg[acc_i])+0.4, accs_across_tolerances[acc_i]-4))\n",
    "plt.xlabel(f'Tolerance (degree)')\n",
    "plt.ylabel(f'Accuracy (%)')\n",
    "plt.title(f'Test accuracy across tolerance levels')\n",
    "plt.xticks(tolerance_array_deg)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Show lines on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(bee_data, batch_size=1, sampler=sampler_test, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_endpoint(point, angle, length):\n",
    "    '''\n",
    "    point - Tuple (x, y)\n",
    "    angle - Angle you want your end point at in degrees.\n",
    "    length - Length of the line you want to plot.\n",
    "    '''\n",
    "    # Unpack the first point\n",
    "    x, y = point\n",
    "    \n",
    "    # Find the end point\n",
    "    endy = y + (length * np.sin(np.radians(angle)))\n",
    "    endx = x + (length * np.cos(np.radians(angle)))\n",
    "    return endx, endy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_arrows(X, y, preds, head, tail, length, ax=None, title=None):\n",
    "    img = X.squeeze().permute(1,2,0).numpy()\n",
    "    img = cv2.normalize(img,None,0,255,cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    midpoint_x = (float(head_x) + float(tail_x)) // 2 \n",
    "    midpoint_y = (float(head_y) + float(tail_y)) // 2 \n",
    "\n",
    "    # True line\n",
    "    true_x1 = tail[0]\n",
    "    true_y1 = tail[1]\n",
    "    true_endx = head[0]\n",
    "    true_endy = head[1]\n",
    "    \n",
    "    # Predicted line\n",
    "    pred_endx, pred_endy = get_endpoint((midpoint_x, midpoint_y), angle=-int(preds), length=length//2)\n",
    "    pred_x1, pred_y1 = get_endpoint((midpoint_x, midpoint_y), angle=-int(preds)+180, length=length//2)\n",
    "\n",
    "    if ax:\n",
    "        plot_type = ax\n",
    "    else:\n",
    "        plot_type = plt\n",
    "        \n",
    "    plot_type.annotate('', xy=(true_x1, true_y1), xytext=(true_endx, true_endy), \n",
    "               arrowprops=dict(arrowstyle=\"->\", color='#81e35d', alpha=0.9, linewidth=2, mutation_scale=28))\n",
    "    plot_type.annotate('', xy=(pred_x1, pred_y1), xytext=(pred_endx, pred_endy), \n",
    "               arrowprops=dict(arrowstyle=\"->\", color='orange', alpha=0.9, linewidth=2, mutation_scale=28))\n",
    "    \n",
    "    if plot_type == ax and title:\n",
    "        plot_type.set_title(f'True: {int(y)}, \\n Pred: {int(preds)}')\n",
    "        \n",
    "    plot_type.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show some test outputs with arrows\n",
    "n_rows = 10\n",
    "num_imgs = 8*n_rows\n",
    "fig, axes = plt.subplots(n_rows, num_imgs//n_rows, \n",
    "                         figsize=(14,10), dpi=300,\n",
    "                         sharex=True, sharey=True)\n",
    "axes = axes.flat\n",
    "\n",
    "try:\n",
    "    model.eval()\n",
    "    for batch_i, (X, y, head_x, head_y, tail_x, tail_y) in enumerate(test_loader):\n",
    "        \n",
    "        if batch_i == num_imgs:\n",
    "            break\n",
    "            \n",
    "        X, y = Utils.shuffle_batch(X, y)\n",
    "        X = Utils.convert_X_for_resnet(X)\n",
    "\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Convert to float data type\n",
    "        y = y.type(torch.FloatTensor).view(-1,1)\n",
    "        y = np.deg2rad(y)  # Convert to radians\n",
    "\n",
    "        logits = model(X)\n",
    "        preds = logits\n",
    "        preds = np.rad2deg(preds.cpu().detach().numpy())  # Convert output to degrees\n",
    "        \n",
    "        y = np.rad2deg(y)\n",
    "\n",
    "        head = (float(head_x), float(head_y))\n",
    "        tail = (float(tail_x), float(tail_y))\n",
    "        length = np.sqrt((tail_x - head_x)**2 + (tail_y - head_y)**2)\n",
    "        \n",
    "        plot_arrows(X.cpu(), y.cpu(), preds, head, tail, length, axes[batch_i])\n",
    "\n",
    "#         print(y, np.rad2deg(y), preds)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Ending early.')\n",
    "    \n",
    "true_patch = mpatches.Patch(color='#81e35d', label='True', linewidth=1)\n",
    "pred_patch = mpatches.Patch(color='orange', label='Predicted', linewidth=1)\n",
    "plt.legend(handles=[true_patch, pred_patch], loc=(-5, -1), title='Orientation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
